{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully!\n",
      "Classification Report for Classes:\n",
      "Classification Report for Poisonousness:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      4722\n",
      "           1       0.31      0.54      0.39       430\n",
      "\n",
      "    accuracy                           0.86      5152\n",
      "   macro avg       0.63      0.71      0.66      5152\n",
      "weighted avg       0.90      0.86      0.88      5152\n",
      "\n",
      "Confusion Matrix for Poisonousness:\n",
      "[[4197  525]\n",
      " [ 198  232]]\n"
     ]
    }
   ],
   "source": [
    "from datasets.fungidataset import build_dataset\n",
    "from sklearn.linear_model import LogisticRegression as Lin\n",
    "from sklearn.ensemble import AdaBoostClassifier , RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision import models \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "IMAGEDIR = \"/Users/koksziszdave/Downloads/fungi_images\"\n",
    "LABELDIR = \"/Users/koksziszdave/Downloads/fungi_train_metadata.csv\"\n",
    "\n",
    "args = {\n",
    "    \"image_dir\": IMAGEDIR,\n",
    "    \"labels_path\": LABELDIR,\n",
    "    \"pre_load\": False,\n",
    "    \"batch_size\": 32\n",
    "}\n",
    "\n",
    "train_loader, valid_loader = build_dataset(args)\n",
    "\n",
    "num_semcls = 100\n",
    "def extract_features(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Extract features using a pre-trained CNN.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    features, labels, poisonous = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            if(batch[\"image\"].shape[0]!=32):\n",
    "                continue\n",
    "            images, lbls, poi= batch[\"image\"].to(device), batch[\"target_sem_cls\"].to(device) , batch[\"target_poisonous\"].to(device)\n",
    "            \n",
    "            images=images.permute(0,3,1,2)\n",
    "            output = model(images)\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.append(lbls.cpu().numpy())\n",
    "            poisonous.append(poi.cpu().numpy())\n",
    "            \n",
    "\n",
    "    features = np.vstack(features)\n",
    "    labels = np.vstack(labels)\n",
    "    poisonous = np.vstack(poisonous)\n",
    "\n",
    "    return features, labels, poisonous\n",
    "\n",
    "def train_encodedmodel():\n",
    "     # Use a pre-trained ResNet for feature extraction\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    resnet.fc = nn.Identity()  # Remove the classification head\n",
    "    resnet = resnet.to(device)\n",
    "\n",
    "    # Extract features\n",
    "    print(\"Extracting features from the training set...\")\n",
    "    X_train, y_train ,y_train_pois = extract_features(resnet, train_loader, device)\n",
    "    print(\"Extracting features from the validation set...\")\n",
    "    X_val, y_val ,y_val_pois = extract_features(resnet, val_loader, device)\n",
    "    y_val_pois=y_val_pois.astype(int)\n",
    "    \n",
    "    y_train_pois=y_train_pois.astype(int)\n",
    "\n",
    "    print(X_train.shape, y_train.shape, y_train_pois.shape)\n",
    "    print(X_val.shape, y_val.shape, y_val_pois.shape)\n",
    "    #Save to numpy file\n",
    "    np.save(\"X_train.npy\",X_train)\n",
    "    np.save(\"y_train.npy\",y_train)\n",
    "    np.save(\"y_train_pois.npy\",y_train_pois)\n",
    "    np.save(\"X_val.npy\",X_val)\n",
    "    np.save(\"y_val.npy\",y_val)\n",
    "    np.save(\"y_val_pois.npy\",y_val_pois)\n",
    "    # Load pre-extracted features and labels\n",
    "    X_train = np.load(\"X_train.npy\")\n",
    "    y_train = np.load(\"y_train.npy\")\n",
    "    y_train_pois = np.load(\"y_train_pois.npy\")\n",
    "    X_val = np.load(\"X_val.npy\")\n",
    "    y_val = np.load(\"y_val.npy\")\n",
    "    y_val_pois = np.load(\"y_val_pois.npy\")\n",
    "\n",
    "    print(\"Features extracted successfully!\")\n",
    "    y_train_poisonous = y_train_pois.reshape(-1) # Shape: (num_samples,)\n",
    "    y_val_poisonous = y_val_pois.reshape(-1)    # Shape: (num_samples,)\n",
    "\n",
    "    # Convert one-hot classes to integers\n",
    "    y_train_classes = np.argmax(y_train, axis=1)  # Shape: (num_samples,)\n",
    "    y_val_classes = np.argmax(y_val, axis=1)      # Shape: (num_samples,)\n",
    "\n",
    "    # Address class imbalance in the poisonousness model\n",
    "    class_weights = sklearn.utils.class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_poisonous),\n",
    "        y=y_train_poisonous\n",
    "    )\n",
    "    class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "    # Pass the computed class weights to the classifier\n",
    "    poison_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    subsample=1.0,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    # Manually apply sample weights during fitting\n",
    "    sample_weights = np.array([class_weights_dict[label] for label in y_train_poisonous])\n",
    "    poison_model.fit(X_train, y_train_poisonous, sample_weight=sample_weights)\n",
    "    \n",
    "    poison_preds = poison_model.predict(X_val)\n",
    "\n",
    "    print(\"Classification Report for Poisonousness:\")\n",
    "    print(classification_report(y_val_poisonous, poison_preds))\n",
    "\n",
    "    # Additional metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(\"Confusion Matrix for Poisonousness:\")\n",
    "    print(confusion_matrix(y_val_poisonous, poison_preds))\n",
    "train_encodedmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.fungidataset import build_dataset\n",
    "from sklearn.linear_model import LogisticRegression as Lin\n",
    "from sklearn.ensemble import AdaBoostClassifier , RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision import models \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "IMAGEDIR = \"/Users/koksziszdave/Downloads/fungi_images\"\n",
    "LABELDIR = \"/Users/koksziszdave/Downloads/fungi_train_metadata.csv\"\n",
    "\n",
    "args = {\n",
    "    \"image_dir\": IMAGEDIR,\n",
    "    \"labels_path\": LABELDIR,\n",
    "    \"pre_load\": False,\n",
    "    \"batch_size\": 32\n",
    "}\n",
    "\n",
    "train_loader, valid_loader = build_dataset(args)\n",
    "\n",
    "num_semcls = 100\n",
    "def extract_features(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Extract features using a pre-trained CNN.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    features, labels, poisonous = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            if(batch[\"image\"].shape[0]!=32):\n",
    "                continue\n",
    "            images, lbls, poi= batch[\"image\"].to(device), batch[\"target_sem_cls\"].to(device) , batch[\"target_poisonous\"].to(device)\n",
    "            \n",
    "            images=images.permute(0,3,1,2)\n",
    "            output = model(images)\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.append(lbls.cpu().numpy())\n",
    "            poisonous.append(poi.cpu().numpy())\n",
    "            \n",
    "\n",
    "    features = np.vstack(features)\n",
    "    labels = np.vstack(labels)\n",
    "    poisonous = np.vstack(poisonous)\n",
    "\n",
    "    return features, labels, poisonous\n",
    "\n",
    "def train_encodedmodel():\n",
    "     # Use a pre-trained ResNet for feature extraction\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    resnet.fc = nn.Identity()  # Remove the classification head\n",
    "    resnet = resnet.to(device)\n",
    "\n",
    "    # Extract features\n",
    "    print(\"Extracting features from the training set...\")\n",
    "    X_train, y_train ,y_train_pois = extract_features(resnet, train_loader, device)\n",
    "    print(\"Extracting features from the validation set...\")\n",
    "    X_val, y_val ,y_val_pois = extract_features(resnet, val_loader, device)\n",
    "    y_val_pois=y_val_pois.astype(int)\n",
    "    \n",
    "    y_train_pois=y_train_pois.astype(int)\n",
    "\n",
    "    print(X_train.shape, y_train.shape, y_train_pois.shape)\n",
    "    print(X_val.shape, y_val.shape, y_val_pois.shape)\n",
    "    #Save to numpy file\n",
    "    np.save(\"X_train.npy\",X_train)\n",
    "    np.save(\"y_train.npy\",y_train)\n",
    "    np.save(\"y_train_pois.npy\",y_train_pois)\n",
    "    np.save(\"X_val.npy\",X_val)\n",
    "    np.save(\"y_val.npy\",y_val)\n",
    "    np.save(\"y_val_pois.npy\",y_val_pois)\n",
    "    # Load pre-extracted features and labels\n",
    "    X_train = np.load(\"X_train.npy\")\n",
    "    y_train = np.load(\"y_train.npy\")\n",
    "    y_train_pois = np.load(\"y_train_pois.npy\")\n",
    "    X_val = np.load(\"X_val.npy\")\n",
    "    y_val = np.load(\"y_val.npy\")\n",
    "    y_val_pois = np.load(\"y_val_pois.npy\")\n",
    "\n",
    "    print(\"Features extracted successfully!\")\n",
    "    y_train_poisonous = y_train_pois.reshape(-1) # Shape: (num_samples,)\n",
    "    y_val_poisonous = y_val_pois.reshape(-1)    # Shape: (num_samples,)\n",
    "\n",
    "    # Convert one-hot classes to integers\n",
    "    y_train_classes = np.argmax(y_train, axis=1)  # Shape: (num_samples,)\n",
    "    y_val_classes = np.argmax(y_val, axis=1)      # Shape: (num_samples,)\n",
    "\n",
    "    # Address class imbalance in the poisonousness model\n",
    "    class_weights = sklearn.utils.class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_poisonous),\n",
    "        y=y_train_poisonous\n",
    "    )\n",
    "    class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "    # Pass the computed class weights to the classifier\n",
    "    poison_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    subsample=1.0,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    # Manually apply sample weights during fitting\n",
    "    sample_weights = np.array([class_weights_dict[label] for label in y_train_poisonous])\n",
    "    poison_model.fit(X_train, y_train_poisonous, sample_weight=sample_weights)\n",
    "    \n",
    "    poison_preds = poison_model.predict(X_val)\n",
    "\n",
    "    print(\"Classification Report for Poisonousness:\")\n",
    "    print(classification_report(y_val_poisonous, poison_preds))\n",
    "\n",
    "    # Additional metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(\"Confusion Matrix for Poisonousness:\")\n",
    "    print(confusion_matrix(y_val_poisonous, poison_preds))\n",
    "train_encodedmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully!\n",
      "Training the classification model...\n",
      "Classification Report for Classes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.18      0.17        51\n",
      "           1       0.44      0.36      0.40        66\n",
      "           2       0.14      0.20      0.17        45\n",
      "           3       0.26      0.16      0.20        51\n",
      "           4       0.16      0.21      0.18        48\n",
      "           5       0.79      0.57      0.66        46\n",
      "           6       0.14      0.15      0.14        54\n",
      "           7       0.41      0.33      0.36        49\n",
      "           8       0.12      0.12      0.12        24\n",
      "           9       0.27      0.21      0.23        63\n",
      "          10       0.07      0.10      0.08        42\n",
      "          11       0.15      0.19      0.17        52\n",
      "          12       0.42      0.34      0.38        50\n",
      "          13       0.55      0.58      0.56        57\n",
      "          14       0.65      0.49      0.56        41\n",
      "          15       0.64      0.43      0.51        49\n",
      "          16       0.78      0.65      0.70        48\n",
      "          17       0.46      0.45      0.45        60\n",
      "          18       0.46      0.61      0.53        59\n",
      "          19       0.66      0.50      0.57        70\n",
      "          20       0.47      0.43      0.45        49\n",
      "          21       0.18      0.19      0.19        64\n",
      "          22       0.37      0.38      0.38        60\n",
      "          23       0.57      0.51      0.54        59\n",
      "          24       0.42      0.33      0.37        43\n",
      "          25       0.33      0.29      0.31        79\n",
      "          26       0.41      0.30      0.35        66\n",
      "          27       0.35      0.32      0.33        38\n",
      "          28       0.40      0.45      0.42        42\n",
      "          29       0.46      0.43      0.44        56\n",
      "          30       0.32      0.45      0.37        56\n",
      "          31       0.69      0.57      0.63        63\n",
      "          32       0.30      0.26      0.28        72\n",
      "          33       0.22      0.28      0.24        50\n",
      "          34       0.53      0.65      0.58        43\n",
      "          35       0.36      0.25      0.29        57\n",
      "          36       0.35      0.33      0.34        52\n",
      "          37       0.25      0.27      0.26        67\n",
      "          38       0.41      0.51      0.46        41\n",
      "          39       0.09      0.10      0.10        58\n",
      "          40       0.26      0.20      0.23        35\n",
      "          41       0.65      0.52      0.58        62\n",
      "          42       0.17      0.16      0.16        38\n",
      "          43       0.17      0.13      0.15        38\n",
      "          44       0.27      0.29      0.28        56\n",
      "          45       0.31      0.35      0.33        52\n",
      "          46       0.26      0.31      0.29        48\n",
      "          47       0.26      0.26      0.26        58\n",
      "          48       0.32      0.31      0.32        54\n",
      "          49       0.73      0.73      0.73        41\n",
      "          50       0.33      0.30      0.32        43\n",
      "          51       0.06      0.06      0.06        52\n",
      "          52       0.15      0.26      0.19        46\n",
      "          53       0.25      0.28      0.26        43\n",
      "          54       0.71      0.70      0.70        46\n",
      "          55       0.20      0.18      0.19        51\n",
      "          56       0.47      0.36      0.41        50\n",
      "          57       0.19      0.22      0.21        55\n",
      "          58       0.27      0.19      0.22        47\n",
      "          59       0.27      0.35      0.31        48\n",
      "          60       0.15      0.20      0.17        51\n",
      "          61       0.23      0.29      0.25        52\n",
      "          62       0.31      0.34      0.33        44\n",
      "          63       0.30      0.29      0.29        49\n",
      "          64       0.38      0.27      0.31        56\n",
      "          65       0.78      0.62      0.69        52\n",
      "          66       0.42      0.36      0.39        45\n",
      "          67       0.26      0.17      0.21        46\n",
      "          68       0.43      0.46      0.45        65\n",
      "          69       0.35      0.38      0.37        55\n",
      "          70       0.40      0.41      0.41        46\n",
      "          71       0.42      0.52      0.46        52\n",
      "          72       0.24      0.22      0.23        50\n",
      "          73       0.65      0.59      0.62        56\n",
      "          74       0.24      0.25      0.25        51\n",
      "          75       0.49      0.45      0.47        55\n",
      "          76       0.24      0.30      0.27        44\n",
      "          77       0.14      0.16      0.15        64\n",
      "          78       0.37      0.33      0.35        43\n",
      "          79       0.72      0.63      0.67        49\n",
      "          80       0.31      0.26      0.28        43\n",
      "          81       0.24      0.38      0.29        53\n",
      "          82       0.23      0.23      0.23        47\n",
      "          83       0.43      0.44      0.44        43\n",
      "          84       0.58      0.44      0.50        63\n",
      "          85       0.48      0.42      0.45        55\n",
      "          86       0.29      0.25      0.26        57\n",
      "          87       0.12      0.15      0.13        34\n",
      "          88       0.29      0.33      0.31        64\n",
      "          89       0.23      0.26      0.24        53\n",
      "          90       0.19      0.18      0.18        45\n",
      "          91       0.30      0.35      0.32        52\n",
      "          92       0.33      0.29      0.30        49\n",
      "          93       0.17      0.26      0.21        54\n",
      "          94       0.23      0.22      0.22        46\n",
      "          95       0.32      0.34      0.33        58\n",
      "          96       0.22      0.27      0.24        52\n",
      "          97       0.45      0.36      0.40        50\n",
      "          98       0.16      0.14      0.15        50\n",
      "          99       0.52      0.54      0.53        56\n",
      "\n",
      "    accuracy                           0.34      5152\n",
      "   macro avg       0.35      0.34      0.34      5152\n",
      "weighted avg       0.36      0.34      0.34      5152\n",
      "\n",
      "Confusion Matrix for Poisonousness:\n",
      "[[ 9  4  3 ...  0  0  0]\n",
      " [ 9 24  1 ...  0  0  0]\n",
      " [ 2  0  9 ...  0  1  0]\n",
      " ...\n",
      " [ 0  0  0 ... 18  0  0]\n",
      " [ 1  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0 30]]\n"
     ]
    }
   ],
   "source": [
    "from datasets.fungidataset import build_dataset\n",
    "from sklearn.linear_model import LogisticRegression as Lin\n",
    "from sklearn.ensemble import AdaBoostClassifier , RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision import models \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "IMAGEDIR = \"/Users/koksziszdave/Downloads/fungi_images\"\n",
    "LABELDIR = \"/Users/koksziszdave/Downloads/fungi_train_metadata.csv\"\n",
    "\n",
    "args = {\n",
    "    \"image_dir\": IMAGEDIR,\n",
    "    \"labels_path\": LABELDIR,\n",
    "    \"pre_load\": False,\n",
    "    \"batch_size\": 32\n",
    "}\n",
    "\n",
    "train_loader, valid_loader = build_dataset(args)\n",
    "\n",
    "num_semcls = 100\n",
    "def extract_features(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Extract features using a pre-trained CNN.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    features, labels, poisonous = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            if(batch[\"image\"].shape[0]!=32):\n",
    "                continue\n",
    "            images, lbls, poi= batch[\"image\"].to(device), batch[\"target_sem_cls\"].to(device) , batch[\"target_poisonous\"].to(device)\n",
    "            \n",
    "            images=images.permute(0,3,1,2)\n",
    "            output = model(images)\n",
    "            features.append(output.cpu().numpy())\n",
    "            labels.append(lbls.cpu().numpy())\n",
    "            poisonous.append(poi.cpu().numpy())\n",
    "            \n",
    "\n",
    "    features = np.vstack(features)\n",
    "    labels = np.vstack(labels)\n",
    "    poisonous = np.vstack(poisonous)\n",
    "\n",
    "    return features, labels, poisonous\n",
    "\n",
    "def train_encodedmodel():\n",
    "    # Load pre-extracted features and labels\n",
    "    X_train = np.load(\"X_train.npy\")\n",
    "    y_train = np.load(\"y_train.npy\")\n",
    "    X_val = np.load(\"X_val.npy\")\n",
    "    y_val = np.load(\"y_val.npy\")\n",
    "    print(\"Features extracted successfully!\")\n",
    "    # Convert one-hot classes to integers\n",
    "    y_train_classes = np.argmax(y_train, axis=1)  # Shape: (num_samples,)\n",
    "    y_val_classes = np.argmax(y_val, axis=1)      # Shape: (num_samples,)\n",
    "\n",
    "    # Pass the computed class weights to the classifier\n",
    "    \n",
    "    # Train the classification model\n",
    "    print(\"Training the classification model...\")\n",
    "    class_model = OneVsRestClassifier(AdaBoostClassifier( n_estimators=100, random_state=42))\n",
    "\n",
    "\n",
    "    class_model.fit(X_train, y_train_classes)\n",
    "\n",
    "\n",
    "\n",
    "    # Evaluate the models\n",
    "    class_preds = class_model.predict(X_val)\n",
    "\n",
    "\n",
    "\n",
    "    # Generate classification reports\n",
    "    print(\"Classification Report for Classes:\")\n",
    "    print(classification_report(y_val_classes, class_preds))\n",
    "\n",
    "    # Additional metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(\"Confusion Matrix for Poisonousness:\")\n",
    "    print(confusion_matrix(y_pred=class_preds, y_true=y_val_classes))\n",
    "train_encodedmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
