{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/czimbermark/Documents/Egyetem/Adatelemzes/Nagyhazi/FungiCLEF2024_ADC\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import timm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "os.chdir(\"/Users/czimbermark/Documents/Egyetem/Adatelemzes/Nagyhazi/FungiCLEF2024_ADC/\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset2 import FungiDataset\n",
    "from src.dataset2 import fungi_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 644 and val_loader: 161\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    \"image_dir\": \"/Users/czimbermark/Documents/Egyetem/Adatelemzes/Nagyhazi/FungiCLEF2024_ADC/data/x_train\",\n",
    "    \"labels_path\": \"/Users/czimbermark/Documents/Egyetem/Adatelemzes/Nagyhazi/FungiCLEF2024_ADC/data/train_metadata_height.csv\",\n",
    "    \"pre_load\": True,\n",
    "    \"batch_size\": 32,\n",
    "    \"crop_height\": 16,\n",
    "    \"interpolate\": \"bilinear\",\n",
    "    \"out_size\": (224, 224)\n",
    "}\n",
    "\n",
    "# Define the classes to include (your list of unique class IDs)\n",
    "class_ids_to_include = [4, 11, 16, 25, 30, 32, 37, 39, 43, 63, 100, 103, 128, 129, 131, 136, 142, 168, 180, 213, 214, 223, 252, 266, 309, 366, 389, 413, 473, 478, 487, 522, 555, 559, 591, 633, 637, 657, 671, 673, 689, 694, 724, 728, 738, 748, 764, 787, 812, 814, 830, 837, 845, 856, 884, 908, 909, 912, 967, 975, 989, 992, 1000, 1005, 1014, 1020, 1052, 1054, 1088, 1093, 1115, 1121, 1135, 1136, 1141, 1160, 1183, 1207, 1214, 1220, 1221, 1232, 1239, 1242, 1290, 1302, 1355, 1381, 1395, 1420, 1438, 1440, 1481, 1484, 1493, 1533, 1537, 1546, 1573, 1603]\n",
    "\n",
    "# Initialize the full dataset\n",
    "full_dataset = FungiDataset(\n",
    "    image_dir=config[\"image_dir\"],\n",
    "    labels_path=config[\"labels_path\"],\n",
    "    pre_load=config[\"pre_load\"],\n",
    "    crop_height=config[\"crop_height\"],\n",
    "    interpolate=config[\"interpolate\"],\n",
    "    out_size=config[\"out_size\"],\n",
    "    transform=None,\n",
    "    class_ids_to_include=class_ids_to_include  # Pass the list of class IDs\n",
    ")\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    list(range(len(full_dataset))), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=fungi_collate_fn, \n",
    "    drop_last=True  # Drops the last incomplete batch\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=fungi_collate_fn,\n",
    "    drop_last=True  # also\n",
    ")\n",
    "\n",
    "print(f\"Length of train_loader: {len(train_loader)} and val_loader: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of species classes: 100\n",
      "MultiTaskModel(\n",
      "  (base_model): MetaFormer(\n",
      "    (stem): Stem(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
      "      (norm): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (stages): Sequential(\n",
      "      (0): MetaFormerStage(\n",
      "        (downsample): Identity()\n",
      "        (blocks): Sequential(\n",
      "          (0): MetaFormerBlock(\n",
      "            (norm1): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): SepConv(\n",
      "              (pwconv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act1): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "              (act2): Identity()\n",
      "              (pwconv2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Identity()\n",
      "            (norm2): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Identity()\n",
      "          )\n",
      "          (1): MetaFormerBlock(\n",
      "            (norm1): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): SepConv(\n",
      "              (pwconv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act1): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "              (act2): Identity()\n",
      "              (pwconv2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Identity()\n",
      "            (norm2): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Identity()\n",
      "          )\n",
      "          (2): MetaFormerBlock(\n",
      "            (norm1): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): SepConv(\n",
      "              (pwconv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act1): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "              (act2): Identity()\n",
      "              (pwconv2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Identity()\n",
      "            (norm2): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): MetaFormerStage(\n",
      "        (downsample): Downsampling(\n",
      "          (norm): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): MetaFormerBlock(\n",
      "            (norm1): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): SepConv(\n",
      "              (pwconv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act1): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "              (act2): Identity()\n",
      "              (pwconv2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Identity()\n",
      "            (norm2): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Identity()\n",
      "          )\n",
      "          (1): MetaFormerBlock(\n",
      "            (norm1): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): SepConv(\n",
      "              (pwconv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act1): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "              (act2): Identity()\n",
      "              (pwconv2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Identity()\n",
      "            (norm2): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Identity()\n",
      "          )\n",
      "          (2): MetaFormerBlock(\n",
      "            (norm1): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): SepConv(\n",
      "              (pwconv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act1): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
      "              (act2): Identity()\n",
      "              (pwconv2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Identity()\n",
      "            (norm2): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): MetaFormerStage(\n",
      "        (downsample): Downsampling(\n",
      "          (norm): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
      "          (conv): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (1): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (2): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (3): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (4): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (5): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (6): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (7): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (8): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): MetaFormerStage(\n",
      "        (downsample): Downsampling(\n",
      "          (norm): LayerNorm2dNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
      "          (conv): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (1): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "          (2): MetaFormerBlock(\n",
      "            (norm1): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
      "            (token_mixer): Attention(\n",
      "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (layer_scale1): Identity()\n",
      "            (res_scale1): Scale()\n",
      "            (norm2): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (act): StarReLU(\n",
      "                (relu): ReLU()\n",
      "              )\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "            (layer_scale2): Identity()\n",
      "            (res_scale2): Scale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (head): Sequential(\n",
      "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "      (fc): MlpHead(\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (act): SquaredReLU(\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=100, bias=True)\n",
      "        (head_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc_toxicity): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Set num_species_classes based on the dataset\n",
    "num_species_classes = full_dataset.num_species_classes\n",
    "print(f\"Number of species classes: {num_species_classes}\")  # Should print 100\n",
    "num_toxicity_classes = 2   # Assuming binary classification (edible or poisonous)\n",
    "\n",
    "# Create the CAFormer model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = timm.create_model(\n",
    "    \"caformer_s18.sail_in22k\",\n",
    "    pretrained=True,\n",
    "    num_classes=num_species_classes  # For species classification\n",
    ")\n",
    "base_model.to(device)\n",
    "\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, base_model, num_species_classes, num_toxicity_classes):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "        # Replace the classifier for species classification\n",
    "        self.base_model.reset_classifier(num_species_classes)\n",
    "\n",
    "        num_features = base_model.num_features  # Number of features after pooling\n",
    "\n",
    "        # Create a new classifier for toxicity\n",
    "        self.fc_toxicity = nn.Linear(num_features, num_toxicity_classes)\n",
    "\n",
    "        # Define a pooling layer if not present\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.base_model.forward_features(x)  # Shape: [batch_size, channels, height, width]\n",
    "        # print(f\"Features shape: {features.shape}\")\n",
    "\n",
    "        # Species classification (using base model's head)\n",
    "        species_logits = self.base_model.forward_head(features)\n",
    "        # print(f\"Species logits shape: {species_logits.shape}\")\n",
    "\n",
    "        # Apply global average pooling for toxicity classification\n",
    "        pooled_features = self.global_pool(features).flatten(1)  # Shape: [batch_size, channels]\n",
    "        # print(f\"Pooled features shape: {pooled_features.shape}\")\n",
    "\n",
    "        # Toxicity classification\n",
    "        toxicity_logits = self.fc_toxicity(pooled_features)\n",
    "        # print(f\"Toxicity logits shape: {toxicity_logits.shape}\")\n",
    "\n",
    "        return {'species': species_logits, 'toxicity': toxicity_logits}\n",
    "\n",
    "# Initialize the multi-task model\n",
    "model = MultiTaskModel(base_model, num_species_classes, num_toxicity_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust learning rate as needed\n",
    "\n",
    "# Define loss functions\n",
    "criterion_species = nn.CrossEntropyLoss()\n",
    "criterion_toxicity = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class IDs in batch: tensor([60,  2, 34, 36,  1, 27, 32, 95, 61,  6, 56, 79, 49, 85,  2, 51, 50, 32,\n",
      "        93, 70,  0, 62, 39,  3, 56, 30, 48, 80,  0, 28, 35, 59])\n",
      "Min class ID: 0, Max class ID: 95\n"
     ]
    }
   ],
   "source": [
    "# Get a batch of data\n",
    "images, (class_ids, toxicities), _ = next(iter(train_loader))\n",
    "\n",
    "# Check the range of class_ids\n",
    "print(f\"Class IDs in batch: {class_ids}\")\n",
    "print(f\"Min class ID: {class_ids.min()}, Max class ID: {class_ids.max()}\")\n",
    "\n",
    "# Ensure class IDs are in the range [0, num_species_classes - 1]\n",
    "assert class_ids.min() >= 0 and class_ids.max() < num_species_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(targets, predictions, num_classes, plot=True):\n",
    "    total_conf_matrix = confusion_matrix(targets, predictions, labels=range(num_classes))\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(total_conf_matrix, annot=False, cmap='Blues', fmt='d')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Species Classification Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    return total_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=10):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies_species = []\n",
    "    train_accuracies_toxicity = []\n",
    "    val_accuracies_species = []\n",
    "    val_accuracies_toxicity = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_species = 0\n",
    "        correct_toxicity = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Iterate over batches\n",
    "        for batch_idx, (images, (class_ids, toxicities), _) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            class_ids = class_ids.to(device, dtype=torch.long)\n",
    "            toxicities = toxicities.to(device, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss_species = criterion_species(outputs['species'], class_ids)\n",
    "            loss_toxicity = criterion_toxicity(outputs['toxicity'], toxicities)\n",
    "            loss = loss_species + loss_toxicity  # Adjust weighting if needed\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            batch_loss = loss.item() * images.size(0)\n",
    "            running_loss += batch_loss\n",
    "\n",
    "            # Calculate accuracies\n",
    "            _, preds_species = torch.max(outputs['species'], 1)\n",
    "            _, preds_toxicity = torch.max(outputs['toxicity'], 1)\n",
    "            batch_correct_species = (preds_species == class_ids).sum().item()\n",
    "            batch_correct_toxicity = (preds_toxicity == toxicities).sum().item()\n",
    "            batch_samples = images.size(0)\n",
    "            correct_species += batch_correct_species\n",
    "            correct_toxicity += batch_correct_toxicity\n",
    "            total_samples += batch_samples\n",
    "\n",
    "            # Calculate batch accuracies\n",
    "            batch_accuracy_species = batch_correct_species / batch_samples * 100\n",
    "            batch_accuracy_toxicity = batch_correct_toxicity / batch_samples * 100\n",
    "\n",
    "            # Print per-batch metrics\n",
    "            print(f\"Train Batch {batch_idx+1}/{len(train_loader)}: Loss = {loss.item():.4f}, Species Acc = {batch_accuracy_species:.2f}%, Toxicity Acc = {batch_accuracy_toxicity:.2f}%\")\n",
    "\n",
    "        avg_train_loss = running_loss / total_samples\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracy_species = correct_species / total_samples * 100\n",
    "        train_accuracy_toxicity = correct_toxicity / total_samples * 100\n",
    "        train_accuracies_species.append(train_accuracy_species)\n",
    "        train_accuracies_toxicity.append(train_accuracy_toxicity)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct_species = 0\n",
    "        val_correct_toxicity = 0\n",
    "        val_total_samples = 0\n",
    "        val_predictions_species = []\n",
    "        val_targets_species = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, (class_ids, toxicities), _) in enumerate(val_loader):\n",
    "                images = images.to(device)\n",
    "                class_ids = class_ids.to(device, dtype=torch.long)\n",
    "                toxicities = toxicities.to(device, dtype=torch.long)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss_species = criterion_species(outputs['species'], class_ids)\n",
    "                loss_toxicity = criterion_toxicity(outputs['toxicity'], toxicities)\n",
    "                loss = loss_species + loss_toxicity  # Adjust weighting if needed\n",
    "\n",
    "                # Update running loss\n",
    "                batch_loss = loss.item() * images.size(0)\n",
    "                val_running_loss += batch_loss\n",
    "\n",
    "                # Calculate accuracies\n",
    "                _, preds_species = torch.max(outputs['species'], 1)\n",
    "                _, preds_toxicity = torch.max(outputs['toxicity'], 1)\n",
    "                batch_correct_species = (preds_species == class_ids).sum().item()\n",
    "                batch_correct_toxicity = (preds_toxicity == toxicities).sum().item()\n",
    "                batch_samples = images.size(0)\n",
    "                val_correct_species += batch_correct_species\n",
    "                val_correct_toxicity += batch_correct_toxicity\n",
    "                val_total_samples += batch_samples\n",
    "\n",
    "                # Store predictions and targets for confusion matrix\n",
    "                val_predictions_species.extend(preds_species.cpu().numpy())\n",
    "                val_targets_species.extend(class_ids.cpu().numpy())\n",
    "\n",
    "                # Calculate batch accuracies\n",
    "                batch_accuracy_species = batch_correct_species / batch_samples * 100\n",
    "                batch_accuracy_toxicity = batch_correct_toxicity / batch_samples * 100\n",
    "\n",
    "                # Print per-batch metrics\n",
    "                print(f\"Val Batch {batch_idx+1}/{len(val_loader)}: Loss = {loss.item():.4f}, Species Acc = {batch_accuracy_species:.2f}%, Toxicity Acc = {batch_accuracy_toxicity:.2f}%\")\n",
    "\n",
    "        avg_val_loss = val_running_loss / val_total_samples\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracy_species = val_correct_species / val_total_samples * 100\n",
    "        val_accuracy_toxicity = val_correct_toxicity / val_total_samples * 100\n",
    "        val_accuracies_species.append(val_accuracy_species)\n",
    "        val_accuracies_toxicity.append(val_accuracy_toxicity)\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}, Species Acc: {train_accuracy_species:.2f}%, Toxicity Acc: {train_accuracy_toxicity:.2f}%\")\n",
    "        print(f\"  Val Loss:   {avg_val_loss:.4f}, Species Acc: {val_accuracy_species:.2f}%, Toxicity Acc: {val_accuracy_toxicity:.2f}%\")\n",
    "\n",
    "        # Confusion Matrix for Species Classification\n",
    "        conf_matrix(val_targets_species, val_predictions_species, num_classes=num_species_classes, plot=True)\n",
    "\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies_species': train_accuracies_species,\n",
    "        'train_accuracies_toxicity': train_accuracies_toxicity,\n",
    "        'val_accuracies_species': val_accuracies_species,\n",
    "        'val_accuracies_toxicity': val_accuracies_toxicity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m training_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 29\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m toxicities \u001b[38;5;241m=\u001b[39m toxicities\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m loss_species \u001b[38;5;241m=\u001b[39m criterion_species(outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m'\u001b[39m], class_ids)\n\u001b[1;32m     32\u001b[0m loss_toxicity \u001b[38;5;241m=\u001b[39m criterion_toxicity(outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoxicity\u001b[39m\u001b[38;5;124m'\u001b[39m], toxicities)\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 35\u001b[0m, in \u001b[0;36mMultiTaskModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: [batch_size, channels, height, width]\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# print(f\"Features shape: {features.shape}\")\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Species classification (using base model's head)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     species_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mforward_head(features)\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/timm/models/metaformer.py:612\u001b[0m, in \u001b[0;36mMetaFormer.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    610\u001b[0m     x \u001b[38;5;241m=\u001b[39m checkpoint_seq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages, x)\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/timm/models/metaformer.py:439\u001b[0m, in \u001b[0;36mMetaFormerStage.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    437\u001b[0m     x \u001b[38;5;241m=\u001b[39m checkpoint_seq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, x)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_nchw:\n\u001b[1;32m    442\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B, C, H, W)\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/timm/models/metaformer.py:366\u001b[0m, in \u001b[0;36mMetaFormerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    363\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_scale1(x) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_scale1(\n\u001b[1;32m    365\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(\n\u001b[0;32m--> 366\u001b[0m                 \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_mixer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m             )\n\u001b[1;32m    368\u001b[0m         )\n\u001b[1;32m    369\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_scale2(x) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_scale2(\n\u001b[1;32m    371\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\n\u001b[1;32m    372\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    373\u001b[0m             )\n\u001b[1;32m    374\u001b[0m         )\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Egyetem/Adatelemzes/.venv/lib/python3.11/site-packages/timm/models/metaformer.py:199\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    196\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused_attn:\n\u001b[0;32m--> 199\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_drop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     attn \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "training_stats = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), training_stats['train_losses'], label=\"Train Loss\")\n",
    "plt.plot(range(1, num_epochs + 1), training_stats['val_losses'], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Species Classification Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), training_stats['train_accuracies_species'], label=\"Train Species Accuracy\")\n",
    "plt.plot(range(1, num_epochs + 1), training_stats['val_accuracies_species'], label=\"Validation Species Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Species Classification Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Toxicity Classification Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), training_stats['train_accuracies_toxicity'], label=\"Train Toxicity Accuracy\")\n",
    "plt.plot(range(1, num_epochs + 1), training_stats['val_accuracies_toxicity'], label=\"Validation Toxicity Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Toxicity Classification Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot User-Focused Loss (if included)\n",
    "if 'val_user_focused_losses' in training_stats:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs + 1), training_stats['val_user_focused_losses'], label=\"Validation User-Focused Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Validation User-Focused Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
