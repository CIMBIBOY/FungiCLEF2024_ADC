{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import timm\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(img, crop_s = 16, interp_mode = \"bilinear\", out_size = [300, 225]):\n",
    "    img = img.transpose(1, 0, 2)\n",
    "    # print(f\"Input shape: {img.shape}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if img is not None:\n",
    "        # Crop\n",
    "        cropped_img = crop(img, crop_s)\n",
    "\n",
    "        # Interpolation\n",
    "        scale_factor = 300 / cropped_img.shape[0]\n",
    "        sigma = scale_factor * 0.5\n",
    "        cropped_img = interpolate(cropped_img, 5, sigma, int_mode = interp_mode, size = out_size)\n",
    "        cropped_img = cropped_img.transpose(1, 2, 0)\n",
    "\n",
    "        # Retransform\n",
    "        cropped_img = cv2.cvtColor(cropped_img, cv2.COLOR_RGB2BGR)\n",
    "        cropped_img = cropped_img.transpose(1, 0, 2)\n",
    "\n",
    "        # Adding to array for saving as .npy\n",
    "        # print(f\"Output shape: {cropped_img.shape}\")\n",
    "        return np.array(cropped_img)\n",
    "\n",
    "def crop(img, crop_s = 16):\n",
    "    w, h, c = img.shape\n",
    "\n",
    "    # Crop x pixels from the top and bottom\n",
    "    if h > 270:\n",
    "        img = img[:, crop_s:h - crop_s, :]\n",
    "    #print(img.shape)\n",
    "    return img\n",
    "\n",
    "def interpolate(img, kernel_size = 5, sigma = 0.1, int_mode = \"bilinear\", size = [300, 225]):\n",
    "    img = torch.tensor(img)\n",
    "    # Blur for noise reduc\n",
    "    blur = torchvision.transforms.GaussianBlur(kernel_size, sigma)\n",
    "    blured_img = blur(img)\n",
    "    blured_img = blured_img.transpose(0, 2)\n",
    "    blured_img = blured_img.transpose(1, 2)\n",
    "    # print(blured_img.shape)\n",
    "    interpolated_img = F.interpolate(blured_img.unsqueeze(0), size, mode= int_mode)\n",
    "    interpolated_img = interpolated_img.squeeze(0)\n",
    "    # print(interpolated_img.shape)\n",
    "    return interpolated_img.detach().numpy()\n",
    "\n",
    "def downsample(data):\n",
    "    d1 = cv2.pyrDown(data)\n",
    "    d2 = cv2.pyrDown(d1)\n",
    "    # d3 = cv2.pyrDown(d2)\n",
    "    print(\"Original shape: \", data.shape, \"Downsampled shape: \", d2.shape)\n",
    "    return np.array(d2)\n",
    "\n",
    "def upsample(data):\n",
    "    d1 = cv2.pyrUp(data)\n",
    "    d2 = cv2.pyrUp(d1)\n",
    "    # d3 = cv2.pyrDown(d2)\n",
    "    print(\"Original shape: \", data.shape, \"Downsampled shape: \", d2.shape)\n",
    "    return np.array(d2)\n",
    "\n",
    "\n",
    "def fungi_collate_fn(batch):\n",
    "    images, class_ids, toxicities, img_names = [], [], [], []\n",
    "    for image, (class_id, toxicity), img_name in batch:\n",
    "        # print(f\"Individual image shape: {image.shape}\")  # Should be [C, H, W]\n",
    "        images.append(image)\n",
    "        class_ids.append(class_id)\n",
    "        toxicities.append(toxicity)\n",
    "        img_names.append(img_name)\n",
    "\n",
    "    images = torch.stack(images)  # Should result in shape [batch_size, C, H, W]\n",
    "    #print(f\"Batch images shape after stacking: {images.shape}\")\n",
    "\n",
    "    class_ids = torch.tensor(class_ids, dtype=torch.long)\n",
    "    toxicities = torch.tensor(toxicities, dtype=torch.long)\n",
    "\n",
    "    return images, (class_ids, toxicities), img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm  # PyTorch Image Models\n",
    "\n",
    "class HybridHead(nn.Module):\n",
    "    def __init__(self, in_features, num_species_classes, num_toxicity_classes):\n",
    "        super(HybridHead, self).__init__()\n",
    "        # Attention mechanism\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=in_features, num_heads=8)\n",
    "        # State Space Model (SSM) component\n",
    "        self.ssm = nn.LSTM(in_features, in_features, batch_first=True)\n",
    "        # Fully connected layers for species classification\n",
    "        self.fc_species = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_species_classes)\n",
    "        )\n",
    "        # Fully connected layers for toxicity prediction\n",
    "        self.fc_toxicity = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_toxicity_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Attention mechanism\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        # State Space Model (SSM) component\n",
    "        ssm_output, _ = self.ssm(attn_output)\n",
    "        # Global average pooling\n",
    "        pooled_output = ssm_output.mean(dim=1)\n",
    "        # Species classification\n",
    "        species_output = self.fc_species(pooled_output)\n",
    "        # Toxicity prediction\n",
    "        toxicity_output = self.fc_toxicity(pooled_output)\n",
    "        return species_output, toxicity_output\n",
    "\n",
    "class FungiClassifier(nn.Module):\n",
    "    def __init__(self, num_species_classes, num_toxicity_classes):\n",
    "        super(FungiClassifier, self).__init__()\n",
    "        # Pre-trained EfficientNet backbone\n",
    "        self.backbone = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0)\n",
    "        in_features = self.backbone.num_features\n",
    "        # Hybrid head\n",
    "        self.head = HybridHead(in_features, num_species_classes, num_toxicity_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        features = self.backbone(x)\n",
    "        # Expand dimensions to match attention input requirements\n",
    "        features = features.unsqueeze(1)\n",
    "        # Hybrid head\n",
    "        species_output, toxicity_output = self.head(features)\n",
    "        return species_output, toxicity_output\n",
    "\n",
    "device='cpu'\n",
    "model = FungiClassifier(100, 2)\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Adjust learning rate as needed\n",
    "\n",
    "# Define loss functions\n",
    "criterion_species = nn.CrossEntropyLoss()\n",
    "criterion_toxicity = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FungiDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_path, pre_load=True, crop_height=16, interpolate=\"bilinear\", out_size=(300, 225), transform=None, class_ids_to_include=None):\n",
    "        '''\n",
    "        Args:\n",
    "            image_dir: directory containing the images\n",
    "            labels_path: path to the labels CSV file\n",
    "            pre_load: True if images should be loaded into memory, False otherwise\n",
    "            crop_height: Height for cropping images\n",
    "            interpolate: Interpolation method\n",
    "            out_size: Output size for resized images\n",
    "            transform: Optional transform to be applied on a sample.\n",
    "        '''\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_path = labels_path\n",
    "        self.pre_load = pre_load\n",
    "        self.crop_h = crop_height\n",
    "        self.interpolate = interpolate\n",
    "        self.out_size = out_size\n",
    "        self.transform = transform\n",
    "        self.load_num = 0\n",
    "\n",
    "        # Load metadata\n",
    "        metadata = pd.read_csv(self.labels_path)\n",
    "\n",
    "        # Filter to include only existing imgs\n",
    "        image_files = set(os.listdir(self.image_dir))\n",
    "        metadata = metadata[metadata['image_path'].isin(image_files)]\n",
    "\n",
    "        if metadata.empty:\n",
    "            raise ValueError('No matching images found in the image directory')\n",
    "\n",
    "        # **Filter to include only specified class IDs**\n",
    "        if class_ids_to_include is not None:\n",
    "            metadata = metadata[metadata['class_id'].isin(class_ids_to_include)]\n",
    "            metadata.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Reset index after filtering\n",
    "        metadata.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Ensure labels are integers\n",
    "        metadata['class_id'] = metadata['class_id'].astype(int)\n",
    "        metadata['poisonous'] = metadata['poisonous'].astype(int)\n",
    "\n",
    "        # **Remap class IDs to a continuous range starting from 0**\n",
    "        unique_class_ids = sorted(metadata['class_id'].unique())\n",
    "        class_id_to_idx = {original_id: idx for idx, original_id in enumerate(unique_class_ids)}\n",
    "        metadata['class_id'] = metadata['class_id'].map(class_id_to_idx)\n",
    "\n",
    "        # Update class IDs and calculate the number of species classes\n",
    "        self.metadata = metadata\n",
    "        self.image_paths = metadata['image_path'].tolist()\n",
    "        self.class_ids = metadata['class_id'].tolist()\n",
    "        self.toxicities = metadata['poisonous'].tolist()\n",
    "        self.num_species_classes = len(unique_class_ids)\n",
    "\n",
    "        # Pre-load images if required\n",
    "        if self.pre_load:\n",
    "            self.images = []\n",
    "            for img_name in self.image_paths:\n",
    "                img_path = os.path.join(self.image_dir, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Image {img_path} could not be read.\")\n",
    "                    continue\n",
    "\n",
    "                img_processed = process(img, crop_s=self.crop_h, interp_mode=self.interpolate, out_size=self.out_size)\n",
    "                # Convert image to tensor and float32\n",
    "                image = torch.from_numpy(img_processed).float()\n",
    "                image = image.permute(2, 0, 1)\n",
    "\n",
    "                # Normalize using ImageNet mean and std\n",
    "                mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "                std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "                image = (image - mean) / std\n",
    "                self.images.append(image)\n",
    "                self.load_num += 1\n",
    "                if self.load_num / 3 == 0:\n",
    "                  print(f\"{self.load_num / 1000} images loaded\")\n",
    "        else:\n",
    "            self.images = None  # Images will be loaded in __getitem__\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.pre_load:\n",
    "            image = self.images[idx]\n",
    "        else:\n",
    "            img_name = self.image_paths[idx]\n",
    "            img_path = os.path.join(self.image_dir, img_name)\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Image at {img_path} could not be read.\")\n",
    "\n",
    "            image_processed = process(img, crop_s=self.crop_h, interp_mode=self.interpolate, out_size=self.out_size)\n",
    "\n",
    "            # Convert image to tensor and float32\n",
    "            img_tensor = torch.from_numpy(image_processed).float().permute(2, 0, 1)\n",
    "\n",
    "            # Normalize using ImageNet mean and std\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "            image = (img_tensor - mean) / std\n",
    "\n",
    "            '''\n",
    "            print(image.shape)\n",
    "            print(f\"Image dtype: {image.dtype}\")  # Should be torch.float32\n",
    "            print(f\"Image min: {image.min()}, max: {image.max()}\")  # Should be within expected range\n",
    "            '''\n",
    "\n",
    "        # labels\n",
    "        class_id = self.class_ids[idx]\n",
    "        toxicity = self.toxicities[idx]\n",
    "\n",
    "        return image, (class_id, toxicity), img_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 25763\n",
      "Length of train_loader: 322 and val_loader: 80\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"image_dir\": \"/Users/dkocsis_local/Downloads/data\",\n",
    "    \"labels_path\": \"/Users/dkocsis_local/Downloads/train_metadata_height.csv\",\n",
    "    \"pre_load\": False,\n",
    "    \"batch_size\": 64,\n",
    "    \"crop_height\": 16,\n",
    "    \"interpolate\": \"bilinear\",\n",
    "    \"out_size\": (224, 224)\n",
    "}\n",
    "\n",
    "# Define the classes to include (your list of unique class IDs)\n",
    "class_ids_to_include = [4, 11, 16, 25, 30, 32, 37, 39, 43, 63, 100, 103, 128, 129, 131, 136, 142, 168, 180, 213, 214, 223, 252, 266, 309, 366, 389, 413, 473, 478, 487, 522, 555, 559, 591, 633, 637, 657, 671, 673, 689, 694, 724, 728, 738, 748, 764, 787, 812, 814, 830, 837, 845, 856, 884, 908, 909, 912, 967, 975, 989, 992, 1000, 1005, 1014, 1020, 1052, 1054, 1088, 1093, 1115, 1121, 1135, 1136, 1141, 1160, 1183, 1207, 1214, 1220, 1221, 1232, 1239, 1242, 1290, 1302, 1355, 1381, 1395, 1420, 1438, 1440, 1481, 1484, 1493, 1533, 1537, 1546, 1573, 1603]\n",
    "\n",
    "# Initialize the full dataset\n",
    "full_dataset = FungiDataset(\n",
    "    image_dir=config[\"image_dir\"],\n",
    "    labels_path=config[\"labels_path\"],\n",
    "    pre_load=config[\"pre_load\"],\n",
    "    crop_height=config[\"crop_height\"],\n",
    "    interpolate=config[\"interpolate\"],\n",
    "    out_size=config[\"out_size\"],\n",
    "    transform=None,\n",
    "    class_ids_to_include=class_ids_to_include  # Pass the list of class IDs\n",
    ")\n",
    "\n",
    "print(f\"Number of samples in dataset: {len(full_dataset)}\")\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_indices, val_indices = train_test_split(\n",
    "    list(range(len(full_dataset))), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    prefetch_factor=None,  # Prefetch batches to improve performance\n",
    "    pin_memory=True,  # Optimize for GPU\n",
    "    collate_fn=fungi_collate_fn,\n",
    "    drop_last=True  # Drops the last incomplete batch\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    prefetch_factor=None,\n",
    "    pin_memory=True,\n",
    "    collate_fn=fungi_collate_fn,\n",
    "    drop_last=True # also\n",
    ")\n",
    "\n",
    "print(f\"Length of train_loader: {len(train_loader)} and val_loader: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class IDs in batch: tensor([99, 41, 57, 25, 52, 73, 61,  3,  2, 32, 20, 57, 50, 39,  8,  1, 75, 26,\n",
      "        49, 91, 31,  1, 74, 89, 33, 18, 35, 19, 50, 13, 21, 15, 87, 25,  7, 88,\n",
      "        72, 79, 85, 71, 73, 36, 96, 30, 31,  0, 94, 79, 22, 47, 39, 61, 80, 62,\n",
      "        27, 10, 47,  9, 36, 67, 10, 82,  0, 15])\n",
      "Min class ID: 0, Max class ID: 99\n"
     ]
    }
   ],
   "source": [
    "# Get a batch of data\n",
    "images, (class_ids, toxicities), _ = next(iter(train_loader))\n",
    "\n",
    "# Check the range of class_ids\n",
    "print(f\"Class IDs in batch: {class_ids}\")\n",
    "print(f\"Min class ID: {class_ids.min()}, Max class ID: {class_ids.max()}\")\n",
    "\n",
    "# Ensure class IDs are in the range [0, num_species_classes - 1]\n",
    "assert class_ids.min() >= 0 and class_ids.max() < 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=10, alpha = 1.0, beta = 0.6):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies_species = []\n",
    "    train_accuracies_toxicity = []\n",
    "    val_accuracies_species = []\n",
    "    val_accuracies_toxicity = []\n",
    "    best_val_acc=0\n",
    "    earlys=0\n",
    "    max_earlys=4\n",
    "    best_not_saved=0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_species = 0\n",
    "        correct_toxicity = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Iterate over batches\n",
    "        for batch_idx, (images, (class_ids, toxicities), _) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            class_ids = class_ids.to(device, dtype=torch.long)\n",
    "            toxicities = toxicities.to(device, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss_species = criterion_species(outputs[0], class_ids)\n",
    "            loss_toxicity = criterion_toxicity(outputs[1], toxicities)\n",
    "            loss = alpha * loss_species + beta * loss_toxicity  # weighting\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            batch_loss = loss.item() * images.size(0)\n",
    "            running_loss += batch_loss\n",
    "\n",
    "            # Calculate accuracies\n",
    "            _, preds_species = torch.max(outputs[0], 1)\n",
    "            _, preds_toxicity = torch.max(outputs[1], 1)\n",
    "            batch_correct_species = (preds_species == class_ids).sum().item()\n",
    "            batch_correct_toxicity = (preds_toxicity == toxicities).sum().item()\n",
    "            batch_samples = images.size(0)\n",
    "            correct_species += batch_correct_species\n",
    "            correct_toxicity += batch_correct_toxicity\n",
    "            total_samples += batch_samples\n",
    "\n",
    "            # Calculate batch accuracies\n",
    "            batch_accuracy_species = batch_correct_species / batch_samples * 100\n",
    "            batch_accuracy_toxicity = batch_correct_toxicity / batch_samples * 100\n",
    "            # Print per-batch metrics\n",
    "            print(f\"Train Batch {batch_idx+1}/{len(train_loader)}: Loss = {loss.item():.4f}, Species Acc = {batch_accuracy_species:.2f}%, Toxicity Acc = {batch_accuracy_toxicity:.2f}%\")\n",
    "            \n",
    "\n",
    "        avg_train_loss = running_loss / total_samples\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracy_species = correct_species / total_samples * 100\n",
    "        train_accuracy_toxicity = correct_toxicity / total_samples * 100\n",
    "        train_accuracies_species.append(train_accuracy_species)\n",
    "        train_accuracies_toxicity.append(train_accuracy_toxicity)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct_species = 0\n",
    "        val_correct_toxicity = 0\n",
    "        val_total_samples = 0\n",
    "        val_predictions_species = []\n",
    "        val_targets_species = []\n",
    "        val_predictions_toxicity = []\n",
    "        val_targets_toxicity = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, (class_ids, toxicities), _) in enumerate(val_loader):\n",
    "                images = images.to(device)\n",
    "                class_ids = class_ids.to(device, dtype=torch.long)\n",
    "                toxicities = toxicities.to(device, dtype=torch.long)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                loss_species = criterion_species(outputs[0], class_ids)\n",
    "                loss_toxicity = criterion_toxicity(outputs[1], toxicities)\n",
    "                loss = alpha * loss_species + beta * loss_toxicity  # Adjust weighting\n",
    "\n",
    "                # Update running loss\n",
    "                batch_loss = loss.item() * images.size(0)\n",
    "                val_running_loss += batch_loss\n",
    "\n",
    "                # Calculate accuracies\n",
    "                _, preds_species = torch.max(outputs[0], 1)\n",
    "                _, preds_toxicity = torch.max(outputs[1], 1)\n",
    "                batch_correct_species = (preds_species == class_ids).sum().item()\n",
    "                batch_correct_toxicity = (preds_toxicity == toxicities).sum().item()\n",
    "                batch_samples = images.size(0)\n",
    "                val_correct_species += batch_correct_species\n",
    "                val_correct_toxicity += batch_correct_toxicity\n",
    "                val_total_samples += batch_samples\n",
    "\n",
    "                # Store predictions and targets for confusion matrices\n",
    "                val_predictions_species.extend(preds_species.cpu().numpy())\n",
    "                val_targets_species.extend(class_ids.cpu().numpy())\n",
    "                val_predictions_toxicity.extend(preds_toxicity.cpu().numpy())\n",
    "                val_targets_toxicity.extend(toxicities.cpu().numpy())\n",
    "\n",
    "                # Calculate batch accuracies\n",
    "                batch_accuracy_species = batch_correct_species / batch_samples * 100\n",
    "                batch_accuracy_toxicity = batch_correct_toxicity / batch_samples * 100\n",
    "\n",
    "                # Print per-batch metrics\n",
    "                print(f\"Val Batch {batch_idx+1}/{len(val_loader)}: Loss = {loss.item():.4f}, Species Acc = {batch_accuracy_species:.2f}%, Toxicity Acc = {batch_accuracy_toxicity:.2f}%\")\n",
    "\n",
    "                \n",
    "\n",
    "        avg_val_loss = val_running_loss / val_total_samples\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracy_species = val_correct_species / val_total_samples * 100\n",
    "        val_accuracy_toxicity = val_correct_toxicity / val_total_samples * 100\n",
    "        val_accuracies_species.append(val_accuracy_species)\n",
    "        val_accuracies_toxicity.append(val_accuracy_toxicity)\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}, Species Acc: {train_accuracy_species:.2f}%, Toxicity Acc: {train_accuracy_toxicity:.2f}%\")\n",
    "        print(f\"  Val Loss:   {avg_val_loss:.4f}, Species Acc: {val_accuracy_species:.2f}%, Toxicity Acc: {val_accuracy_toxicity:.2f}%\")\n",
    "\n",
    "        if(epoch>10):\n",
    "            if(val_accuracy_species>best_val_acc):\n",
    "                if best_not_saved>5:\n",
    "                    torch.save(model.state_dict(), 'model.pth')\n",
    "                    best_not_saved=0\n",
    "                else:\n",
    "                    best_not_saved+=1\n",
    "                best_val_acc=val_accuracy_species\n",
    "                earlys=0\n",
    "            else:\n",
    "                earlys+=1\n",
    "            if(earlys>max_earlys):\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        # Confusion Matrices\n",
    "        # For Species Classification\n",
    "        species_correct = np.array(val_predictions_species) == np.array(val_targets_species)\n",
    "        species_binary_predictions = species_correct.astype(int)  # 1 if correct, 0 if incorrect\n",
    "        species_binary_targets = np.zeros_like(species_binary_predictions)  # All zeros (1 row for misclassification matrix)\n",
    "\n",
    "        # Plot Confusion Matrix for Species Classification\n",
    "        print(classification_report(species_binary_targets, species_binary_predictions))\n",
    "        print(confusion_matrix(val_targets_species, val_predictions_species))\n",
    "\n",
    "\n",
    "        # For Toxicity Classification\n",
    "        toxicity_predictions = np.array(val_predictions_toxicity)\n",
    "        toxicity_targets = np.array(val_targets_toxicity)\n",
    "\n",
    "        # Plot Confusion Matrix for Toxicity Classification\n",
    "        print(classification_report(toxicity_targets, toxicity_predictions))\n",
    "        print(confusion_matrix(toxicity_targets, toxicity_predictions))\n",
    "\n",
    "\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies_species': train_accuracies_species,\n",
    "        'train_accuracies_toxicity': train_accuracies_toxicity,\n",
    "        'val_accuracies_species': val_accuracies_species,\n",
    "        'val_accuracies_toxicity': val_accuracies_toxicity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/200\n",
      "Train Batch 1/322: Loss = 4.7389, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 2/322: Loss = 4.7843, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 3/322: Loss = 4.7049, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 4/322: Loss = 4.8230, Species Acc = 1.56%, Toxicity Acc = 82.81%\n",
      "Train Batch 5/322: Loss = 4.6977, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 6/322: Loss = 4.7529, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 7/322: Loss = 4.6783, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 8/322: Loss = 4.7140, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 9/322: Loss = 4.7653, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 10/322: Loss = 4.6943, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 11/322: Loss = 4.7223, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 12/322: Loss = 4.7143, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 13/322: Loss = 4.7021, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 14/322: Loss = 4.7941, Species Acc = 0.00%, Toxicity Acc = 85.94%\n",
      "Train Batch 15/322: Loss = 4.6942, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 16/322: Loss = 4.7011, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 17/322: Loss = 4.7382, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 18/322: Loss = 4.7035, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 19/322: Loss = 4.7601, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 20/322: Loss = 4.6866, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 21/322: Loss = 4.7746, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 22/322: Loss = 4.6958, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 23/322: Loss = 4.8047, Species Acc = 0.00%, Toxicity Acc = 85.94%\n",
      "Train Batch 24/322: Loss = 4.6871, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 25/322: Loss = 4.7588, Species Acc = 0.00%, Toxicity Acc = 84.38%\n",
      "Train Batch 26/322: Loss = 4.6714, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 27/322: Loss = 4.7120, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 28/322: Loss = 4.7016, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 29/322: Loss = 4.7235, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 30/322: Loss = 4.6437, Species Acc = 0.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 31/322: Loss = 4.7411, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 32/322: Loss = 4.6617, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 33/322: Loss = 4.6530, Species Acc = 3.12%, Toxicity Acc = 85.94%\n",
      "Train Batch 34/322: Loss = 4.7680, Species Acc = 0.00%, Toxicity Acc = 87.50%\n",
      "Train Batch 35/322: Loss = 4.5280, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 36/322: Loss = 4.6748, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 37/322: Loss = 4.7451, Species Acc = 1.56%, Toxicity Acc = 85.94%\n",
      "Train Batch 38/322: Loss = 4.6318, Species Acc = 0.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 39/322: Loss = 4.6694, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 40/322: Loss = 4.7218, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 41/322: Loss = 4.6517, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 42/322: Loss = 4.6250, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 43/322: Loss = 4.6272, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 44/322: Loss = 4.6986, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 45/322: Loss = 4.7093, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 46/322: Loss = 4.7079, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 47/322: Loss = 4.6934, Species Acc = 1.56%, Toxicity Acc = 87.50%\n",
      "Train Batch 48/322: Loss = 4.6889, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 49/322: Loss = 4.5489, Species Acc = 3.12%, Toxicity Acc = 100.00%\n",
      "Train Batch 50/322: Loss = 4.6811, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 51/322: Loss = 4.6243, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 52/322: Loss = 4.5900, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 53/322: Loss = 4.5983, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 54/322: Loss = 4.6772, Species Acc = 0.00%, Toxicity Acc = 90.62%\n",
      "Train Batch 55/322: Loss = 4.5691, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 56/322: Loss = 4.5940, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 57/322: Loss = 4.7151, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 58/322: Loss = 4.6568, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 59/322: Loss = 4.7510, Species Acc = 0.00%, Toxicity Acc = 87.50%\n",
      "Train Batch 60/322: Loss = 4.6145, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 61/322: Loss = 4.5533, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 62/322: Loss = 4.6295, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 63/322: Loss = 4.7416, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 64/322: Loss = 4.6747, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 65/322: Loss = 4.5893, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 66/322: Loss = 4.5169, Species Acc = 1.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 67/322: Loss = 4.5641, Species Acc = 0.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 68/322: Loss = 4.5838, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 69/322: Loss = 4.5520, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 70/322: Loss = 4.6181, Species Acc = 4.69%, Toxicity Acc = 89.06%\n",
      "Train Batch 71/322: Loss = 4.7512, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 72/322: Loss = 4.5959, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 73/322: Loss = 4.5893, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 74/322: Loss = 4.5864, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 75/322: Loss = 4.5386, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 76/322: Loss = 4.6383, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 77/322: Loss = 4.5191, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 78/322: Loss = 4.5917, Species Acc = 1.56%, Toxicity Acc = 87.50%\n",
      "Train Batch 79/322: Loss = 4.5908, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 80/322: Loss = 4.5579, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 81/322: Loss = 4.6332, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 82/322: Loss = 4.5700, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 83/322: Loss = 4.7352, Species Acc = 4.69%, Toxicity Acc = 89.06%\n",
      "Train Batch 84/322: Loss = 4.6688, Species Acc = 0.00%, Toxicity Acc = 90.62%\n",
      "Train Batch 85/322: Loss = 4.6142, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 86/322: Loss = 4.5892, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 87/322: Loss = 4.5967, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 88/322: Loss = 4.4697, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 89/322: Loss = 4.5446, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 90/322: Loss = 4.5046, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 91/322: Loss = 4.5655, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 92/322: Loss = 4.5927, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 93/322: Loss = 4.6284, Species Acc = 1.56%, Toxicity Acc = 85.94%\n",
      "Train Batch 94/322: Loss = 4.3949, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 95/322: Loss = 4.4970, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 96/322: Loss = 4.4723, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 97/322: Loss = 4.5523, Species Acc = 1.56%, Toxicity Acc = 87.50%\n",
      "Train Batch 98/322: Loss = 4.5518, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 99/322: Loss = 4.5483, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 100/322: Loss = 4.5936, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 101/322: Loss = 4.5291, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 102/322: Loss = 4.5165, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 103/322: Loss = 4.5103, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 104/322: Loss = 4.4235, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 105/322: Loss = 4.5510, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 106/322: Loss = 4.5172, Species Acc = 0.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 107/322: Loss = 4.5260, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 108/322: Loss = 4.6656, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 109/322: Loss = 4.4753, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 110/322: Loss = 4.4989, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 111/322: Loss = 4.6322, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 112/322: Loss = 4.5703, Species Acc = 0.00%, Toxicity Acc = 90.62%\n",
      "Train Batch 113/322: Loss = 4.6486, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 114/322: Loss = 4.5575, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 115/322: Loss = 4.5934, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 116/322: Loss = 4.3783, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 117/322: Loss = 4.4580, Species Acc = 4.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 118/322: Loss = 4.5472, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 119/322: Loss = 4.4909, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 120/322: Loss = 4.5095, Species Acc = 1.56%, Toxicity Acc = 87.50%\n",
      "Train Batch 121/322: Loss = 4.5893, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 122/322: Loss = 4.6073, Species Acc = 6.25%, Toxicity Acc = 84.38%\n",
      "Train Batch 123/322: Loss = 4.4603, Species Acc = 0.00%, Toxicity Acc = 90.62%\n",
      "Train Batch 124/322: Loss = 4.5322, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 125/322: Loss = 4.5484, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 126/322: Loss = 4.4042, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 127/322: Loss = 4.4535, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 128/322: Loss = 4.4428, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 129/322: Loss = 4.5242, Species Acc = 1.56%, Toxicity Acc = 87.50%\n",
      "Train Batch 130/322: Loss = 4.5355, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 131/322: Loss = 4.3999, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 132/322: Loss = 4.3427, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 133/322: Loss = 4.4363, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 134/322: Loss = 4.3735, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 135/322: Loss = 4.4531, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 136/322: Loss = 4.6591, Species Acc = 3.12%, Toxicity Acc = 84.38%\n",
      "Train Batch 137/322: Loss = 4.3575, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 138/322: Loss = 4.3759, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 139/322: Loss = 4.4024, Species Acc = 1.56%, Toxicity Acc = 87.50%\n",
      "Train Batch 140/322: Loss = 4.4000, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 141/322: Loss = 4.3974, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 142/322: Loss = 4.3947, Species Acc = 4.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 143/322: Loss = 4.5157, Species Acc = 4.69%, Toxicity Acc = 85.94%\n",
      "Train Batch 144/322: Loss = 4.4610, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 145/322: Loss = 4.5011, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 146/322: Loss = 4.3688, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 147/322: Loss = 4.3761, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 148/322: Loss = 4.3059, Species Acc = 10.94%, Toxicity Acc = 100.00%\n",
      "Train Batch 149/322: Loss = 4.3316, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 150/322: Loss = 4.2571, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 151/322: Loss = 4.4405, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 152/322: Loss = 4.3294, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 153/322: Loss = 4.5054, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 154/322: Loss = 4.4252, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 155/322: Loss = 4.3129, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 156/322: Loss = 4.3661, Species Acc = 4.69%, Toxicity Acc = 87.50%\n",
      "Train Batch 157/322: Loss = 4.2033, Species Acc = 9.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 158/322: Loss = 4.3579, Species Acc = 0.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 159/322: Loss = 4.2233, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 160/322: Loss = 4.5624, Species Acc = 0.00%, Toxicity Acc = 85.94%\n",
      "Train Batch 161/322: Loss = 4.2765, Species Acc = 7.81%, Toxicity Acc = 89.06%\n",
      "Train Batch 162/322: Loss = 4.2204, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 163/322: Loss = 4.3897, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 164/322: Loss = 4.4012, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 165/322: Loss = 4.3550, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 166/322: Loss = 4.1728, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 167/322: Loss = 4.3730, Species Acc = 6.25%, Toxicity Acc = 84.38%\n",
      "Train Batch 168/322: Loss = 4.1758, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 169/322: Loss = 4.3984, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 170/322: Loss = 4.3059, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 171/322: Loss = 4.3734, Species Acc = 0.00%, Toxicity Acc = 90.62%\n",
      "Train Batch 172/322: Loss = 4.3724, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 173/322: Loss = 4.3749, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 174/322: Loss = 4.4524, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 175/322: Loss = 4.2273, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 176/322: Loss = 4.1266, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 177/322: Loss = 4.2722, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 178/322: Loss = 4.2252, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 179/322: Loss = 4.4284, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 180/322: Loss = 4.2998, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 181/322: Loss = 4.3546, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 182/322: Loss = 4.2410, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 183/322: Loss = 4.2817, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 184/322: Loss = 4.3604, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 185/322: Loss = 4.4101, Species Acc = 3.12%, Toxicity Acc = 85.94%\n",
      "Train Batch 186/322: Loss = 4.2320, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 187/322: Loss = 4.4606, Species Acc = 1.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 188/322: Loss = 4.2117, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 189/322: Loss = 4.2063, Species Acc = 6.25%, Toxicity Acc = 89.06%\n",
      "Train Batch 190/322: Loss = 4.2810, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 191/322: Loss = 4.2589, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 192/322: Loss = 4.3668, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 193/322: Loss = 4.2827, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 194/322: Loss = 4.3519, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 195/322: Loss = 4.4023, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 196/322: Loss = 4.1996, Species Acc = 0.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 197/322: Loss = 4.1776, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 198/322: Loss = 4.3576, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 199/322: Loss = 4.2914, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 200/322: Loss = 4.3220, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 201/322: Loss = 4.5039, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 202/322: Loss = 4.2941, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 203/322: Loss = 4.2531, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 204/322: Loss = 4.2178, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 205/322: Loss = 4.1043, Species Acc = 7.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 206/322: Loss = 4.2535, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 207/322: Loss = 4.2561, Species Acc = 1.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 208/322: Loss = 4.1227, Species Acc = 6.25%, Toxicity Acc = 100.00%\n",
      "Train Batch 209/322: Loss = 4.2193, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 210/322: Loss = 4.1676, Species Acc = 4.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 211/322: Loss = 4.1316, Species Acc = 4.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 212/322: Loss = 4.2090, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 213/322: Loss = 4.2561, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 214/322: Loss = 4.2663, Species Acc = 0.00%, Toxicity Acc = 90.62%\n",
      "Train Batch 215/322: Loss = 4.3857, Species Acc = 4.69%, Toxicity Acc = 89.06%\n",
      "Train Batch 216/322: Loss = 4.0022, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 217/322: Loss = 4.1565, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 218/322: Loss = 4.2855, Species Acc = 3.12%, Toxicity Acc = 87.50%\n",
      "Train Batch 219/322: Loss = 4.0842, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 220/322: Loss = 4.1138, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 221/322: Loss = 4.2919, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 222/322: Loss = 4.2621, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 223/322: Loss = 4.1314, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 224/322: Loss = 4.2688, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 225/322: Loss = 4.2429, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 226/322: Loss = 4.2850, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 227/322: Loss = 4.0553, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 228/322: Loss = 4.0689, Species Acc = 6.25%, Toxicity Acc = 89.06%\n",
      "Train Batch 229/322: Loss = 4.3768, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 230/322: Loss = 4.1706, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 231/322: Loss = 4.1281, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 232/322: Loss = 4.1803, Species Acc = 1.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 233/322: Loss = 3.9561, Species Acc = 3.12%, Toxicity Acc = 100.00%\n",
      "Train Batch 234/322: Loss = 4.0353, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 235/322: Loss = 4.1803, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 236/322: Loss = 4.2319, Species Acc = 0.00%, Toxicity Acc = 90.62%\n",
      "Train Batch 237/322: Loss = 4.0676, Species Acc = 1.56%, Toxicity Acc = 84.38%\n",
      "Train Batch 238/322: Loss = 4.2426, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 239/322: Loss = 4.1115, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 240/322: Loss = 4.0042, Species Acc = 3.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 241/322: Loss = 4.1635, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 242/322: Loss = 3.9951, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 243/322: Loss = 4.1303, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 244/322: Loss = 4.2493, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 245/322: Loss = 4.0442, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 246/322: Loss = 4.2312, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 247/322: Loss = 3.9044, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 248/322: Loss = 4.1102, Species Acc = 1.56%, Toxicity Acc = 85.94%\n",
      "Train Batch 249/322: Loss = 4.3038, Species Acc = 1.56%, Toxicity Acc = 85.94%\n",
      "Train Batch 250/322: Loss = 4.2607, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 251/322: Loss = 4.1987, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 252/322: Loss = 4.0213, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 253/322: Loss = 4.0500, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 254/322: Loss = 4.0820, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 255/322: Loss = 4.0728, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 256/322: Loss = 4.1266, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 257/322: Loss = 4.0044, Species Acc = 1.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 258/322: Loss = 4.0587, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 259/322: Loss = 4.0281, Species Acc = 0.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 260/322: Loss = 4.1110, Species Acc = 4.69%, Toxicity Acc = 84.38%\n",
      "Train Batch 261/322: Loss = 4.2003, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 262/322: Loss = 4.2541, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 263/322: Loss = 4.1034, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 264/322: Loss = 4.1848, Species Acc = 4.69%, Toxicity Acc = 87.50%\n",
      "Train Batch 265/322: Loss = 4.1965, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 266/322: Loss = 4.1542, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 267/322: Loss = 4.2849, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 268/322: Loss = 4.0614, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 269/322: Loss = 4.1383, Species Acc = 1.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 270/322: Loss = 4.1562, Species Acc = 0.00%, Toxicity Acc = 90.62%\n",
      "Train Batch 271/322: Loss = 4.1215, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 272/322: Loss = 4.2054, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 273/322: Loss = 4.0196, Species Acc = 1.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 274/322: Loss = 4.1694, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 275/322: Loss = 4.0735, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 276/322: Loss = 4.2487, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 277/322: Loss = 4.0859, Species Acc = 4.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 278/322: Loss = 3.9349, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 279/322: Loss = 4.0867, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 280/322: Loss = 4.0716, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 281/322: Loss = 4.1042, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 282/322: Loss = 4.0843, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 283/322: Loss = 4.1104, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 284/322: Loss = 4.1835, Species Acc = 7.81%, Toxicity Acc = 90.62%\n",
      "Train Batch 285/322: Loss = 4.2087, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 286/322: Loss = 3.8883, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 287/322: Loss = 4.0565, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 288/322: Loss = 4.2809, Species Acc = 3.12%, Toxicity Acc = 87.50%\n",
      "Train Batch 289/322: Loss = 4.0279, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 290/322: Loss = 4.1941, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 291/322: Loss = 4.0425, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 292/322: Loss = 4.2282, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 293/322: Loss = 3.9794, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Train Batch 294/322: Loss = 3.7917, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 295/322: Loss = 3.8879, Species Acc = 10.94%, Toxicity Acc = 95.31%\n",
      "Train Batch 296/322: Loss = 4.0854, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 297/322: Loss = 4.0375, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 298/322: Loss = 4.1199, Species Acc = 0.00%, Toxicity Acc = 87.50%\n",
      "Train Batch 299/322: Loss = 4.1077, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 300/322: Loss = 3.9902, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 301/322: Loss = 3.9314, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 302/322: Loss = 4.1053, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 303/322: Loss = 3.9875, Species Acc = 3.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 304/322: Loss = 4.0041, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 305/322: Loss = 4.0300, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 306/322: Loss = 4.0818, Species Acc = 7.81%, Toxicity Acc = 93.75%\n",
      "Train Batch 307/322: Loss = 4.1065, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 308/322: Loss = 3.9165, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 309/322: Loss = 4.0679, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 310/322: Loss = 4.1047, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 311/322: Loss = 4.0458, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 312/322: Loss = 4.0562, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 313/322: Loss = 4.3535, Species Acc = 1.56%, Toxicity Acc = 85.94%\n",
      "Train Batch 314/322: Loss = 3.9776, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 315/322: Loss = 4.1826, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 316/322: Loss = 4.1103, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 317/322: Loss = 4.0367, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 318/322: Loss = 3.8827, Species Acc = 7.81%, Toxicity Acc = 90.62%\n",
      "Train Batch 319/322: Loss = 4.0545, Species Acc = 9.38%, Toxicity Acc = 90.62%\n",
      "Train Batch 320/322: Loss = 4.0223, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 321/322: Loss = 4.0650, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 322/322: Loss = 3.9626, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Val Batch 1/80: Loss = 3.9726, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Val Batch 2/80: Loss = 3.9427, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Val Batch 3/80: Loss = 4.0055, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Val Batch 4/80: Loss = 3.9194, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Val Batch 5/80: Loss = 3.8971, Species Acc = 14.06%, Toxicity Acc = 92.19%\n",
      "Val Batch 6/80: Loss = 3.9483, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Val Batch 7/80: Loss = 3.8285, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Val Batch 8/80: Loss = 3.9141, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Val Batch 9/80: Loss = 3.9290, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Val Batch 10/80: Loss = 3.8978, Species Acc = 3.12%, Toxicity Acc = 85.94%\n",
      "Val Batch 11/80: Loss = 3.8528, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Val Batch 12/80: Loss = 3.8830, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Val Batch 13/80: Loss = 4.0731, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Val Batch 14/80: Loss = 4.0092, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Val Batch 15/80: Loss = 3.9368, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Val Batch 16/80: Loss = 3.7806, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Val Batch 17/80: Loss = 3.8998, Species Acc = 7.81%, Toxicity Acc = 93.75%\n",
      "Val Batch 18/80: Loss = 4.0381, Species Acc = 4.69%, Toxicity Acc = 87.50%\n",
      "Val Batch 19/80: Loss = 3.8332, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Val Batch 20/80: Loss = 3.8263, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Val Batch 21/80: Loss = 3.7542, Species Acc = 3.12%, Toxicity Acc = 98.44%\n",
      "Val Batch 22/80: Loss = 3.9897, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Val Batch 23/80: Loss = 3.9140, Species Acc = 4.69%, Toxicity Acc = 96.88%\n",
      "Val Batch 24/80: Loss = 3.9851, Species Acc = 7.81%, Toxicity Acc = 98.44%\n",
      "Val Batch 25/80: Loss = 3.8455, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Val Batch 26/80: Loss = 3.9676, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Val Batch 27/80: Loss = 3.8953, Species Acc = 4.69%, Toxicity Acc = 100.00%\n",
      "Val Batch 28/80: Loss = 4.0918, Species Acc = 4.69%, Toxicity Acc = 89.06%\n",
      "Val Batch 29/80: Loss = 4.0581, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Val Batch 30/80: Loss = 3.8861, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Val Batch 31/80: Loss = 3.8570, Species Acc = 10.94%, Toxicity Acc = 95.31%\n",
      "Val Batch 32/80: Loss = 3.9090, Species Acc = 6.25%, Toxicity Acc = 98.44%\n",
      "Val Batch 33/80: Loss = 3.9498, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Val Batch 34/80: Loss = 3.9461, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Val Batch 35/80: Loss = 3.9062, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Val Batch 36/80: Loss = 3.9380, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Val Batch 37/80: Loss = 3.9183, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Val Batch 38/80: Loss = 3.9722, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Val Batch 39/80: Loss = 3.9251, Species Acc = 12.50%, Toxicity Acc = 93.75%\n",
      "Val Batch 40/80: Loss = 3.9587, Species Acc = 10.94%, Toxicity Acc = 92.19%\n",
      "Val Batch 41/80: Loss = 3.8709, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Val Batch 42/80: Loss = 3.9638, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Val Batch 43/80: Loss = 3.7703, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Val Batch 44/80: Loss = 3.8106, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Val Batch 45/80: Loss = 4.0342, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Val Batch 46/80: Loss = 3.8437, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Val Batch 47/80: Loss = 3.8220, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Val Batch 48/80: Loss = 3.9572, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Val Batch 49/80: Loss = 3.8434, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Val Batch 50/80: Loss = 3.7471, Species Acc = 7.81%, Toxicity Acc = 98.44%\n",
      "Val Batch 51/80: Loss = 3.9592, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Val Batch 52/80: Loss = 3.9250, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Val Batch 53/80: Loss = 3.8093, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Val Batch 54/80: Loss = 3.7896, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Val Batch 55/80: Loss = 3.9539, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Val Batch 56/80: Loss = 3.7720, Species Acc = 10.94%, Toxicity Acc = 92.19%\n",
      "Val Batch 57/80: Loss = 3.8937, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Val Batch 58/80: Loss = 4.0560, Species Acc = 10.94%, Toxicity Acc = 89.06%\n",
      "Val Batch 59/80: Loss = 3.9363, Species Acc = 7.81%, Toxicity Acc = 98.44%\n",
      "Val Batch 60/80: Loss = 3.7767, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Val Batch 61/80: Loss = 3.9065, Species Acc = 7.81%, Toxicity Acc = 93.75%\n",
      "Val Batch 62/80: Loss = 3.9724, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Val Batch 63/80: Loss = 3.8488, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Val Batch 64/80: Loss = 4.0489, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Val Batch 65/80: Loss = 3.9498, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Val Batch 66/80: Loss = 3.8483, Species Acc = 9.38%, Toxicity Acc = 96.88%\n",
      "Val Batch 67/80: Loss = 4.0063, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Val Batch 68/80: Loss = 4.0724, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Val Batch 69/80: Loss = 3.9124, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Val Batch 70/80: Loss = 4.0025, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Val Batch 71/80: Loss = 3.9264, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Val Batch 72/80: Loss = 4.0141, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Val Batch 73/80: Loss = 3.9088, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Val Batch 74/80: Loss = 3.9963, Species Acc = 0.00%, Toxicity Acc = 90.62%\n",
      "Val Batch 75/80: Loss = 4.0492, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Val Batch 76/80: Loss = 3.9114, Species Acc = 6.25%, Toxicity Acc = 89.06%\n",
      "Val Batch 77/80: Loss = 3.9085, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Val Batch 78/80: Loss = 3.9554, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Val Batch 79/80: Loss = 3.9733, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Val Batch 80/80: Loss = 3.9525, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "\n",
      "Epoch 1/200 Summary:\n",
      "  Train Loss: 4.3715, Species Acc: 2.93%, Toxicity Acc: 92.38%\n",
      "  Val Loss:   3.9219, Species Acc: 6.04%, Toxicity Acc: 93.61%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      5120\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94      5120\n",
      "   macro avg       0.50      0.47      0.48      5120\n",
      "weighted avg       1.00      0.94      0.97      5120\n",
      "\n",
      "[[ 0 34  0 ...  0  0  0]\n",
      " [ 0 51  0 ...  0  0  0]\n",
      " [ 3 22  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0 36  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      4693\n",
      "           1       0.78      0.32      0.46       427\n",
      "\n",
      "    accuracy                           0.94      5120\n",
      "   macro avg       0.86      0.66      0.71      5120\n",
      "weighted avg       0.93      0.94      0.92      5120\n",
      "\n",
      "[[4655   38]\n",
      " [ 289  138]]\n",
      "\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 1/322: Loss = 3.8059, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 2/322: Loss = 4.0774, Species Acc = 0.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 3/322: Loss = 4.0251, Species Acc = 7.81%, Toxicity Acc = 90.62%\n",
      "Train Batch 4/322: Loss = 3.9504, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 5/322: Loss = 3.8671, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 6/322: Loss = 3.8353, Species Acc = 10.94%, Toxicity Acc = 100.00%\n",
      "Train Batch 7/322: Loss = 3.8715, Species Acc = 1.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 8/322: Loss = 4.0304, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 9/322: Loss = 4.0030, Species Acc = 1.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 10/322: Loss = 3.8378, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 11/322: Loss = 3.8868, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 12/322: Loss = 3.8126, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 13/322: Loss = 3.9911, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 14/322: Loss = 3.8289, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 15/322: Loss = 3.8707, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 16/322: Loss = 4.0715, Species Acc = 7.81%, Toxicity Acc = 84.38%\n",
      "Train Batch 17/322: Loss = 3.7986, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 18/322: Loss = 3.8645, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 19/322: Loss = 3.9497, Species Acc = 7.81%, Toxicity Acc = 90.62%\n",
      "Train Batch 20/322: Loss = 3.9214, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 21/322: Loss = 3.6925, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 22/322: Loss = 3.9476, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Train Batch 23/322: Loss = 3.8450, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 24/322: Loss = 3.9762, Species Acc = 1.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 25/322: Loss = 3.9621, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 26/322: Loss = 3.8577, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 27/322: Loss = 3.7130, Species Acc = 4.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 28/322: Loss = 4.0523, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 29/322: Loss = 3.6744, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 30/322: Loss = 3.8712, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 31/322: Loss = 3.8520, Species Acc = 3.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 32/322: Loss = 3.8857, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 33/322: Loss = 4.1205, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 34/322: Loss = 3.8474, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 35/322: Loss = 3.8451, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 36/322: Loss = 3.9935, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 37/322: Loss = 3.8775, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 38/322: Loss = 4.1579, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 39/322: Loss = 3.6555, Species Acc = 4.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 40/322: Loss = 3.9118, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 41/322: Loss = 4.0463, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 42/322: Loss = 3.8543, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 43/322: Loss = 3.8146, Species Acc = 10.94%, Toxicity Acc = 92.19%\n",
      "Train Batch 44/322: Loss = 3.9502, Species Acc = 1.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 45/322: Loss = 3.9460, Species Acc = 1.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 46/322: Loss = 4.0231, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 47/322: Loss = 4.0223, Species Acc = 7.81%, Toxicity Acc = 89.06%\n",
      "Train Batch 48/322: Loss = 4.2348, Species Acc = 3.12%, Toxicity Acc = 89.06%\n",
      "Train Batch 49/322: Loss = 3.9621, Species Acc = 7.81%, Toxicity Acc = 93.75%\n",
      "Train Batch 50/322: Loss = 3.8908, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 51/322: Loss = 3.9799, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 52/322: Loss = 3.8127, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Train Batch 53/322: Loss = 3.8055, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 54/322: Loss = 3.8665, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 55/322: Loss = 4.0399, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 56/322: Loss = 3.8253, Species Acc = 12.50%, Toxicity Acc = 93.75%\n",
      "Train Batch 57/322: Loss = 3.7479, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 58/322: Loss = 4.0395, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 59/322: Loss = 3.8529, Species Acc = 9.38%, Toxicity Acc = 87.50%\n",
      "Train Batch 60/322: Loss = 3.9401, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 61/322: Loss = 3.6645, Species Acc = 12.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 62/322: Loss = 3.8201, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 63/322: Loss = 4.0274, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 64/322: Loss = 3.7402, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 65/322: Loss = 3.8435, Species Acc = 7.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 66/322: Loss = 3.8831, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 67/322: Loss = 3.8035, Species Acc = 3.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 68/322: Loss = 3.8256, Species Acc = 1.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 69/322: Loss = 3.8165, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 70/322: Loss = 3.7827, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 71/322: Loss = 3.7628, Species Acc = 4.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 72/322: Loss = 3.7647, Species Acc = 1.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 73/322: Loss = 3.8674, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 74/322: Loss = 3.9842, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 75/322: Loss = 4.0301, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 76/322: Loss = 3.7715, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 77/322: Loss = 3.6631, Species Acc = 10.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 78/322: Loss = 4.0165, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 79/322: Loss = 3.8796, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 80/322: Loss = 3.8391, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 81/322: Loss = 3.6134, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 82/322: Loss = 3.9049, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 83/322: Loss = 3.6686, Species Acc = 10.94%, Toxicity Acc = 95.31%\n",
      "Train Batch 84/322: Loss = 3.7880, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 85/322: Loss = 3.8872, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 86/322: Loss = 3.9433, Species Acc = 7.81%, Toxicity Acc = 89.06%\n",
      "Train Batch 87/322: Loss = 3.6672, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Train Batch 88/322: Loss = 3.7744, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 89/322: Loss = 3.9207, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 90/322: Loss = 3.7421, Species Acc = 4.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 91/322: Loss = 3.8619, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 92/322: Loss = 3.6467, Species Acc = 6.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 93/322: Loss = 3.7467, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 94/322: Loss = 3.8274, Species Acc = 12.50%, Toxicity Acc = 89.06%\n",
      "Train Batch 95/322: Loss = 3.6385, Species Acc = 9.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 96/322: Loss = 3.7133, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 97/322: Loss = 3.9175, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 98/322: Loss = 3.8192, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 99/322: Loss = 4.0600, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 100/322: Loss = 3.8384, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 101/322: Loss = 3.8632, Species Acc = 0.00%, Toxicity Acc = 89.06%\n",
      "Train Batch 102/322: Loss = 3.8958, Species Acc = 3.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 103/322: Loss = 3.8393, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 104/322: Loss = 3.7402, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 105/322: Loss = 3.7844, Species Acc = 3.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 106/322: Loss = 3.7721, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 107/322: Loss = 3.8197, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 108/322: Loss = 3.7575, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 109/322: Loss = 3.8766, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 110/322: Loss = 3.8345, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Train Batch 111/322: Loss = 3.8945, Species Acc = 0.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 112/322: Loss = 3.6784, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 113/322: Loss = 3.8164, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 114/322: Loss = 3.7149, Species Acc = 7.81%, Toxicity Acc = 89.06%\n",
      "Train Batch 115/322: Loss = 3.5588, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 116/322: Loss = 3.8112, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 117/322: Loss = 3.9114, Species Acc = 15.62%, Toxicity Acc = 92.19%\n",
      "Train Batch 118/322: Loss = 3.9498, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 119/322: Loss = 3.7178, Species Acc = 6.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 120/322: Loss = 3.8555, Species Acc = 1.56%, Toxicity Acc = 89.06%\n",
      "Train Batch 121/322: Loss = 3.8418, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 122/322: Loss = 3.7979, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 123/322: Loss = 3.6789, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 124/322: Loss = 3.5821, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 125/322: Loss = 3.7660, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 126/322: Loss = 3.7437, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 127/322: Loss = 3.6393, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 128/322: Loss = 3.6125, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 129/322: Loss = 3.9383, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 130/322: Loss = 3.6589, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 131/322: Loss = 3.8493, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 132/322: Loss = 3.5578, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 133/322: Loss = 3.6702, Species Acc = 12.50%, Toxicity Acc = 89.06%\n",
      "Train Batch 134/322: Loss = 3.5921, Species Acc = 9.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 135/322: Loss = 3.7017, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 136/322: Loss = 4.0036, Species Acc = 4.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 137/322: Loss = 3.6431, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 138/322: Loss = 3.6939, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 139/322: Loss = 3.7229, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 140/322: Loss = 3.6005, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 141/322: Loss = 3.6612, Species Acc = 3.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 142/322: Loss = 3.8442, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 143/322: Loss = 3.5696, Species Acc = 12.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 144/322: Loss = 3.5968, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 145/322: Loss = 3.5890, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 146/322: Loss = 3.7340, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 147/322: Loss = 3.5388, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 148/322: Loss = 3.9747, Species Acc = 3.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 149/322: Loss = 3.3582, Species Acc = 9.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 150/322: Loss = 3.5228, Species Acc = 10.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 151/322: Loss = 3.7280, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 152/322: Loss = 4.3218, Species Acc = 1.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 153/322: Loss = 3.5626, Species Acc = 9.38%, Toxicity Acc = 87.50%\n",
      "Train Batch 154/322: Loss = 3.5827, Species Acc = 15.62%, Toxicity Acc = 92.19%\n",
      "Train Batch 155/322: Loss = 3.2850, Species Acc = 17.19%, Toxicity Acc = 93.75%\n",
      "Train Batch 156/322: Loss = 3.7394, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 157/322: Loss = 3.6028, Species Acc = 18.75%, Toxicity Acc = 93.75%\n",
      "Train Batch 158/322: Loss = 3.8385, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 159/322: Loss = 3.6588, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 160/322: Loss = 3.7247, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 161/322: Loss = 3.8329, Species Acc = 7.81%, Toxicity Acc = 90.62%\n",
      "Train Batch 162/322: Loss = 3.5557, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 163/322: Loss = 3.6645, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 164/322: Loss = 3.7549, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 165/322: Loss = 3.4727, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 166/322: Loss = 3.4046, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Train Batch 167/322: Loss = 3.8310, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 168/322: Loss = 3.7537, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 169/322: Loss = 3.6461, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 170/322: Loss = 3.6174, Species Acc = 6.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 171/322: Loss = 3.4735, Species Acc = 12.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 172/322: Loss = 3.5512, Species Acc = 6.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 173/322: Loss = 3.7490, Species Acc = 15.62%, Toxicity Acc = 90.62%\n",
      "Train Batch 174/322: Loss = 3.5625, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 175/322: Loss = 3.4380, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 176/322: Loss = 3.5728, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 177/322: Loss = 3.8082, Species Acc = 4.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 178/322: Loss = 3.6675, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 179/322: Loss = 3.7232, Species Acc = 12.50%, Toxicity Acc = 89.06%\n",
      "Train Batch 180/322: Loss = 3.6810, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 181/322: Loss = 3.6963, Species Acc = 4.69%, Toxicity Acc = 89.06%\n",
      "Train Batch 182/322: Loss = 3.6698, Species Acc = 4.69%, Toxicity Acc = 89.06%\n",
      "Train Batch 183/322: Loss = 3.5198, Species Acc = 9.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 184/322: Loss = 3.5450, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 185/322: Loss = 3.6018, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 186/322: Loss = 3.5552, Species Acc = 10.94%, Toxicity Acc = 95.31%\n",
      "Train Batch 187/322: Loss = 3.9636, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 188/322: Loss = 3.8667, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 189/322: Loss = 3.5908, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 190/322: Loss = 3.7853, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 191/322: Loss = 3.5905, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 192/322: Loss = 3.6267, Species Acc = 14.06%, Toxicity Acc = 92.19%\n",
      "Train Batch 193/322: Loss = 3.5437, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 194/322: Loss = 3.8834, Species Acc = 7.81%, Toxicity Acc = 90.62%\n",
      "Train Batch 195/322: Loss = 3.5991, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 196/322: Loss = 3.3982, Species Acc = 14.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 197/322: Loss = 3.5471, Species Acc = 9.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 198/322: Loss = 3.6291, Species Acc = 9.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 199/322: Loss = 3.5103, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 200/322: Loss = 3.8083, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 201/322: Loss = 3.4527, Species Acc = 10.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 202/322: Loss = 3.4079, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 203/322: Loss = 3.6719, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 204/322: Loss = 3.6500, Species Acc = 4.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 205/322: Loss = 3.5830, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 206/322: Loss = 3.6702, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Train Batch 207/322: Loss = 3.6496, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 208/322: Loss = 3.6301, Species Acc = 10.94%, Toxicity Acc = 92.19%\n",
      "Train Batch 209/322: Loss = 3.4407, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 210/322: Loss = 3.6202, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 211/322: Loss = 3.3038, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 212/322: Loss = 3.7025, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 213/322: Loss = 3.6749, Species Acc = 7.81%, Toxicity Acc = 93.75%\n",
      "Train Batch 214/322: Loss = 3.7063, Species Acc = 6.25%, Toxicity Acc = 100.00%\n",
      "Train Batch 215/322: Loss = 3.2778, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 216/322: Loss = 3.4271, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 217/322: Loss = 3.8054, Species Acc = 4.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 218/322: Loss = 3.7895, Species Acc = 7.81%, Toxicity Acc = 93.75%\n",
      "Train Batch 219/322: Loss = 3.7612, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 220/322: Loss = 3.8456, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 221/322: Loss = 3.7484, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 222/322: Loss = 3.5463, Species Acc = 12.50%, Toxicity Acc = 89.06%\n",
      "Train Batch 223/322: Loss = 3.5828, Species Acc = 14.06%, Toxicity Acc = 93.75%\n",
      "Train Batch 224/322: Loss = 3.5463, Species Acc = 14.06%, Toxicity Acc = 93.75%\n",
      "Train Batch 225/322: Loss = 3.3953, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 226/322: Loss = 3.6215, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 227/322: Loss = 3.3521, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 228/322: Loss = 3.8796, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 229/322: Loss = 3.5878, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 230/322: Loss = 3.5960, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 231/322: Loss = 3.7214, Species Acc = 4.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 232/322: Loss = 3.4225, Species Acc = 18.75%, Toxicity Acc = 92.19%\n",
      "Train Batch 233/322: Loss = 3.4068, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 234/322: Loss = 3.5391, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 235/322: Loss = 3.4149, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 236/322: Loss = 3.7541, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 237/322: Loss = 3.5790, Species Acc = 9.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 238/322: Loss = 3.3083, Species Acc = 7.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 239/322: Loss = 3.5804, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 240/322: Loss = 3.3253, Species Acc = 15.62%, Toxicity Acc = 100.00%\n",
      "Train Batch 241/322: Loss = 3.4799, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 242/322: Loss = 3.5253, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Train Batch 243/322: Loss = 3.3762, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 244/322: Loss = 3.7745, Species Acc = 10.94%, Toxicity Acc = 92.19%\n",
      "Train Batch 245/322: Loss = 3.5007, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 246/322: Loss = 3.7193, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 247/322: Loss = 3.5959, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 248/322: Loss = 3.5464, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 249/322: Loss = 3.5367, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 250/322: Loss = 3.4228, Species Acc = 15.62%, Toxicity Acc = 90.62%\n",
      "Train Batch 251/322: Loss = 3.4552, Species Acc = 10.94%, Toxicity Acc = 87.50%\n",
      "Train Batch 252/322: Loss = 3.3244, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 253/322: Loss = 3.5012, Species Acc = 6.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 254/322: Loss = 3.4594, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 255/322: Loss = 3.3775, Species Acc = 14.06%, Toxicity Acc = 90.62%\n",
      "Train Batch 256/322: Loss = 3.3264, Species Acc = 7.81%, Toxicity Acc = 93.75%\n",
      "Train Batch 257/322: Loss = 3.8621, Species Acc = 3.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 258/322: Loss = 3.5818, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Train Batch 259/322: Loss = 3.5566, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Train Batch 260/322: Loss = 3.5451, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 261/322: Loss = 3.7053, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 262/322: Loss = 3.5317, Species Acc = 7.81%, Toxicity Acc = 93.75%\n",
      "Train Batch 263/322: Loss = 3.5245, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 264/322: Loss = 3.3899, Species Acc = 9.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 265/322: Loss = 3.4818, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 266/322: Loss = 3.5200, Species Acc = 4.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 267/322: Loss = 3.4576, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 268/322: Loss = 3.3834, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Train Batch 269/322: Loss = 3.6111, Species Acc = 6.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 270/322: Loss = 3.7500, Species Acc = 4.69%, Toxicity Acc = 87.50%\n",
      "Train Batch 271/322: Loss = 3.4960, Species Acc = 14.06%, Toxicity Acc = 90.62%\n",
      "Train Batch 272/322: Loss = 3.5728, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 273/322: Loss = 3.6985, Species Acc = 4.69%, Toxicity Acc = 90.62%\n",
      "Train Batch 274/322: Loss = 3.5838, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 275/322: Loss = 3.5580, Species Acc = 10.94%, Toxicity Acc = 90.62%\n",
      "Train Batch 276/322: Loss = 3.5541, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Train Batch 277/322: Loss = 3.5342, Species Acc = 10.94%, Toxicity Acc = 92.19%\n",
      "Train Batch 278/322: Loss = 3.4847, Species Acc = 6.25%, Toxicity Acc = 89.06%\n",
      "Train Batch 279/322: Loss = 3.4288, Species Acc = 10.94%, Toxicity Acc = 92.19%\n",
      "Train Batch 280/322: Loss = 3.4176, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 281/322: Loss = 3.4895, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Train Batch 282/322: Loss = 3.4039, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 283/322: Loss = 3.1974, Species Acc = 14.06%, Toxicity Acc = 100.00%\n",
      "Train Batch 284/322: Loss = 3.5172, Species Acc = 10.94%, Toxicity Acc = 89.06%\n",
      "Train Batch 285/322: Loss = 3.5596, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 286/322: Loss = 3.5511, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 287/322: Loss = 3.2125, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 288/322: Loss = 3.4618, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 289/322: Loss = 3.3404, Species Acc = 15.62%, Toxicity Acc = 100.00%\n",
      "Train Batch 290/322: Loss = 3.4265, Species Acc = 7.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 291/322: Loss = 3.5961, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 292/322: Loss = 3.2996, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 293/322: Loss = 3.3513, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 294/322: Loss = 3.5046, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 295/322: Loss = 3.3570, Species Acc = 14.06%, Toxicity Acc = 93.75%\n",
      "Train Batch 296/322: Loss = 3.5190, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 297/322: Loss = 3.3367, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 298/322: Loss = 3.4243, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 299/322: Loss = 3.5670, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Train Batch 300/322: Loss = 3.2726, Species Acc = 9.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 301/322: Loss = 3.1778, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 302/322: Loss = 3.5199, Species Acc = 3.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 303/322: Loss = 3.4431, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 304/322: Loss = 3.3114, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Train Batch 305/322: Loss = 3.2708, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Train Batch 306/322: Loss = 3.3213, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 307/322: Loss = 3.4505, Species Acc = 12.50%, Toxicity Acc = 90.62%\n",
      "Train Batch 308/322: Loss = 3.6582, Species Acc = 4.69%, Toxicity Acc = 89.06%\n",
      "Train Batch 309/322: Loss = 3.3242, Species Acc = 15.62%, Toxicity Acc = 90.62%\n",
      "Train Batch 310/322: Loss = 3.4320, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 311/322: Loss = 3.6044, Species Acc = 12.50%, Toxicity Acc = 90.62%\n",
      "Train Batch 312/322: Loss = 3.2606, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 313/322: Loss = 3.5062, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 314/322: Loss = 3.3943, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Train Batch 315/322: Loss = 3.3992, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 316/322: Loss = 3.3217, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 317/322: Loss = 3.4080, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 318/322: Loss = 3.3693, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 319/322: Loss = 3.4500, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 320/322: Loss = 3.3222, Species Acc = 20.31%, Toxicity Acc = 95.31%\n",
      "Train Batch 321/322: Loss = 3.4588, Species Acc = 10.94%, Toxicity Acc = 95.31%\n",
      "Train Batch 322/322: Loss = 3.1912, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Val Batch 1/80: Loss = 3.2540, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Val Batch 2/80: Loss = 3.1988, Species Acc = 23.44%, Toxicity Acc = 93.75%\n",
      "Val Batch 3/80: Loss = 3.3596, Species Acc = 18.75%, Toxicity Acc = 92.19%\n",
      "Val Batch 4/80: Loss = 3.3111, Species Acc = 15.62%, Toxicity Acc = 93.75%\n",
      "Val Batch 5/80: Loss = 3.5179, Species Acc = 14.06%, Toxicity Acc = 92.19%\n",
      "Val Batch 6/80: Loss = 3.3152, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Val Batch 7/80: Loss = 3.2325, Species Acc = 20.31%, Toxicity Acc = 96.88%\n",
      "Val Batch 8/80: Loss = 3.5721, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Val Batch 9/80: Loss = 3.3839, Species Acc = 6.25%, Toxicity Acc = 95.31%\n",
      "Val Batch 10/80: Loss = 3.4082, Species Acc = 9.38%, Toxicity Acc = 90.62%\n",
      "Val Batch 11/80: Loss = 3.1189, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Val Batch 12/80: Loss = 3.2933, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Val Batch 13/80: Loss = 3.4052, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Val Batch 14/80: Loss = 3.3909, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Val Batch 15/80: Loss = 3.2216, Species Acc = 20.31%, Toxicity Acc = 90.62%\n",
      "Val Batch 16/80: Loss = 3.4205, Species Acc = 15.62%, Toxicity Acc = 90.62%\n",
      "Val Batch 17/80: Loss = 3.0186, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Val Batch 18/80: Loss = 3.4133, Species Acc = 20.31%, Toxicity Acc = 85.94%\n",
      "Val Batch 19/80: Loss = 3.4542, Species Acc = 7.81%, Toxicity Acc = 93.75%\n",
      "Val Batch 20/80: Loss = 3.2805, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Val Batch 21/80: Loss = 3.2305, Species Acc = 9.38%, Toxicity Acc = 98.44%\n",
      "Val Batch 22/80: Loss = 3.3646, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Val Batch 23/80: Loss = 3.3432, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Val Batch 24/80: Loss = 3.2393, Species Acc = 12.50%, Toxicity Acc = 98.44%\n",
      "Val Batch 25/80: Loss = 3.0636, Species Acc = 17.19%, Toxicity Acc = 93.75%\n",
      "Val Batch 26/80: Loss = 3.4016, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Val Batch 27/80: Loss = 3.2852, Species Acc = 14.06%, Toxicity Acc = 100.00%\n",
      "Val Batch 28/80: Loss = 3.3440, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Val Batch 29/80: Loss = 3.5008, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Val Batch 30/80: Loss = 3.1779, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Val Batch 31/80: Loss = 3.3687, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Val Batch 32/80: Loss = 3.2888, Species Acc = 9.38%, Toxicity Acc = 98.44%\n",
      "Val Batch 33/80: Loss = 3.4161, Species Acc = 20.31%, Toxicity Acc = 89.06%\n",
      "Val Batch 34/80: Loss = 3.1730, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Val Batch 35/80: Loss = 3.3680, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Val Batch 36/80: Loss = 3.2605, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Val Batch 37/80: Loss = 3.3180, Species Acc = 10.94%, Toxicity Acc = 95.31%\n",
      "Val Batch 38/80: Loss = 3.3487, Species Acc = 20.31%, Toxicity Acc = 96.88%\n",
      "Val Batch 39/80: Loss = 3.3557, Species Acc = 18.75%, Toxicity Acc = 90.62%\n",
      "Val Batch 40/80: Loss = 3.2255, Species Acc = 23.44%, Toxicity Acc = 92.19%\n",
      "Val Batch 41/80: Loss = 3.2011, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Val Batch 42/80: Loss = 3.4506, Species Acc = 23.44%, Toxicity Acc = 92.19%\n",
      "Val Batch 43/80: Loss = 3.1731, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Val Batch 44/80: Loss = 3.1887, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Val Batch 45/80: Loss = 3.2931, Species Acc = 14.06%, Toxicity Acc = 92.19%\n",
      "Val Batch 46/80: Loss = 3.3301, Species Acc = 10.94%, Toxicity Acc = 95.31%\n",
      "Val Batch 47/80: Loss = 3.2199, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Val Batch 48/80: Loss = 3.3528, Species Acc = 9.38%, Toxicity Acc = 92.19%\n",
      "Val Batch 49/80: Loss = 3.0147, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Val Batch 50/80: Loss = 3.2299, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Val Batch 51/80: Loss = 3.2795, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Val Batch 52/80: Loss = 3.3357, Species Acc = 17.19%, Toxicity Acc = 93.75%\n",
      "Val Batch 53/80: Loss = 3.3382, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Val Batch 54/80: Loss = 3.2791, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Val Batch 55/80: Loss = 3.4151, Species Acc = 15.62%, Toxicity Acc = 92.19%\n",
      "Val Batch 56/80: Loss = 3.0262, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Val Batch 57/80: Loss = 3.3520, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Val Batch 58/80: Loss = 3.2468, Species Acc = 25.00%, Toxicity Acc = 90.62%\n",
      "Val Batch 59/80: Loss = 3.2809, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Val Batch 60/80: Loss = 3.2346, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Val Batch 61/80: Loss = 3.4998, Species Acc = 6.25%, Toxicity Acc = 92.19%\n",
      "Val Batch 62/80: Loss = 3.3124, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Val Batch 63/80: Loss = 3.2239, Species Acc = 18.75%, Toxicity Acc = 95.31%\n",
      "Val Batch 64/80: Loss = 3.3699, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Val Batch 65/80: Loss = 3.1191, Species Acc = 14.06%, Toxicity Acc = 93.75%\n",
      "Val Batch 66/80: Loss = 3.4252, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Val Batch 67/80: Loss = 3.5052, Species Acc = 14.06%, Toxicity Acc = 92.19%\n",
      "Val Batch 68/80: Loss = 3.5216, Species Acc = 12.50%, Toxicity Acc = 93.75%\n",
      "Val Batch 69/80: Loss = 3.4141, Species Acc = 18.75%, Toxicity Acc = 95.31%\n",
      "Val Batch 70/80: Loss = 3.3339, Species Acc = 17.19%, Toxicity Acc = 93.75%\n",
      "Val Batch 71/80: Loss = 3.3423, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Val Batch 72/80: Loss = 3.4900, Species Acc = 17.19%, Toxicity Acc = 93.75%\n",
      "Val Batch 73/80: Loss = 3.3183, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Val Batch 74/80: Loss = 3.3810, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Val Batch 75/80: Loss = 3.5086, Species Acc = 14.06%, Toxicity Acc = 90.62%\n",
      "Val Batch 76/80: Loss = 3.3403, Species Acc = 14.06%, Toxicity Acc = 92.19%\n",
      "Val Batch 77/80: Loss = 3.2761, Species Acc = 12.50%, Toxicity Acc = 93.75%\n",
      "Val Batch 78/80: Loss = 3.2980, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Val Batch 79/80: Loss = 3.3378, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Val Batch 80/80: Loss = 3.3151, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "\n",
      "Epoch 2/200 Summary:\n",
      "  Train Loss: 3.6773, Species Acc: 8.15%, Toxicity Acc: 94.28%\n",
      "  Val Loss:   3.3152, Species Acc: 14.73%, Toxicity Acc: 94.36%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92      5120\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.85      5120\n",
      "   macro avg       0.50      0.43      0.46      5120\n",
      "weighted avg       1.00      0.85      0.92      5120\n",
      "\n",
      "[[ 0 11  0 ...  0  0  0]\n",
      " [ 0 35  2 ...  0  0  0]\n",
      " [ 0  3  3 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  6  0  0]\n",
      " [ 0  9  3 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4693\n",
      "           1       0.87      0.38      0.53       427\n",
      "\n",
      "    accuracy                           0.94      5120\n",
      "   macro avg       0.91      0.69      0.75      5120\n",
      "weighted avg       0.94      0.94      0.93      5120\n",
      "\n",
      "[[4669   24]\n",
      " [ 265  162]]\n",
      "\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 1/322: Loss = 3.2106, Species Acc = 14.06%, Toxicity Acc = 93.75%\n",
      "Train Batch 2/322: Loss = 3.4851, Species Acc = 10.94%, Toxicity Acc = 95.31%\n",
      "Train Batch 3/322: Loss = 3.4927, Species Acc = 7.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 4/322: Loss = 3.2062, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 5/322: Loss = 3.1456, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 6/322: Loss = 3.2915, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 7/322: Loss = 3.4111, Species Acc = 6.25%, Toxicity Acc = 90.62%\n",
      "Train Batch 8/322: Loss = 3.1772, Species Acc = 15.62%, Toxicity Acc = 100.00%\n",
      "Train Batch 9/322: Loss = 3.3843, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 10/322: Loss = 3.1478, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 11/322: Loss = 3.2767, Species Acc = 7.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 12/322: Loss = 3.1780, Species Acc = 14.06%, Toxicity Acc = 100.00%\n",
      "Train Batch 13/322: Loss = 3.0818, Species Acc = 17.19%, Toxicity Acc = 98.44%\n",
      "Train Batch 14/322: Loss = 3.1624, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 15/322: Loss = 3.3081, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 16/322: Loss = 3.0309, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 17/322: Loss = 3.3969, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 18/322: Loss = 3.2506, Species Acc = 12.50%, Toxicity Acc = 89.06%\n",
      "Train Batch 19/322: Loss = 3.3500, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 20/322: Loss = 3.0493, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 21/322: Loss = 3.0519, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 22/322: Loss = 3.1873, Species Acc = 18.75%, Toxicity Acc = 93.75%\n",
      "Train Batch 23/322: Loss = 3.1710, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 24/322: Loss = 3.0475, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 25/322: Loss = 3.3339, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 26/322: Loss = 3.3322, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Train Batch 27/322: Loss = 3.2527, Species Acc = 6.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 28/322: Loss = 3.3246, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Train Batch 29/322: Loss = 3.0460, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 30/322: Loss = 3.0875, Species Acc = 15.62%, Toxicity Acc = 93.75%\n",
      "Train Batch 31/322: Loss = 3.1243, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 32/322: Loss = 3.1124, Species Acc = 10.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 33/322: Loss = 3.4142, Species Acc = 4.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 34/322: Loss = 3.1682, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 35/322: Loss = 3.0624, Species Acc = 14.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 36/322: Loss = 3.1346, Species Acc = 18.75%, Toxicity Acc = 95.31%\n",
      "Train Batch 37/322: Loss = 3.0609, Species Acc = 10.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 38/322: Loss = 3.0996, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 39/322: Loss = 3.0808, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 40/322: Loss = 2.8504, Species Acc = 17.19%, Toxicity Acc = 98.44%\n",
      "Train Batch 41/322: Loss = 3.2869, Species Acc = 12.50%, Toxicity Acc = 100.00%\n",
      "Train Batch 42/322: Loss = 3.1249, Species Acc = 7.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 43/322: Loss = 3.0280, Species Acc = 18.75%, Toxicity Acc = 98.44%\n",
      "Train Batch 44/322: Loss = 2.9518, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 45/322: Loss = 3.0316, Species Acc = 15.62%, Toxicity Acc = 98.44%\n",
      "Train Batch 46/322: Loss = 3.3616, Species Acc = 14.06%, Toxicity Acc = 93.75%\n",
      "Train Batch 47/322: Loss = 3.2339, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 48/322: Loss = 2.9173, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 49/322: Loss = 3.3608, Species Acc = 14.06%, Toxicity Acc = 92.19%\n",
      "Train Batch 50/322: Loss = 3.1111, Species Acc = 20.31%, Toxicity Acc = 95.31%\n",
      "Train Batch 51/322: Loss = 3.0802, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 52/322: Loss = 3.1666, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 53/322: Loss = 2.9508, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 54/322: Loss = 3.1132, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 55/322: Loss = 3.0243, Species Acc = 14.06%, Toxicity Acc = 92.19%\n",
      "Train Batch 56/322: Loss = 3.0368, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 57/322: Loss = 3.0483, Species Acc = 23.44%, Toxicity Acc = 98.44%\n",
      "Train Batch 58/322: Loss = 3.1770, Species Acc = 15.62%, Toxicity Acc = 98.44%\n",
      "Train Batch 59/322: Loss = 3.1585, Species Acc = 14.06%, Toxicity Acc = 100.00%\n",
      "Train Batch 60/322: Loss = 3.0912, Species Acc = 15.62%, Toxicity Acc = 92.19%\n",
      "Train Batch 61/322: Loss = 3.0678, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 62/322: Loss = 3.2532, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 63/322: Loss = 3.2281, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 64/322: Loss = 3.0023, Species Acc = 26.56%, Toxicity Acc = 90.62%\n",
      "Train Batch 65/322: Loss = 2.9429, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 66/322: Loss = 3.1313, Species Acc = 17.19%, Toxicity Acc = 93.75%\n",
      "Train Batch 67/322: Loss = 3.3053, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 68/322: Loss = 2.8913, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 69/322: Loss = 2.9857, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 70/322: Loss = 3.2850, Species Acc = 9.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 71/322: Loss = 3.0076, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 72/322: Loss = 3.1945, Species Acc = 12.50%, Toxicity Acc = 87.50%\n",
      "Train Batch 73/322: Loss = 3.2492, Species Acc = 21.88%, Toxicity Acc = 93.75%\n",
      "Train Batch 74/322: Loss = 3.1434, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 75/322: Loss = 3.0021, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 76/322: Loss = 3.2710, Species Acc = 10.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 77/322: Loss = 2.9829, Species Acc = 17.19%, Toxicity Acc = 100.00%\n",
      "Train Batch 78/322: Loss = 3.1871, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 79/322: Loss = 2.9317, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 80/322: Loss = 3.0726, Species Acc = 21.88%, Toxicity Acc = 93.75%\n",
      "Train Batch 81/322: Loss = 2.9543, Species Acc = 14.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 82/322: Loss = 3.0538, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 83/322: Loss = 3.1537, Species Acc = 9.38%, Toxicity Acc = 93.75%\n",
      "Train Batch 84/322: Loss = 2.8830, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 85/322: Loss = 3.3028, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 86/322: Loss = 2.8796, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 87/322: Loss = 3.1452, Species Acc = 17.19%, Toxicity Acc = 93.75%\n",
      "Train Batch 88/322: Loss = 2.9415, Species Acc = 14.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 89/322: Loss = 2.8009, Species Acc = 23.44%, Toxicity Acc = 98.44%\n",
      "Train Batch 90/322: Loss = 3.1069, Species Acc = 14.06%, Toxicity Acc = 93.75%\n",
      "Train Batch 91/322: Loss = 2.9653, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 92/322: Loss = 2.8929, Species Acc = 17.19%, Toxicity Acc = 98.44%\n",
      "Train Batch 93/322: Loss = 2.9604, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 94/322: Loss = 3.0057, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 95/322: Loss = 2.9508, Species Acc = 18.75%, Toxicity Acc = 98.44%\n",
      "Train Batch 96/322: Loss = 2.8495, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 97/322: Loss = 3.1487, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 98/322: Loss = 3.1745, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 99/322: Loss = 2.9930, Species Acc = 7.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 100/322: Loss = 2.6763, Species Acc = 21.88%, Toxicity Acc = 100.00%\n",
      "Train Batch 101/322: Loss = 2.8476, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 102/322: Loss = 2.7493, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 103/322: Loss = 3.2162, Species Acc = 15.62%, Toxicity Acc = 93.75%\n",
      "Train Batch 104/322: Loss = 2.8794, Species Acc = 20.31%, Toxicity Acc = 100.00%\n",
      "Train Batch 105/322: Loss = 2.7710, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 106/322: Loss = 3.2510, Species Acc = 18.75%, Toxicity Acc = 92.19%\n",
      "Train Batch 107/322: Loss = 2.9687, Species Acc = 21.88%, Toxicity Acc = 92.19%\n",
      "Train Batch 108/322: Loss = 3.0396, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 109/322: Loss = 3.0795, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 110/322: Loss = 3.1733, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 111/322: Loss = 3.2916, Species Acc = 10.94%, Toxicity Acc = 100.00%\n",
      "Train Batch 112/322: Loss = 2.8075, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 113/322: Loss = 2.8583, Species Acc = 21.88%, Toxicity Acc = 100.00%\n",
      "Train Batch 114/322: Loss = 2.9608, Species Acc = 18.75%, Toxicity Acc = 95.31%\n",
      "Train Batch 115/322: Loss = 3.0216, Species Acc = 9.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 116/322: Loss = 3.2639, Species Acc = 17.19%, Toxicity Acc = 90.62%\n",
      "Train Batch 117/322: Loss = 2.8887, Species Acc = 25.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 118/322: Loss = 3.0076, Species Acc = 26.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 119/322: Loss = 2.8484, Species Acc = 20.31%, Toxicity Acc = 95.31%\n",
      "Train Batch 120/322: Loss = 3.0730, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 121/322: Loss = 2.8947, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 122/322: Loss = 2.7159, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 123/322: Loss = 3.2639, Species Acc = 6.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 124/322: Loss = 3.0311, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 125/322: Loss = 2.9356, Species Acc = 23.44%, Toxicity Acc = 98.44%\n",
      "Train Batch 126/322: Loss = 3.1141, Species Acc = 18.75%, Toxicity Acc = 95.31%\n",
      "Train Batch 127/322: Loss = 2.9800, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 128/322: Loss = 2.9676, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 129/322: Loss = 2.9677, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 130/322: Loss = 2.8520, Species Acc = 21.88%, Toxicity Acc = 93.75%\n",
      "Train Batch 131/322: Loss = 2.8028, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 132/322: Loss = 3.0799, Species Acc = 15.62%, Toxicity Acc = 93.75%\n",
      "Train Batch 133/322: Loss = 3.0777, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 134/322: Loss = 2.7958, Species Acc = 15.62%, Toxicity Acc = 98.44%\n",
      "Train Batch 135/322: Loss = 2.7512, Species Acc = 18.75%, Toxicity Acc = 93.75%\n",
      "Train Batch 136/322: Loss = 3.1299, Species Acc = 20.31%, Toxicity Acc = 96.88%\n",
      "Train Batch 137/322: Loss = 3.5999, Species Acc = 9.38%, Toxicity Acc = 90.62%\n",
      "Train Batch 138/322: Loss = 2.8291, Species Acc = 10.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 139/322: Loss = 3.2526, Species Acc = 12.50%, Toxicity Acc = 93.75%\n",
      "Train Batch 140/322: Loss = 2.7251, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 141/322: Loss = 2.8594, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 142/322: Loss = 2.8311, Species Acc = 17.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 143/322: Loss = 2.9777, Species Acc = 20.31%, Toxicity Acc = 93.75%\n",
      "Train Batch 144/322: Loss = 2.8365, Species Acc = 21.88%, Toxicity Acc = 98.44%\n",
      "Train Batch 145/322: Loss = 2.9558, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 146/322: Loss = 2.9581, Species Acc = 14.06%, Toxicity Acc = 92.19%\n",
      "Train Batch 147/322: Loss = 2.7198, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 148/322: Loss = 3.0289, Species Acc = 12.50%, Toxicity Acc = 90.62%\n",
      "Train Batch 149/322: Loss = 2.9437, Species Acc = 18.75%, Toxicity Acc = 100.00%\n",
      "Train Batch 150/322: Loss = 2.9166, Species Acc = 23.44%, Toxicity Acc = 98.44%\n",
      "Train Batch 151/322: Loss = 3.2427, Species Acc = 12.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 152/322: Loss = 2.8047, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 153/322: Loss = 2.8843, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 154/322: Loss = 3.1810, Species Acc = 15.62%, Toxicity Acc = 93.75%\n",
      "Train Batch 155/322: Loss = 2.9262, Species Acc = 15.62%, Toxicity Acc = 93.75%\n",
      "Train Batch 156/322: Loss = 2.6876, Species Acc = 20.31%, Toxicity Acc = 100.00%\n",
      "Train Batch 157/322: Loss = 2.9977, Species Acc = 12.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 158/322: Loss = 3.1628, Species Acc = 15.62%, Toxicity Acc = 98.44%\n",
      "Train Batch 159/322: Loss = 2.8445, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 160/322: Loss = 2.6671, Species Acc = 26.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 161/322: Loss = 2.9426, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 162/322: Loss = 2.9271, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 163/322: Loss = 3.0762, Species Acc = 20.31%, Toxicity Acc = 92.19%\n",
      "Train Batch 164/322: Loss = 3.0097, Species Acc = 23.44%, Toxicity Acc = 93.75%\n",
      "Train Batch 165/322: Loss = 2.7733, Species Acc = 15.62%, Toxicity Acc = 98.44%\n",
      "Train Batch 166/322: Loss = 2.8738, Species Acc = 20.31%, Toxicity Acc = 95.31%\n",
      "Train Batch 167/322: Loss = 2.8005, Species Acc = 23.44%, Toxicity Acc = 89.06%\n",
      "Train Batch 168/322: Loss = 2.9910, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 169/322: Loss = 3.0120, Species Acc = 21.88%, Toxicity Acc = 89.06%\n",
      "Train Batch 170/322: Loss = 2.8672, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 171/322: Loss = 3.1761, Species Acc = 18.75%, Toxicity Acc = 89.06%\n",
      "Train Batch 172/322: Loss = 2.7416, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 173/322: Loss = 3.1318, Species Acc = 28.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 174/322: Loss = 3.0013, Species Acc = 14.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 175/322: Loss = 2.6802, Species Acc = 23.44%, Toxicity Acc = 89.06%\n",
      "Train Batch 176/322: Loss = 2.8130, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 177/322: Loss = 2.7462, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 178/322: Loss = 3.0232, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 179/322: Loss = 2.6965, Species Acc = 12.50%, Toxicity Acc = 100.00%\n",
      "Train Batch 180/322: Loss = 3.0459, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 181/322: Loss = 2.9811, Species Acc = 23.44%, Toxicity Acc = 90.62%\n",
      "Train Batch 182/322: Loss = 2.7767, Species Acc = 23.44%, Toxicity Acc = 98.44%\n",
      "Train Batch 183/322: Loss = 3.2031, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 184/322: Loss = 2.8853, Species Acc = 14.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 185/322: Loss = 2.5810, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 186/322: Loss = 3.0086, Species Acc = 14.06%, Toxicity Acc = 100.00%\n",
      "Train Batch 187/322: Loss = 2.6459, Species Acc = 23.44%, Toxicity Acc = 90.62%\n",
      "Train Batch 188/322: Loss = 2.9025, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 189/322: Loss = 2.8710, Species Acc = 20.31%, Toxicity Acc = 95.31%\n",
      "Train Batch 190/322: Loss = 3.0819, Species Acc = 17.19%, Toxicity Acc = 92.19%\n",
      "Train Batch 191/322: Loss = 2.7342, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 192/322: Loss = 2.5189, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 193/322: Loss = 3.0517, Species Acc = 20.31%, Toxicity Acc = 89.06%\n",
      "Train Batch 194/322: Loss = 2.9893, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 195/322: Loss = 3.1488, Species Acc = 9.38%, Toxicity Acc = 100.00%\n",
      "Train Batch 196/322: Loss = 2.7310, Species Acc = 21.88%, Toxicity Acc = 98.44%\n",
      "Train Batch 197/322: Loss = 2.8594, Species Acc = 20.31%, Toxicity Acc = 95.31%\n",
      "Train Batch 198/322: Loss = 2.8377, Species Acc = 26.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 199/322: Loss = 2.7779, Species Acc = 17.19%, Toxicity Acc = 93.75%\n",
      "Train Batch 200/322: Loss = 2.7139, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 201/322: Loss = 2.7587, Species Acc = 23.44%, Toxicity Acc = 98.44%\n",
      "Train Batch 202/322: Loss = 2.7496, Species Acc = 15.62%, Toxicity Acc = 98.44%\n",
      "Train Batch 203/322: Loss = 2.5206, Species Acc = 32.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 204/322: Loss = 2.7594, Species Acc = 12.50%, Toxicity Acc = 93.75%\n",
      "Train Batch 205/322: Loss = 2.8353, Species Acc = 20.31%, Toxicity Acc = 95.31%\n",
      "Train Batch 206/322: Loss = 3.0278, Species Acc = 12.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 207/322: Loss = 3.2118, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 208/322: Loss = 2.6879, Species Acc = 25.00%, Toxicity Acc = 98.44%\n",
      "Train Batch 209/322: Loss = 2.9015, Species Acc = 14.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 210/322: Loss = 2.7159, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 211/322: Loss = 2.7274, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 212/322: Loss = 2.6925, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 213/322: Loss = 2.8309, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 214/322: Loss = 2.6994, Species Acc = 18.75%, Toxicity Acc = 95.31%\n",
      "Train Batch 215/322: Loss = 2.9752, Species Acc = 25.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 216/322: Loss = 2.8928, Species Acc = 25.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 217/322: Loss = 2.8135, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 218/322: Loss = 2.7731, Species Acc = 25.00%, Toxicity Acc = 98.44%\n",
      "Train Batch 219/322: Loss = 2.6146, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 220/322: Loss = 2.7513, Species Acc = 28.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 221/322: Loss = 3.0255, Species Acc = 10.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 222/322: Loss = 2.6702, Species Acc = 25.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 223/322: Loss = 2.8209, Species Acc = 25.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 224/322: Loss = 2.6265, Species Acc = 25.00%, Toxicity Acc = 98.44%\n",
      "Train Batch 225/322: Loss = 2.7747, Species Acc = 21.88%, Toxicity Acc = 100.00%\n",
      "Train Batch 226/322: Loss = 2.7909, Species Acc = 18.75%, Toxicity Acc = 95.31%\n",
      "Train Batch 227/322: Loss = 2.8770, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 228/322: Loss = 2.7442, Species Acc = 18.75%, Toxicity Acc = 100.00%\n",
      "Train Batch 229/322: Loss = 2.7854, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 230/322: Loss = 2.5437, Species Acc = 26.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 231/322: Loss = 2.9132, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 232/322: Loss = 2.5477, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 233/322: Loss = 2.8426, Species Acc = 25.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 234/322: Loss = 2.6015, Species Acc = 25.00%, Toxicity Acc = 100.00%\n",
      "Train Batch 235/322: Loss = 2.7085, Species Acc = 28.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 236/322: Loss = 2.8003, Species Acc = 23.44%, Toxicity Acc = 93.75%\n",
      "Train Batch 237/322: Loss = 2.7047, Species Acc = 23.44%, Toxicity Acc = 100.00%\n",
      "Train Batch 238/322: Loss = 2.7892, Species Acc = 17.19%, Toxicity Acc = 98.44%\n",
      "Train Batch 239/322: Loss = 2.9880, Species Acc = 18.75%, Toxicity Acc = 95.31%\n",
      "Train Batch 240/322: Loss = 2.7414, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 241/322: Loss = 2.9407, Species Acc = 18.75%, Toxicity Acc = 98.44%\n",
      "Train Batch 242/322: Loss = 2.7996, Species Acc = 20.31%, Toxicity Acc = 96.88%\n",
      "Train Batch 243/322: Loss = 2.8187, Species Acc = 20.31%, Toxicity Acc = 93.75%\n",
      "Train Batch 244/322: Loss = 2.6350, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 245/322: Loss = 2.6770, Species Acc = 21.88%, Toxicity Acc = 93.75%\n",
      "Train Batch 246/322: Loss = 2.7352, Species Acc = 25.00%, Toxicity Acc = 92.19%\n",
      "Train Batch 247/322: Loss = 2.8603, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 248/322: Loss = 2.6223, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 249/322: Loss = 2.5409, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 250/322: Loss = 2.6960, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 251/322: Loss = 2.9590, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 252/322: Loss = 2.7037, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Train Batch 253/322: Loss = 2.7123, Species Acc = 26.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 254/322: Loss = 2.6679, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 255/322: Loss = 2.8791, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Train Batch 256/322: Loss = 2.8313, Species Acc = 20.31%, Toxicity Acc = 100.00%\n",
      "Train Batch 257/322: Loss = 2.8475, Species Acc = 12.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 258/322: Loss = 2.5984, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 259/322: Loss = 2.7420, Species Acc = 29.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 260/322: Loss = 2.7037, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 261/322: Loss = 2.5830, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 262/322: Loss = 2.4278, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 263/322: Loss = 2.6914, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 264/322: Loss = 2.6733, Species Acc = 31.25%, Toxicity Acc = 100.00%\n",
      "Train Batch 265/322: Loss = 2.5000, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 266/322: Loss = 2.6305, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 267/322: Loss = 2.6433, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 268/322: Loss = 2.6698, Species Acc = 23.44%, Toxicity Acc = 100.00%\n",
      "Train Batch 269/322: Loss = 2.8126, Species Acc = 25.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 270/322: Loss = 2.7202, Species Acc = 20.31%, Toxicity Acc = 96.88%\n",
      "Train Batch 271/322: Loss = 2.6766, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 272/322: Loss = 2.5148, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 273/322: Loss = 2.4660, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 274/322: Loss = 2.8509, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 275/322: Loss = 2.7057, Species Acc = 21.88%, Toxicity Acc = 98.44%\n",
      "Train Batch 276/322: Loss = 2.8396, Species Acc = 28.12%, Toxicity Acc = 92.19%\n",
      "Train Batch 277/322: Loss = 2.9323, Species Acc = 28.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 278/322: Loss = 2.7362, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 279/322: Loss = 2.5298, Species Acc = 18.75%, Toxicity Acc = 98.44%\n",
      "Train Batch 280/322: Loss = 2.6625, Species Acc = 32.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 281/322: Loss = 2.7485, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 282/322: Loss = 2.9265, Species Acc = 26.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 283/322: Loss = 2.8094, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 284/322: Loss = 2.3328, Species Acc = 37.50%, Toxicity Acc = 93.75%\n",
      "Train Batch 285/322: Loss = 2.8242, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Train Batch 286/322: Loss = 2.7871, Species Acc = 31.25%, Toxicity Acc = 93.75%\n",
      "Train Batch 287/322: Loss = 2.4836, Species Acc = 26.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 288/322: Loss = 2.6342, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 289/322: Loss = 2.7140, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 290/322: Loss = 3.1740, Species Acc = 18.75%, Toxicity Acc = 93.75%\n",
      "Train Batch 291/322: Loss = 2.6069, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 292/322: Loss = 2.8414, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 293/322: Loss = 2.5517, Species Acc = 25.00%, Toxicity Acc = 98.44%\n",
      "Train Batch 294/322: Loss = 2.4849, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 295/322: Loss = 3.1005, Species Acc = 17.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 296/322: Loss = 2.4384, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 297/322: Loss = 2.7491, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 298/322: Loss = 2.4983, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 299/322: Loss = 2.4270, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 300/322: Loss = 3.0406, Species Acc = 9.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 301/322: Loss = 2.6107, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 302/322: Loss = 2.5143, Species Acc = 29.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 303/322: Loss = 2.5092, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 304/322: Loss = 2.9204, Species Acc = 21.88%, Toxicity Acc = 92.19%\n",
      "Train Batch 305/322: Loss = 3.0186, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 306/322: Loss = 2.6322, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Train Batch 307/322: Loss = 2.7778, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 308/322: Loss = 2.5381, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 309/322: Loss = 2.8074, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 310/322: Loss = 2.3821, Species Acc = 42.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 311/322: Loss = 2.5560, Species Acc = 23.44%, Toxicity Acc = 100.00%\n",
      "Train Batch 312/322: Loss = 2.5886, Species Acc = 18.75%, Toxicity Acc = 98.44%\n",
      "Train Batch 313/322: Loss = 2.4423, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 314/322: Loss = 3.2824, Species Acc = 12.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 315/322: Loss = 2.9422, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Train Batch 316/322: Loss = 2.6715, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 317/322: Loss = 2.5842, Species Acc = 26.56%, Toxicity Acc = 92.19%\n",
      "Train Batch 318/322: Loss = 2.7984, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 319/322: Loss = 2.7746, Species Acc = 28.12%, Toxicity Acc = 93.75%\n",
      "Train Batch 320/322: Loss = 2.8493, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 321/322: Loss = 2.4469, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 322/322: Loss = 2.3947, Species Acc = 29.69%, Toxicity Acc = 95.31%\n",
      "Val Batch 1/80: Loss = 2.5417, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Val Batch 2/80: Loss = 2.6331, Species Acc = 28.12%, Toxicity Acc = 93.75%\n",
      "Val Batch 3/80: Loss = 2.9777, Species Acc = 25.00%, Toxicity Acc = 92.19%\n",
      "Val Batch 4/80: Loss = 2.6971, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Val Batch 5/80: Loss = 2.8654, Species Acc = 26.56%, Toxicity Acc = 93.75%\n",
      "Val Batch 6/80: Loss = 2.7999, Species Acc = 25.00%, Toxicity Acc = 92.19%\n",
      "Val Batch 7/80: Loss = 2.6129, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Val Batch 8/80: Loss = 2.9648, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Val Batch 9/80: Loss = 2.5993, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Val Batch 10/80: Loss = 2.8068, Species Acc = 25.00%, Toxicity Acc = 90.62%\n",
      "Val Batch 11/80: Loss = 2.4542, Species Acc = 32.81%, Toxicity Acc = 93.75%\n",
      "Val Batch 12/80: Loss = 2.7550, Species Acc = 32.81%, Toxicity Acc = 92.19%\n",
      "Val Batch 13/80: Loss = 2.5748, Species Acc = 31.25%, Toxicity Acc = 95.31%\n",
      "Val Batch 14/80: Loss = 2.7730, Species Acc = 29.69%, Toxicity Acc = 93.75%\n",
      "Val Batch 15/80: Loss = 2.6268, Species Acc = 20.31%, Toxicity Acc = 93.75%\n",
      "Val Batch 16/80: Loss = 2.8639, Species Acc = 31.25%, Toxicity Acc = 92.19%\n",
      "Val Batch 17/80: Loss = 2.4551, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Val Batch 18/80: Loss = 2.5710, Species Acc = 28.12%, Toxicity Acc = 93.75%\n",
      "Val Batch 19/80: Loss = 3.1208, Species Acc = 18.75%, Toxicity Acc = 89.06%\n",
      "Val Batch 20/80: Loss = 2.7379, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Val Batch 21/80: Loss = 2.4441, Species Acc = 37.50%, Toxicity Acc = 98.44%\n",
      "Val Batch 22/80: Loss = 2.9346, Species Acc = 21.88%, Toxicity Acc = 92.19%\n",
      "Val Batch 23/80: Loss = 2.8577, Species Acc = 15.62%, Toxicity Acc = 95.31%\n",
      "Val Batch 24/80: Loss = 2.7629, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Val Batch 25/80: Loss = 2.6128, Species Acc = 26.56%, Toxicity Acc = 92.19%\n",
      "Val Batch 26/80: Loss = 2.8558, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Val Batch 27/80: Loss = 2.7210, Species Acc = 21.88%, Toxicity Acc = 98.44%\n",
      "Val Batch 28/80: Loss = 2.9299, Species Acc = 18.75%, Toxicity Acc = 92.19%\n",
      "Val Batch 29/80: Loss = 2.9005, Species Acc = 18.75%, Toxicity Acc = 95.31%\n",
      "Val Batch 30/80: Loss = 2.4184, Species Acc = 39.06%, Toxicity Acc = 96.88%\n",
      "Val Batch 31/80: Loss = 2.7821, Species Acc = 25.00%, Toxicity Acc = 93.75%\n",
      "Val Batch 32/80: Loss = 2.7713, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Val Batch 33/80: Loss = 2.6032, Species Acc = 35.94%, Toxicity Acc = 90.62%\n",
      "Val Batch 34/80: Loss = 2.5912, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Val Batch 35/80: Loss = 2.6342, Species Acc = 26.56%, Toxicity Acc = 90.62%\n",
      "Val Batch 36/80: Loss = 2.8392, Species Acc = 25.00%, Toxicity Acc = 95.31%\n",
      "Val Batch 37/80: Loss = 2.6018, Species Acc = 26.56%, Toxicity Acc = 90.62%\n",
      "Val Batch 38/80: Loss = 2.7740, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Val Batch 39/80: Loss = 2.8077, Species Acc = 23.44%, Toxicity Acc = 87.50%\n",
      "Val Batch 40/80: Loss = 2.6634, Species Acc = 39.06%, Toxicity Acc = 93.75%\n",
      "Val Batch 41/80: Loss = 2.4541, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Val Batch 42/80: Loss = 2.7740, Species Acc = 40.62%, Toxicity Acc = 95.31%\n",
      "Val Batch 43/80: Loss = 2.4550, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Val Batch 44/80: Loss = 2.5654, Species Acc = 35.94%, Toxicity Acc = 95.31%\n",
      "Val Batch 45/80: Loss = 2.7077, Species Acc = 25.00%, Toxicity Acc = 95.31%\n",
      "Val Batch 46/80: Loss = 2.7483, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Val Batch 47/80: Loss = 2.4358, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Val Batch 48/80: Loss = 2.8114, Species Acc = 23.44%, Toxicity Acc = 92.19%\n",
      "Val Batch 49/80: Loss = 2.2865, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Val Batch 50/80: Loss = 2.5016, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Val Batch 51/80: Loss = 2.5941, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Val Batch 52/80: Loss = 2.7671, Species Acc = 26.56%, Toxicity Acc = 95.31%\n",
      "Val Batch 53/80: Loss = 2.7218, Species Acc = 20.31%, Toxicity Acc = 95.31%\n",
      "Val Batch 54/80: Loss = 2.5388, Species Acc = 29.69%, Toxicity Acc = 95.31%\n",
      "Val Batch 55/80: Loss = 2.8212, Species Acc = 25.00%, Toxicity Acc = 95.31%\n",
      "Val Batch 56/80: Loss = 2.5033, Species Acc = 28.12%, Toxicity Acc = 95.31%\n",
      "Val Batch 57/80: Loss = 2.7148, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Val Batch 58/80: Loss = 2.7063, Species Acc = 26.56%, Toxicity Acc = 92.19%\n",
      "Val Batch 59/80: Loss = 2.6428, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Val Batch 60/80: Loss = 2.4415, Species Acc = 32.81%, Toxicity Acc = 93.75%\n",
      "Val Batch 61/80: Loss = 2.9678, Species Acc = 21.88%, Toxicity Acc = 92.19%\n",
      "Val Batch 62/80: Loss = 2.6664, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Val Batch 63/80: Loss = 2.5744, Species Acc = 35.94%, Toxicity Acc = 95.31%\n",
      "Val Batch 64/80: Loss = 2.7799, Species Acc = 28.12%, Toxicity Acc = 92.19%\n",
      "Val Batch 65/80: Loss = 2.6478, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Val Batch 66/80: Loss = 2.7216, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Val Batch 67/80: Loss = 3.0087, Species Acc = 25.00%, Toxicity Acc = 92.19%\n",
      "Val Batch 68/80: Loss = 2.8507, Species Acc = 29.69%, Toxicity Acc = 93.75%\n",
      "Val Batch 69/80: Loss = 2.8716, Species Acc = 31.25%, Toxicity Acc = 93.75%\n",
      "Val Batch 70/80: Loss = 2.7448, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Val Batch 71/80: Loss = 2.7760, Species Acc = 39.06%, Toxicity Acc = 96.88%\n",
      "Val Batch 72/80: Loss = 2.9083, Species Acc = 26.56%, Toxicity Acc = 95.31%\n",
      "Val Batch 73/80: Loss = 2.7444, Species Acc = 25.00%, Toxicity Acc = 95.31%\n",
      "Val Batch 74/80: Loss = 3.0163, Species Acc = 20.31%, Toxicity Acc = 93.75%\n",
      "Val Batch 75/80: Loss = 3.1400, Species Acc = 32.81%, Toxicity Acc = 90.62%\n",
      "Val Batch 76/80: Loss = 2.6521, Species Acc = 26.56%, Toxicity Acc = 93.75%\n",
      "Val Batch 77/80: Loss = 2.5172, Species Acc = 34.38%, Toxicity Acc = 93.75%\n",
      "Val Batch 78/80: Loss = 2.7297, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Val Batch 79/80: Loss = 2.7921, Species Acc = 23.44%, Toxicity Acc = 93.75%\n",
      "Val Batch 80/80: Loss = 2.7362, Species Acc = 26.56%, Toxicity Acc = 92.19%\n",
      "\n",
      "Epoch 3/200 Summary:\n",
      "  Train Loss: 2.9153, Species Acc: 19.39%, Toxicity Acc: 96.08%\n",
      "  Val Loss:   2.7122, Species Acc: 27.56%, Toxicity Acc: 94.65%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84      5120\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72      5120\n",
      "   macro avg       0.50      0.36      0.42      5120\n",
      "weighted avg       1.00      0.72      0.84      5120\n",
      "\n",
      "[[ 8 16  0 ...  0  0  0]\n",
      " [ 4 47  0 ...  0  0  0]\n",
      " [ 1  3  2 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 14  0  0]\n",
      " [ 1 12  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      4693\n",
      "           1       0.72      0.58      0.65       427\n",
      "\n",
      "    accuracy                           0.95      5120\n",
      "   macro avg       0.84      0.78      0.81      5120\n",
      "weighted avg       0.94      0.95      0.94      5120\n",
      "\n",
      "[[4597   96]\n",
      " [ 178  249]]\n",
      "\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 1/322: Loss = 2.4314, Species Acc = 26.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 2/322: Loss = 2.4739, Species Acc = 23.44%, Toxicity Acc = 100.00%\n",
      "Train Batch 3/322: Loss = 2.3675, Species Acc = 26.56%, Toxicity Acc = 100.00%\n",
      "Train Batch 4/322: Loss = 2.6921, Species Acc = 15.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 5/322: Loss = 2.5337, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 6/322: Loss = 2.5508, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 7/322: Loss = 2.4844, Species Acc = 29.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 8/322: Loss = 2.4249, Species Acc = 17.19%, Toxicity Acc = 98.44%\n",
      "Train Batch 9/322: Loss = 2.1985, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 10/322: Loss = 2.6779, Species Acc = 18.75%, Toxicity Acc = 98.44%\n",
      "Train Batch 11/322: Loss = 2.3658, Species Acc = 25.00%, Toxicity Acc = 100.00%\n",
      "Train Batch 12/322: Loss = 2.3230, Species Acc = 37.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 13/322: Loss = 2.7915, Species Acc = 23.44%, Toxicity Acc = 100.00%\n",
      "Train Batch 14/322: Loss = 2.4138, Species Acc = 28.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 15/322: Loss = 2.2694, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 16/322: Loss = 2.3314, Species Acc = 32.81%, Toxicity Acc = 93.75%\n",
      "Train Batch 17/322: Loss = 2.4056, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 18/322: Loss = 2.7478, Species Acc = 23.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 19/322: Loss = 2.6057, Species Acc = 12.50%, Toxicity Acc = 92.19%\n",
      "Train Batch 20/322: Loss = 2.1904, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 21/322: Loss = 2.3007, Species Acc = 28.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 22/322: Loss = 2.2413, Species Acc = 34.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 23/322: Loss = 2.2274, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 24/322: Loss = 2.1797, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 25/322: Loss = 2.6222, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 26/322: Loss = 2.5357, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 27/322: Loss = 2.6640, Species Acc = 18.75%, Toxicity Acc = 96.88%\n",
      "Train Batch 28/322: Loss = 2.2106, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 29/322: Loss = 2.3115, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 30/322: Loss = 2.4415, Species Acc = 20.31%, Toxicity Acc = 100.00%\n",
      "Train Batch 31/322: Loss = 2.4304, Species Acc = 21.88%, Toxicity Acc = 98.44%\n",
      "Train Batch 32/322: Loss = 2.4290, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 33/322: Loss = 2.1530, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 34/322: Loss = 2.2702, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 35/322: Loss = 2.4109, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 36/322: Loss = 2.3039, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 37/322: Loss = 2.3019, Species Acc = 28.12%, Toxicity Acc = 100.00%\n",
      "Train Batch 38/322: Loss = 2.6346, Species Acc = 21.88%, Toxicity Acc = 98.44%\n",
      "Train Batch 39/322: Loss = 2.1413, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 40/322: Loss = 2.2689, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 41/322: Loss = 2.5614, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 42/322: Loss = 2.4136, Species Acc = 25.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 43/322: Loss = 2.6008, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Train Batch 44/322: Loss = 2.3185, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 45/322: Loss = 2.4356, Species Acc = 28.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 46/322: Loss = 2.3785, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 47/322: Loss = 2.3281, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 48/322: Loss = 2.3352, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 49/322: Loss = 2.4336, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 50/322: Loss = 2.4533, Species Acc = 37.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 51/322: Loss = 2.1238, Species Acc = 35.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 52/322: Loss = 2.4848, Species Acc = 31.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 53/322: Loss = 2.3696, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 54/322: Loss = 2.2088, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 55/322: Loss = 2.3318, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 56/322: Loss = 2.3483, Species Acc = 20.31%, Toxicity Acc = 100.00%\n",
      "Train Batch 57/322: Loss = 2.4624, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 58/322: Loss = 2.1492, Species Acc = 26.56%, Toxicity Acc = 100.00%\n",
      "Train Batch 59/322: Loss = 2.2854, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 60/322: Loss = 2.1970, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 61/322: Loss = 2.4077, Species Acc = 31.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 62/322: Loss = 2.4843, Species Acc = 26.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 63/322: Loss = 2.0656, Species Acc = 39.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 64/322: Loss = 2.4185, Species Acc = 23.44%, Toxicity Acc = 100.00%\n",
      "Train Batch 65/322: Loss = 2.5511, Species Acc = 21.88%, Toxicity Acc = 100.00%\n",
      "Train Batch 66/322: Loss = 2.5483, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 67/322: Loss = 2.5459, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 68/322: Loss = 2.2222, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 69/322: Loss = 2.2068, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 70/322: Loss = 2.0346, Species Acc = 40.62%, Toxicity Acc = 100.00%\n",
      "Train Batch 71/322: Loss = 2.3557, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 72/322: Loss = 2.0270, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 73/322: Loss = 2.4078, Species Acc = 23.44%, Toxicity Acc = 93.75%\n",
      "Train Batch 74/322: Loss = 2.2934, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 75/322: Loss = 2.4101, Species Acc = 23.44%, Toxicity Acc = 100.00%\n",
      "Train Batch 76/322: Loss = 2.6303, Species Acc = 25.00%, Toxicity Acc = 95.31%\n",
      "Train Batch 77/322: Loss = 2.1357, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 78/322: Loss = 2.5458, Species Acc = 21.88%, Toxicity Acc = 96.88%\n",
      "Train Batch 79/322: Loss = 2.3375, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 80/322: Loss = 2.3235, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 81/322: Loss = 2.3862, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 82/322: Loss = 2.1035, Species Acc = 39.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 83/322: Loss = 2.4623, Species Acc = 32.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 84/322: Loss = 2.1200, Species Acc = 26.56%, Toxicity Acc = 100.00%\n",
      "Train Batch 85/322: Loss = 1.9964, Species Acc = 37.50%, Toxicity Acc = 100.00%\n",
      "Train Batch 86/322: Loss = 2.1809, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 87/322: Loss = 2.2834, Species Acc = 39.06%, Toxicity Acc = 95.31%\n",
      "Train Batch 88/322: Loss = 2.5104, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 89/322: Loss = 2.0878, Species Acc = 45.31%, Toxicity Acc = 100.00%\n",
      "Train Batch 90/322: Loss = 2.4340, Species Acc = 25.00%, Toxicity Acc = 98.44%\n",
      "Train Batch 91/322: Loss = 2.3838, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 92/322: Loss = 2.7549, Species Acc = 28.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 93/322: Loss = 2.2907, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 94/322: Loss = 2.5111, Species Acc = 25.00%, Toxicity Acc = 98.44%\n",
      "Train Batch 95/322: Loss = 2.4992, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 96/322: Loss = 2.4176, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 97/322: Loss = 2.2314, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 98/322: Loss = 2.2257, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 99/322: Loss = 2.4648, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 100/322: Loss = 2.2937, Species Acc = 25.00%, Toxicity Acc = 98.44%\n",
      "Train Batch 101/322: Loss = 2.2934, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 102/322: Loss = 2.3448, Species Acc = 18.75%, Toxicity Acc = 98.44%\n",
      "Train Batch 103/322: Loss = 2.3036, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 104/322: Loss = 2.2689, Species Acc = 31.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 105/322: Loss = 2.0991, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 106/322: Loss = 2.1157, Species Acc = 35.94%, Toxicity Acc = 93.75%\n",
      "Train Batch 107/322: Loss = 2.4364, Species Acc = 32.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 108/322: Loss = 2.2847, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 109/322: Loss = 2.2138, Species Acc = 28.12%, Toxicity Acc = 95.31%\n",
      "Train Batch 110/322: Loss = 2.5724, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 111/322: Loss = 2.4875, Species Acc = 20.31%, Toxicity Acc = 98.44%\n",
      "Train Batch 112/322: Loss = 2.5581, Species Acc = 23.44%, Toxicity Acc = 93.75%\n",
      "Train Batch 113/322: Loss = 2.3667, Species Acc = 29.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 114/322: Loss = 2.5123, Species Acc = 28.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 115/322: Loss = 2.2988, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 116/322: Loss = 2.3951, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 117/322: Loss = 2.2815, Species Acc = 21.88%, Toxicity Acc = 100.00%\n",
      "Train Batch 118/322: Loss = 2.3817, Species Acc = 35.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 119/322: Loss = 2.5046, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 120/322: Loss = 2.5235, Species Acc = 18.75%, Toxicity Acc = 98.44%\n",
      "Train Batch 121/322: Loss = 2.2717, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 122/322: Loss = 2.0332, Species Acc = 39.06%, Toxicity Acc = 90.62%\n",
      "Train Batch 123/322: Loss = 2.2251, Species Acc = 26.56%, Toxicity Acc = 100.00%\n",
      "Train Batch 124/322: Loss = 2.4072, Species Acc = 25.00%, Toxicity Acc = 98.44%\n",
      "Train Batch 125/322: Loss = 2.0622, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 126/322: Loss = 2.5303, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 127/322: Loss = 2.1732, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 128/322: Loss = 2.2770, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 129/322: Loss = 2.3358, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 130/322: Loss = 2.1868, Species Acc = 26.56%, Toxicity Acc = 100.00%\n",
      "Train Batch 131/322: Loss = 2.3667, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 132/322: Loss = 2.4372, Species Acc = 32.81%, Toxicity Acc = 93.75%\n",
      "Train Batch 133/322: Loss = 2.4497, Species Acc = 25.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 134/322: Loss = 2.2537, Species Acc = 31.25%, Toxicity Acc = 100.00%\n",
      "Train Batch 135/322: Loss = 2.3416, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 136/322: Loss = 2.3597, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 137/322: Loss = 2.6024, Species Acc = 21.88%, Toxicity Acc = 98.44%\n",
      "Train Batch 138/322: Loss = 2.3843, Species Acc = 29.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 139/322: Loss = 2.2013, Species Acc = 40.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 140/322: Loss = 2.3713, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 141/322: Loss = 2.4062, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 142/322: Loss = 2.7757, Species Acc = 26.56%, Toxicity Acc = 93.75%\n",
      "Train Batch 143/322: Loss = 2.4805, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 144/322: Loss = 2.2441, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 145/322: Loss = 2.2826, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 146/322: Loss = 2.1533, Species Acc = 31.25%, Toxicity Acc = 100.00%\n",
      "Train Batch 147/322: Loss = 2.0427, Species Acc = 37.50%, Toxicity Acc = 100.00%\n",
      "Train Batch 148/322: Loss = 2.5986, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 149/322: Loss = 1.9548, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 150/322: Loss = 2.3156, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 151/322: Loss = 1.9621, Species Acc = 45.31%, Toxicity Acc = 100.00%\n",
      "Train Batch 152/322: Loss = 2.3072, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 153/322: Loss = 2.2335, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 154/322: Loss = 2.3908, Species Acc = 34.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 155/322: Loss = 1.8559, Species Acc = 50.00%, Toxicity Acc = 98.44%\n",
      "Train Batch 156/322: Loss = 2.5260, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 157/322: Loss = 2.3569, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 158/322: Loss = 2.0796, Species Acc = 31.25%, Toxicity Acc = 100.00%\n",
      "Train Batch 159/322: Loss = 2.2517, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 160/322: Loss = 2.3347, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 161/322: Loss = 2.1610, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 162/322: Loss = 2.3179, Species Acc = 42.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 163/322: Loss = 2.2640, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 164/322: Loss = 2.3806, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 165/322: Loss = 2.2082, Species Acc = 29.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 166/322: Loss = 2.0891, Species Acc = 39.06%, Toxicity Acc = 100.00%\n",
      "Train Batch 167/322: Loss = 2.1636, Species Acc = 25.00%, Toxicity Acc = 100.00%\n",
      "Train Batch 168/322: Loss = 2.2622, Species Acc = 28.12%, Toxicity Acc = 98.44%\n",
      "Train Batch 169/322: Loss = 2.2260, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 170/322: Loss = 2.1962, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 171/322: Loss = 2.4006, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 172/322: Loss = 2.2573, Species Acc = 35.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 173/322: Loss = 2.5975, Species Acc = 25.00%, Toxicity Acc = 93.75%\n",
      "Train Batch 174/322: Loss = 2.1972, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 175/322: Loss = 2.0171, Species Acc = 35.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 176/322: Loss = 2.0145, Species Acc = 34.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 177/322: Loss = 2.1646, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 178/322: Loss = 1.9670, Species Acc = 37.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 179/322: Loss = 2.5218, Species Acc = 31.25%, Toxicity Acc = 100.00%\n",
      "Train Batch 180/322: Loss = 2.2421, Species Acc = 35.94%, Toxicity Acc = 95.31%\n",
      "Train Batch 181/322: Loss = 2.3842, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 182/322: Loss = 2.2997, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 183/322: Loss = 2.1196, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 184/322: Loss = 2.1490, Species Acc = 37.50%, Toxicity Acc = 100.00%\n",
      "Train Batch 185/322: Loss = 2.2387, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 186/322: Loss = 2.1348, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 187/322: Loss = 2.2410, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 188/322: Loss = 2.2663, Species Acc = 45.31%, Toxicity Acc = 93.75%\n",
      "Train Batch 189/322: Loss = 2.2539, Species Acc = 35.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 190/322: Loss = 2.1838, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 191/322: Loss = 2.1521, Species Acc = 31.25%, Toxicity Acc = 100.00%\n",
      "Train Batch 192/322: Loss = 2.0990, Species Acc = 35.94%, Toxicity Acc = 95.31%\n",
      "Train Batch 193/322: Loss = 2.1189, Species Acc = 32.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 194/322: Loss = 2.2622, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 195/322: Loss = 2.3924, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 196/322: Loss = 2.2004, Species Acc = 40.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 197/322: Loss = 2.2169, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 198/322: Loss = 2.2624, Species Acc = 21.88%, Toxicity Acc = 98.44%\n",
      "Train Batch 199/322: Loss = 2.2013, Species Acc = 37.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 200/322: Loss = 2.3812, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 201/322: Loss = 2.1518, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 202/322: Loss = 2.3512, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 203/322: Loss = 2.4131, Species Acc = 37.50%, Toxicity Acc = 100.00%\n",
      "Train Batch 204/322: Loss = 2.5078, Species Acc = 32.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 205/322: Loss = 2.2268, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 206/322: Loss = 2.2538, Species Acc = 37.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 207/322: Loss = 2.1950, Species Acc = 34.38%, Toxicity Acc = 100.00%\n",
      "Train Batch 208/322: Loss = 1.9969, Species Acc = 42.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 209/322: Loss = 2.0608, Species Acc = 31.25%, Toxicity Acc = 100.00%\n",
      "Train Batch 210/322: Loss = 2.2633, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 211/322: Loss = 2.1426, Species Acc = 35.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 212/322: Loss = 2.5827, Species Acc = 12.50%, Toxicity Acc = 93.75%\n",
      "Train Batch 213/322: Loss = 2.1912, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 214/322: Loss = 2.1865, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Train Batch 215/322: Loss = 2.0829, Species Acc = 42.19%, Toxicity Acc = 98.44%\n",
      "Train Batch 216/322: Loss = 2.0846, Species Acc = 37.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 217/322: Loss = 2.2308, Species Acc = 34.38%, Toxicity Acc = 100.00%\n",
      "Train Batch 218/322: Loss = 2.3300, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 219/322: Loss = 2.1095, Species Acc = 39.06%, Toxicity Acc = 100.00%\n",
      "Train Batch 220/322: Loss = 2.3104, Species Acc = 23.44%, Toxicity Acc = 96.88%\n",
      "Train Batch 221/322: Loss = 1.9782, Species Acc = 35.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 222/322: Loss = 2.2894, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 223/322: Loss = 2.3175, Species Acc = 31.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 224/322: Loss = 1.9741, Species Acc = 39.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 225/322: Loss = 2.3693, Species Acc = 34.38%, Toxicity Acc = 95.31%\n",
      "Train Batch 226/322: Loss = 1.9419, Species Acc = 51.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 227/322: Loss = 2.1446, Species Acc = 42.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 228/322: Loss = 2.4996, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 229/322: Loss = 2.5637, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 230/322: Loss = 2.2052, Species Acc = 31.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 231/322: Loss = 1.8423, Species Acc = 48.44%, Toxicity Acc = 98.44%\n",
      "Train Batch 232/322: Loss = 2.2418, Species Acc = 35.94%, Toxicity Acc = 100.00%\n",
      "Train Batch 233/322: Loss = 2.1625, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 234/322: Loss = 2.1533, Species Acc = 35.94%, Toxicity Acc = 100.00%\n",
      "Train Batch 235/322: Loss = 2.3544, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 236/322: Loss = 2.6678, Species Acc = 32.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 237/322: Loss = 2.0810, Species Acc = 35.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 238/322: Loss = 2.3801, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 239/322: Loss = 2.3010, Species Acc = 37.50%, Toxicity Acc = 95.31%\n",
      "Train Batch 240/322: Loss = 2.0704, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 241/322: Loss = 2.1561, Species Acc = 26.56%, Toxicity Acc = 100.00%\n",
      "Train Batch 242/322: Loss = 2.1144, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 243/322: Loss = 2.1138, Species Acc = 39.06%, Toxicity Acc = 100.00%\n",
      "Train Batch 244/322: Loss = 1.9646, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 245/322: Loss = 2.1772, Species Acc = 42.19%, Toxicity Acc = 98.44%\n",
      "Train Batch 246/322: Loss = 2.0846, Species Acc = 40.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 247/322: Loss = 2.1511, Species Acc = 37.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 248/322: Loss = 2.0641, Species Acc = 34.38%, Toxicity Acc = 100.00%\n",
      "Train Batch 249/322: Loss = 2.1381, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 250/322: Loss = 2.2543, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 251/322: Loss = 2.2034, Species Acc = 35.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 252/322: Loss = 2.2918, Species Acc = 35.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 253/322: Loss = 2.2762, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 254/322: Loss = 2.0566, Species Acc = 39.06%, Toxicity Acc = 100.00%\n",
      "Train Batch 255/322: Loss = 2.4047, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 256/322: Loss = 2.1334, Species Acc = 32.81%, Toxicity Acc = 96.88%\n",
      "Train Batch 257/322: Loss = 2.3263, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 258/322: Loss = 2.3393, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 259/322: Loss = 2.1974, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 260/322: Loss = 2.4468, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Train Batch 261/322: Loss = 2.5511, Species Acc = 29.69%, Toxicity Acc = 95.31%\n",
      "Train Batch 262/322: Loss = 2.0713, Species Acc = 39.06%, Toxicity Acc = 100.00%\n",
      "Train Batch 263/322: Loss = 2.6926, Species Acc = 21.88%, Toxicity Acc = 98.44%\n",
      "Train Batch 264/322: Loss = 2.2062, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 265/322: Loss = 2.2132, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 266/322: Loss = 2.2797, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Train Batch 267/322: Loss = 2.4391, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 268/322: Loss = 2.2434, Species Acc = 39.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 269/322: Loss = 2.4911, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 270/322: Loss = 1.8787, Species Acc = 45.31%, Toxicity Acc = 100.00%\n",
      "Train Batch 271/322: Loss = 2.6598, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 272/322: Loss = 2.5740, Species Acc = 32.81%, Toxicity Acc = 93.75%\n",
      "Train Batch 273/322: Loss = 2.3194, Species Acc = 29.69%, Toxicity Acc = 98.44%\n",
      "Train Batch 274/322: Loss = 2.3431, Species Acc = 34.38%, Toxicity Acc = 100.00%\n",
      "Train Batch 275/322: Loss = 2.3132, Species Acc = 31.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 276/322: Loss = 2.2334, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 277/322: Loss = 2.0884, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 278/322: Loss = 2.0377, Species Acc = 39.06%, Toxicity Acc = 96.88%\n",
      "Train Batch 279/322: Loss = 2.2555, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Train Batch 280/322: Loss = 2.2072, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Train Batch 281/322: Loss = 2.2503, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 282/322: Loss = 2.5837, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Train Batch 283/322: Loss = 1.9410, Species Acc = 40.62%, Toxicity Acc = 98.44%\n",
      "Train Batch 284/322: Loss = 1.9380, Species Acc = 35.94%, Toxicity Acc = 98.44%\n",
      "Train Batch 285/322: Loss = 2.2464, Species Acc = 25.00%, Toxicity Acc = 100.00%\n",
      "Train Batch 286/322: Loss = 1.9866, Species Acc = 51.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 287/322: Loss = 2.3773, Species Acc = 42.19%, Toxicity Acc = 95.31%\n",
      "Train Batch 288/322: Loss = 2.2670, Species Acc = 29.69%, Toxicity Acc = 92.19%\n",
      "Train Batch 289/322: Loss = 2.1822, Species Acc = 29.69%, Toxicity Acc = 93.75%\n",
      "Train Batch 290/322: Loss = 2.2563, Species Acc = 31.25%, Toxicity Acc = 95.31%\n",
      "Train Batch 291/322: Loss = 2.2797, Species Acc = 35.94%, Toxicity Acc = 95.31%\n",
      "Train Batch 292/322: Loss = 2.1030, Species Acc = 28.12%, Toxicity Acc = 100.00%\n",
      "Train Batch 293/322: Loss = 2.0325, Species Acc = 46.88%, Toxicity Acc = 95.31%\n",
      "Train Batch 294/322: Loss = 2.0890, Species Acc = 40.62%, Toxicity Acc = 96.88%\n",
      "Train Batch 295/322: Loss = 1.8276, Species Acc = 42.19%, Toxicity Acc = 96.88%\n",
      "Train Batch 296/322: Loss = 1.9769, Species Acc = 40.62%, Toxicity Acc = 92.19%\n",
      "Train Batch 297/322: Loss = 2.0971, Species Acc = 37.50%, Toxicity Acc = 98.44%\n",
      "Train Batch 298/322: Loss = 2.3054, Species Acc = 26.56%, Toxicity Acc = 96.88%\n",
      "Train Batch 299/322: Loss = 1.8859, Species Acc = 48.44%, Toxicity Acc = 95.31%\n",
      "Train Batch 300/322: Loss = 2.4678, Species Acc = 26.56%, Toxicity Acc = 95.31%\n",
      "Train Batch 301/322: Loss = 1.9684, Species Acc = 35.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 302/322: Loss = 2.0529, Species Acc = 35.94%, Toxicity Acc = 100.00%\n",
      "Train Batch 303/322: Loss = 2.3224, Species Acc = 35.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 304/322: Loss = 2.4808, Species Acc = 26.56%, Toxicity Acc = 98.44%\n",
      "Train Batch 305/322: Loss = 2.0804, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 306/322: Loss = 2.1113, Species Acc = 40.62%, Toxicity Acc = 95.31%\n",
      "Train Batch 307/322: Loss = 2.1795, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 308/322: Loss = 2.1612, Species Acc = 35.94%, Toxicity Acc = 95.31%\n",
      "Train Batch 309/322: Loss = 1.8429, Species Acc = 50.00%, Toxicity Acc = 96.88%\n",
      "Train Batch 310/322: Loss = 2.3807, Species Acc = 29.69%, Toxicity Acc = 100.00%\n",
      "Train Batch 311/322: Loss = 2.2386, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 312/322: Loss = 2.0941, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Train Batch 313/322: Loss = 2.0194, Species Acc = 32.81%, Toxicity Acc = 92.19%\n",
      "Train Batch 314/322: Loss = 2.1841, Species Acc = 40.62%, Toxicity Acc = 98.44%\n",
      "Train Batch 315/322: Loss = 2.0309, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Train Batch 316/322: Loss = 2.1321, Species Acc = 35.94%, Toxicity Acc = 100.00%\n",
      "Train Batch 317/322: Loss = 2.1966, Species Acc = 28.12%, Toxicity Acc = 96.88%\n",
      "Train Batch 318/322: Loss = 2.2340, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "Train Batch 319/322: Loss = 2.5408, Species Acc = 28.12%, Toxicity Acc = 90.62%\n",
      "Train Batch 320/322: Loss = 2.5936, Species Acc = 35.94%, Toxicity Acc = 96.88%\n",
      "Train Batch 321/322: Loss = 1.9209, Species Acc = 37.50%, Toxicity Acc = 96.88%\n",
      "Train Batch 322/322: Loss = 2.1926, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Val Batch 1/80: Loss = 2.1994, Species Acc = 46.88%, Toxicity Acc = 96.88%\n",
      "Val Batch 2/80: Loss = 2.5791, Species Acc = 34.38%, Toxicity Acc = 92.19%\n",
      "Val Batch 3/80: Loss = 2.7057, Species Acc = 34.38%, Toxicity Acc = 90.62%\n",
      "Val Batch 4/80: Loss = 2.5487, Species Acc = 31.25%, Toxicity Acc = 90.62%\n",
      "Val Batch 5/80: Loss = 2.6376, Species Acc = 26.56%, Toxicity Acc = 93.75%\n",
      "Val Batch 6/80: Loss = 2.4685, Species Acc = 32.81%, Toxicity Acc = 92.19%\n",
      "Val Batch 7/80: Loss = 2.2861, Species Acc = 35.94%, Toxicity Acc = 96.88%\n",
      "Val Batch 8/80: Loss = 2.6793, Species Acc = 21.88%, Toxicity Acc = 95.31%\n",
      "Val Batch 9/80: Loss = 2.2406, Species Acc = 42.19%, Toxicity Acc = 95.31%\n",
      "Val Batch 10/80: Loss = 2.4594, Species Acc = 32.81%, Toxicity Acc = 90.62%\n",
      "Val Batch 11/80: Loss = 1.9168, Species Acc = 37.50%, Toxicity Acc = 95.31%\n",
      "Val Batch 12/80: Loss = 2.3946, Species Acc = 39.06%, Toxicity Acc = 92.19%\n",
      "Val Batch 13/80: Loss = 2.2699, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Val Batch 14/80: Loss = 2.2606, Species Acc = 51.56%, Toxicity Acc = 93.75%\n",
      "Val Batch 15/80: Loss = 2.5536, Species Acc = 40.62%, Toxicity Acc = 90.62%\n",
      "Val Batch 16/80: Loss = 2.5903, Species Acc = 35.94%, Toxicity Acc = 93.75%\n",
      "Val Batch 17/80: Loss = 2.1103, Species Acc = 28.12%, Toxicity Acc = 93.75%\n",
      "Val Batch 18/80: Loss = 2.1605, Species Acc = 40.62%, Toxicity Acc = 90.62%\n",
      "Val Batch 19/80: Loss = 3.0417, Species Acc = 29.69%, Toxicity Acc = 84.38%\n",
      "Val Batch 20/80: Loss = 2.3501, Species Acc = 31.25%, Toxicity Acc = 93.75%\n",
      "Val Batch 21/80: Loss = 2.1270, Species Acc = 45.31%, Toxicity Acc = 96.88%\n",
      "Val Batch 22/80: Loss = 2.5251, Species Acc = 26.56%, Toxicity Acc = 93.75%\n",
      "Val Batch 23/80: Loss = 2.4044, Species Acc = 32.81%, Toxicity Acc = 100.00%\n",
      "Val Batch 24/80: Loss = 2.4541, Species Acc = 37.50%, Toxicity Acc = 98.44%\n",
      "Val Batch 25/80: Loss = 2.4675, Species Acc = 32.81%, Toxicity Acc = 92.19%\n",
      "Val Batch 26/80: Loss = 2.4459, Species Acc = 34.38%, Toxicity Acc = 98.44%\n",
      "Val Batch 27/80: Loss = 2.4966, Species Acc = 31.25%, Toxicity Acc = 98.44%\n",
      "Val Batch 28/80: Loss = 2.6710, Species Acc = 37.50%, Toxicity Acc = 90.62%\n",
      "Val Batch 29/80: Loss = 2.6225, Species Acc = 37.50%, Toxicity Acc = 93.75%\n",
      "Val Batch 30/80: Loss = 1.9728, Species Acc = 53.12%, Toxicity Acc = 98.44%\n",
      "Val Batch 31/80: Loss = 2.5839, Species Acc = 28.12%, Toxicity Acc = 93.75%\n",
      "Val Batch 32/80: Loss = 2.2157, Species Acc = 34.38%, Toxicity Acc = 100.00%\n",
      "Val Batch 33/80: Loss = 2.1627, Species Acc = 46.88%, Toxicity Acc = 90.62%\n",
      "Val Batch 34/80: Loss = 2.2794, Species Acc = 25.00%, Toxicity Acc = 96.88%\n",
      "Val Batch 35/80: Loss = 2.1281, Species Acc = 45.31%, Toxicity Acc = 93.75%\n",
      "Val Batch 36/80: Loss = 2.2101, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "Val Batch 37/80: Loss = 2.2820, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Val Batch 38/80: Loss = 2.4122, Species Acc = 35.94%, Toxicity Acc = 98.44%\n",
      "Val Batch 39/80: Loss = 2.4577, Species Acc = 23.44%, Toxicity Acc = 89.06%\n",
      "Val Batch 40/80: Loss = 2.4525, Species Acc = 40.62%, Toxicity Acc = 90.62%\n",
      "Val Batch 41/80: Loss = 2.1868, Species Acc = 29.69%, Toxicity Acc = 96.88%\n",
      "Val Batch 42/80: Loss = 2.6181, Species Acc = 43.75%, Toxicity Acc = 93.75%\n",
      "Val Batch 43/80: Loss = 2.2115, Species Acc = 42.19%, Toxicity Acc = 95.31%\n",
      "Val Batch 44/80: Loss = 2.3253, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Val Batch 45/80: Loss = 2.4747, Species Acc = 32.81%, Toxicity Acc = 93.75%\n",
      "Val Batch 46/80: Loss = 2.5715, Species Acc = 28.12%, Toxicity Acc = 92.19%\n",
      "Val Batch 47/80: Loss = 2.2352, Species Acc = 42.19%, Toxicity Acc = 95.31%\n",
      "Val Batch 48/80: Loss = 2.4269, Species Acc = 32.81%, Toxicity Acc = 95.31%\n",
      "Val Batch 49/80: Loss = 1.8864, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Val Batch 50/80: Loss = 2.3282, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "Val Batch 51/80: Loss = 2.0854, Species Acc = 42.19%, Toxicity Acc = 95.31%\n",
      "Val Batch 52/80: Loss = 2.6571, Species Acc = 31.25%, Toxicity Acc = 90.62%\n",
      "Val Batch 53/80: Loss = 2.4449, Species Acc = 39.06%, Toxicity Acc = 92.19%\n",
      "Val Batch 54/80: Loss = 2.2775, Species Acc = 34.38%, Toxicity Acc = 93.75%\n",
      "Val Batch 55/80: Loss = 2.7509, Species Acc = 39.06%, Toxicity Acc = 90.62%\n",
      "Val Batch 56/80: Loss = 2.4272, Species Acc = 23.44%, Toxicity Acc = 92.19%\n",
      "Val Batch 57/80: Loss = 2.2346, Species Acc = 46.88%, Toxicity Acc = 96.88%\n",
      "Val Batch 58/80: Loss = 2.2032, Species Acc = 39.06%, Toxicity Acc = 98.44%\n",
      "Val Batch 59/80: Loss = 2.3605, Species Acc = 32.81%, Toxicity Acc = 98.44%\n",
      "Val Batch 60/80: Loss = 2.1633, Species Acc = 43.75%, Toxicity Acc = 93.75%\n",
      "Val Batch 61/80: Loss = 2.6927, Species Acc = 20.31%, Toxicity Acc = 92.19%\n",
      "Val Batch 62/80: Loss = 2.3659, Species Acc = 37.50%, Toxicity Acc = 92.19%\n",
      "Val Batch 63/80: Loss = 2.3051, Species Acc = 35.94%, Toxicity Acc = 96.88%\n",
      "Val Batch 64/80: Loss = 2.4366, Species Acc = 46.88%, Toxicity Acc = 93.75%\n",
      "Val Batch 65/80: Loss = 2.2233, Species Acc = 42.19%, Toxicity Acc = 95.31%\n",
      "Val Batch 66/80: Loss = 2.6285, Species Acc = 35.94%, Toxicity Acc = 96.88%\n",
      "Val Batch 67/80: Loss = 2.7505, Species Acc = 31.25%, Toxicity Acc = 93.75%\n",
      "Val Batch 68/80: Loss = 2.6063, Species Acc = 35.94%, Toxicity Acc = 93.75%\n",
      "Val Batch 69/80: Loss = 2.4597, Species Acc = 39.06%, Toxicity Acc = 92.19%\n",
      "Val Batch 70/80: Loss = 2.5065, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Val Batch 71/80: Loss = 2.4471, Species Acc = 31.25%, Toxicity Acc = 96.88%\n",
      "Val Batch 72/80: Loss = 2.7874, Species Acc = 26.56%, Toxicity Acc = 92.19%\n",
      "Val Batch 73/80: Loss = 2.3199, Species Acc = 31.25%, Toxicity Acc = 95.31%\n",
      "Val Batch 74/80: Loss = 2.9726, Species Acc = 20.31%, Toxicity Acc = 90.62%\n",
      "Val Batch 75/80: Loss = 2.7241, Species Acc = 31.25%, Toxicity Acc = 90.62%\n",
      "Val Batch 76/80: Loss = 2.3701, Species Acc = 31.25%, Toxicity Acc = 92.19%\n",
      "Val Batch 77/80: Loss = 2.3085, Species Acc = 35.94%, Toxicity Acc = 93.75%\n",
      "Val Batch 78/80: Loss = 2.3592, Species Acc = 29.69%, Toxicity Acc = 95.31%\n",
      "Val Batch 79/80: Loss = 2.3450, Species Acc = 40.62%, Toxicity Acc = 95.31%\n",
      "Val Batch 80/80: Loss = 2.4551, Species Acc = 34.38%, Toxicity Acc = 96.88%\n",
      "\n",
      "Epoch 4/200 Summary:\n",
      "  Train Loss: 2.2848, Species Acc: 32.00%, Toxicity Acc: 97.52%\n",
      "  Val Loss:   2.4095, Species Acc: 35.21%, Toxicity Acc: 94.32%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79      5120\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.65      5120\n",
      "   macro avg       0.50      0.32      0.39      5120\n",
      "weighted avg       1.00      0.65      0.79      5120\n",
      "\n",
      "[[14 14  0 ...  0  0  0]\n",
      " [ 9 33  0 ...  0  0  0]\n",
      " [ 2  3  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 11  0  0]\n",
      " [ 0  4  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      4693\n",
      "           1       0.68      0.61      0.64       427\n",
      "\n",
      "    accuracy                           0.94      5120\n",
      "   macro avg       0.82      0.79      0.81      5120\n",
      "weighted avg       0.94      0.94      0.94      5120\n",
      "\n",
      "[[4567  126]\n",
      " [ 165  262]]\n",
      "\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Save the model and statistics\u001b[39;00m\n\u001b[1;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_task_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 35\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, num_epochs, alpha, beta)\u001b[0m\n\u001b[1;32m     32\u001b[0m loss_toxicity \u001b[38;5;241m=\u001b[39m criterion_toxicity(outputs[\u001b[38;5;241m1\u001b[39m], toxicities)\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m loss_species \u001b[38;5;241m+\u001b[39m beta \u001b[38;5;241m*\u001b[39m loss_toxicity  \u001b[38;5;66;03m# weighting\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Update running loss\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "training_stats = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=200\n",
    ")\n",
    "\n",
    "# Save the model and statistics\n",
    "torch.save(model.state_dict(), \"multi_task_model.pth\")\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FungiClassifier(\n",
      "  (backbone): EfficientNet(\n",
      "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNormAct2d(\n",
      "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (blocks): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): DepthwiseSeparableConv(\n",
      "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): InvertedResidual(\n",
      "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "          (bn2): BatchNormAct2d(\n",
      "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (aa): Identity()\n",
      "          (se): SqueezeExcite(\n",
      "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act1): SiLU(inplace=True)\n",
      "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNormAct2d(\n",
      "            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNormAct2d(\n",
      "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (classifier): Identity()\n",
      "  )\n",
      "  (head): HybridHead(\n",
      "    (attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (ssm): LSTM(1280, 1280, batch_first=True)\n",
      "    (fc_species): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=100, bias=True)\n",
      "    )\n",
      "    (fc_toxicity): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=512, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "torch.save(model.state_dict(), 'model_dict.pth')\n",
    "#Save full model\n",
    "torch.save(model,'full_mode.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.27      0.31        51\n",
      "           1       0.39      0.50      0.44        66\n",
      "           2       0.00      0.00      0.00        45\n",
      "           3       0.19      0.20      0.19        50\n",
      "           4       0.18      0.11      0.13        47\n",
      "           5       0.59      0.41      0.49        46\n",
      "           6       0.24      0.30      0.26        53\n",
      "           7       0.21      0.45      0.29        49\n",
      "           8       0.20      0.04      0.07        24\n",
      "           9       0.28      0.19      0.23        63\n",
      "          10       0.00      0.00      0.00        42\n",
      "          11       0.31      0.63      0.42        52\n",
      "          12       0.40      0.38      0.39        50\n",
      "          13       0.63      0.63      0.63        57\n",
      "          14       0.79      0.90      0.84        41\n",
      "          15       0.50      0.46      0.48        48\n",
      "          16       0.44      0.69      0.54        48\n",
      "          17       0.23      0.30      0.26        57\n",
      "          18       0.64      0.86      0.73        59\n",
      "          19       0.70      0.71      0.71        69\n",
      "          20       0.33      0.33      0.33        49\n",
      "          21       0.22      0.20      0.21        64\n",
      "          22       0.40      0.43      0.42        60\n",
      "          23       0.40      0.42      0.41        59\n",
      "          24       0.55      0.55      0.55        42\n",
      "          25       0.48      0.49      0.49        79\n",
      "          26       0.32      0.15      0.21        66\n",
      "          27       0.28      0.55      0.37        38\n",
      "          28       0.33      0.12      0.18        42\n",
      "          29       0.37      0.35      0.36        55\n",
      "          30       0.38      0.59      0.46        56\n",
      "          31       0.55      0.74      0.63        62\n",
      "          32       0.31      0.29      0.30        72\n",
      "          33       0.11      0.02      0.03        49\n",
      "          34       0.45      0.81      0.58        43\n",
      "          35       0.42      0.74      0.54        57\n",
      "          36       0.50      0.02      0.04        52\n",
      "          37       0.42      0.28      0.34        67\n",
      "          38       0.22      0.53      0.31        40\n",
      "          39       0.17      0.12      0.14        58\n",
      "          40       0.33      0.46      0.39        35\n",
      "          41       0.64      0.76      0.69        62\n",
      "          42       0.25      0.55      0.35        38\n",
      "          43       0.50      0.13      0.21        38\n",
      "          44       0.00      0.00      0.00        56\n",
      "          45       0.40      0.33      0.36        52\n",
      "          46       0.28      0.10      0.15        48\n",
      "          47       0.41      0.19      0.26        57\n",
      "          48       0.29      0.37      0.33        54\n",
      "          49       0.27      0.71      0.39        41\n",
      "          50       0.17      0.02      0.04        43\n",
      "          51       0.40      0.04      0.07        51\n",
      "          52       0.21      0.11      0.14        45\n",
      "          53       0.20      0.21      0.21        43\n",
      "          54       0.55      0.67      0.61        46\n",
      "          55       0.27      0.16      0.20        51\n",
      "          56       0.49      0.36      0.41        50\n",
      "          57       0.29      0.46      0.36        54\n",
      "          58       0.25      0.43      0.32        46\n",
      "          59       0.42      0.72      0.54        47\n",
      "          60       0.14      0.08      0.10        50\n",
      "          61       0.50      0.71      0.59        52\n",
      "          62       0.54      0.34      0.42        44\n",
      "          63       0.24      0.29      0.26        49\n",
      "          64       0.36      0.68      0.47        53\n",
      "          65       0.46      0.81      0.58        52\n",
      "          66       0.25      0.51      0.33        45\n",
      "          67       0.12      0.07      0.09        45\n",
      "          68       0.44      0.23      0.31        64\n",
      "          69       0.36      0.71      0.48        55\n",
      "          70       0.30      0.41      0.35        46\n",
      "          71       0.21      0.71      0.32        52\n",
      "          72       0.67      0.04      0.08        48\n",
      "          73       0.00      0.00      0.00        56\n",
      "          74       0.10      0.06      0.07        51\n",
      "          75       0.50      0.37      0.43        54\n",
      "          76       0.41      0.44      0.43        43\n",
      "          77       0.19      0.08      0.11        64\n",
      "          78       0.21      0.58      0.31        43\n",
      "          79       0.18      0.06      0.09        49\n",
      "          80       0.04      0.02      0.03        43\n",
      "          81       0.28      0.45      0.35        53\n",
      "          82       0.22      0.24      0.23        46\n",
      "          83       0.45      0.58      0.51        43\n",
      "          84       0.38      0.24      0.30        62\n",
      "          85       0.64      0.65      0.65        55\n",
      "          86       0.30      0.47      0.36        57\n",
      "          87       1.00      0.03      0.06        34\n",
      "          88       0.41      0.50      0.45        64\n",
      "          89       0.27      0.13      0.18        53\n",
      "          90       0.23      0.16      0.19        45\n",
      "          91       0.25      0.25      0.25        52\n",
      "          92       0.33      0.04      0.07        49\n",
      "          93       0.06      0.02      0.03        54\n",
      "          94       0.00      0.00      0.00        46\n",
      "          95       0.24      0.34      0.28        58\n",
      "          96       0.25      0.37      0.30        52\n",
      "          97       0.67      0.24      0.36        49\n",
      "          98       0.00      0.00      0.00        50\n",
      "          99       0.34      0.25      0.29        56\n",
      "\n",
      "    accuracy                           0.35      5120\n",
      "   macro avg       0.34      0.35      0.31      5120\n",
      "weighted avg       0.34      0.35      0.32      5120\n",
      "\n",
      "[[14 13  0 ...  0  0  0]\n",
      " [ 9 33  0 ...  0  0  0]\n",
      " [ 2  3  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 12  0  0]\n",
      " [ 0  3  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      4693\n",
      "           1       0.67      0.63      0.65       427\n",
      "\n",
      "    accuracy                           0.94      5120\n",
      "   macro avg       0.82      0.80      0.81      5120\n",
      "weighted avg       0.94      0.94      0.94      5120\n",
      "\n",
      "[[4561  132]\n",
      " [ 160  267]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/dkocsis_local/Downloads/FungiCLEF2024_ADC-main/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "def eval(model,loader):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct_species = 0\n",
    "    val_correct_toxicity = 0\n",
    "    val_total_samples = 0\n",
    "    val_predictions_species = []\n",
    "    val_targets_species = []\n",
    "    val_predictions_toxicity = []\n",
    "    val_targets_toxicity = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "            for batch_idx, (images, (class_ids, toxicities), _) in enumerate(val_loader):\n",
    "                images = images.to(device)\n",
    "                class_ids = class_ids.to(device, dtype=torch.long)\n",
    "                toxicities = toxicities.to(device, dtype=torch.long)\n",
    "\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Calculate accuracies\n",
    "                _, preds_species = torch.max(outputs[0], 1)\n",
    "                _, preds_toxicity = torch.max(outputs[1], 1)\n",
    "                batch_correct_species = (preds_species == class_ids).sum().item()\n",
    "                batch_correct_toxicity = (preds_toxicity == toxicities).sum().item()\n",
    "                batch_samples = images.size(0)\n",
    "                val_correct_species += batch_correct_species\n",
    "                val_correct_toxicity += batch_correct_toxicity\n",
    "                val_total_samples += batch_samples\n",
    "\n",
    "                # Store predictions and targets for confusion matrices\n",
    "                val_predictions_species.extend(preds_species.cpu().numpy())\n",
    "                val_targets_species.extend(class_ids.cpu().numpy())\n",
    "                val_predictions_toxicity.extend(preds_toxicity.cpu().numpy())\n",
    "                val_targets_toxicity.extend(toxicities.cpu().numpy())\n",
    "\n",
    "    \n",
    "    \n",
    "        # Plot Confusion Matrix for Species Classification\n",
    "    classificatioj_cls=classification_report(val_targets_species, val_predictions_species)\n",
    "    class_conf=confusion_matrix(val_targets_species, val_predictions_species)\n",
    "    print(classificatioj_cls)\n",
    "    print(class_conf)\n",
    "    np.save(\"class_conf.npy\",class_conf)\n",
    "        # For Toxicity Classification\n",
    "    toxicity_predictions = np.array(val_predictions_toxicity)\n",
    "    toxicity_targets = np.array(val_targets_toxicity)\n",
    "\n",
    "        # Plot Confusion Matrix for Toxicity Classification\n",
    "    toxreport=classification_report(toxicity_targets, toxicity_predictions)\n",
    "    toxconf=confusion_matrix(toxicity_targets, toxicity_predictions)\n",
    "    np.save(\"toxconf.npy\",toxconf)\n",
    "    print(toxreport)\n",
    "    print(toxconf)\n",
    "\n",
    "\n",
    "eval(model,val_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class_conf=np.load(\"class_conf.npy\")\n",
    "poi_conf=np.load(\"toxconf.npy\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Species Classification Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.imshow(class_conf, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Toxicity Classification Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.imshow(poi_conf, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
