{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CIMBIBOY/FungiCLEF2024_ADC/blob/main/caformer_continue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import timm\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "g4fonl7JPYRm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D3SkKdnMmLy",
        "outputId": "a7e13535-cf4a-4a2b-9427-d07c9f8a3a25"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process(img, crop_s = 16, interp_mode = \"bilinear\", out_size = [300, 225]):\n",
        "    img = img.transpose(1, 0, 2)\n",
        "    # print(f\"Input shape: {img.shape}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    if img is not None:\n",
        "        # Crop\n",
        "        cropped_img = crop(img, crop_s)\n",
        "\n",
        "        # Interpolation\n",
        "        scale_factor = 300 / cropped_img.shape[0]\n",
        "        sigma = scale_factor * 0.5\n",
        "        cropped_img = interpolate(cropped_img, 5, sigma, int_mode = interp_mode, size = out_size)\n",
        "        cropped_img = cropped_img.transpose(1, 2, 0)\n",
        "\n",
        "        # Retransform\n",
        "        cropped_img = cv2.cvtColor(cropped_img, cv2.COLOR_RGB2BGR)\n",
        "        cropped_img = cropped_img.transpose(1, 0, 2)\n",
        "\n",
        "        # Adding to array for saving as .npy\n",
        "        # print(f\"Output shape: {cropped_img.shape}\")\n",
        "        return np.array(cropped_img)\n",
        "\n",
        "def crop(img, crop_s = 16):\n",
        "    w, h, c = img.shape\n",
        "\n",
        "    # Crop x pixels from the top and bottom\n",
        "    if h > 270:\n",
        "        img = img[:, crop_s:h - crop_s, :]\n",
        "    #print(img.shape)\n",
        "    return img\n",
        "\n",
        "def interpolate(img, kernel_size = 5, sigma = 0.1, int_mode = \"bilinear\", size = [300, 225]):\n",
        "    img = torch.tensor(img)\n",
        "    # Blur for noise reduc\n",
        "    blur = torchvision.transforms.GaussianBlur(kernel_size, sigma)\n",
        "    blured_img = blur(img)\n",
        "    blured_img = blured_img.transpose(0, 2)\n",
        "    blured_img = blured_img.transpose(1, 2)\n",
        "    # print(blured_img.shape)\n",
        "    interpolated_img = F.interpolate(blured_img.unsqueeze(0), size, mode= int_mode)\n",
        "    interpolated_img = interpolated_img.squeeze(0)\n",
        "    # print(interpolated_img.shape)\n",
        "    return interpolated_img.detach().numpy()\n",
        "\n",
        "def downsample(data):\n",
        "    d1 = cv2.pyrDown(data)\n",
        "    d2 = cv2.pyrDown(d1)\n",
        "    # d3 = cv2.pyrDown(d2)\n",
        "    print(\"Original shape: \", data.shape, \"Downsampled shape: \", d2.shape)\n",
        "    return np.array(d2)\n",
        "\n",
        "def upsample(data):\n",
        "    d1 = cv2.pyrUp(data)\n",
        "    d2 = cv2.pyrUp(d1)\n",
        "    # d3 = cv2.pyrDown(d2)\n",
        "    print(\"Original shape: \", data.shape, \"Downsampled shape: \", d2.shape)\n",
        "    return np.array(d2)\n",
        "\n",
        "\n",
        "def fungi_collate_fn(batch):\n",
        "    images, class_ids, toxicities, img_names = [], [], [], []\n",
        "    for image, (class_id, toxicity), img_name in batch:\n",
        "        # print(f\"Individual image shape: {image.shape}\")  # Should be [C, H, W]\n",
        "        images.append(image)\n",
        "        class_ids.append(class_id)\n",
        "        toxicities.append(toxicity)\n",
        "        img_names.append(img_name)\n",
        "\n",
        "    images = torch.stack(images)  # Should result in shape [batch_size, C, H, W]\n",
        "    #print(f\"Batch images shape after stacking: {images.shape}\")\n",
        "\n",
        "    class_ids = torch.tensor(class_ids, dtype=torch.long)\n",
        "    toxicities = torch.tensor(toxicities, dtype=torch.long)\n",
        "\n",
        "    return images, (class_ids, toxicities), img_names"
      ],
      "metadata": {
        "id": "dBLxLEghMhTy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FungiDataset(Dataset):\n",
        "    def __init__(self, image_dir, labels_path, pre_load=True, crop_height=16, interpolate=\"bilinear\", out_size=(300, 225), transform=None, class_ids_to_include=None):\n",
        "        '''\n",
        "        Args:\n",
        "            image_dir: directory containing the images\n",
        "            labels_path: path to the labels CSV file\n",
        "            pre_load: True if images should be loaded into memory, False otherwise\n",
        "            crop_height: Height for cropping images\n",
        "            interpolate: Interpolation method\n",
        "            out_size: Output size for resized images\n",
        "            transform: Optional transform to be applied on a sample.\n",
        "        '''\n",
        "        self.image_dir = image_dir\n",
        "        self.labels_path = labels_path\n",
        "        self.pre_load = pre_load\n",
        "        self.crop_h = crop_height\n",
        "        self.interpolate = interpolate\n",
        "        self.out_size = out_size\n",
        "        self.transform = transform\n",
        "        self.load_num = 0\n",
        "\n",
        "        # Load metadata\n",
        "        metadata = pd.read_csv(self.labels_path)\n",
        "\n",
        "        # Filter to include only existing imgs\n",
        "        image_files = set(os.listdir(self.image_dir))\n",
        "        metadata = metadata[metadata['image_path'].isin(image_files)]\n",
        "\n",
        "        if metadata.empty:\n",
        "            raise ValueError('No matching images found in the image directory')\n",
        "\n",
        "        # **Filter to include only specified class IDs**\n",
        "        if class_ids_to_include is not None:\n",
        "            metadata = metadata[metadata['class_id'].isin(class_ids_to_include)]\n",
        "            metadata.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        # Reset index after filtering\n",
        "        metadata.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        # Ensure labels are integers\n",
        "        metadata['class_id'] = metadata['class_id'].astype(int)\n",
        "        metadata['poisonous'] = metadata['poisonous'].astype(int)\n",
        "\n",
        "        # **Remap class IDs to a continuous range starting from 0**\n",
        "        unique_class_ids = sorted(metadata['class_id'].unique())\n",
        "        class_id_to_idx = {original_id: idx for idx, original_id in enumerate(unique_class_ids)}\n",
        "        metadata['class_id'] = metadata['class_id'].map(class_id_to_idx)\n",
        "\n",
        "        # Update class IDs and calculate the number of species classes\n",
        "        self.metadata = metadata\n",
        "        self.image_paths = metadata['image_path'].tolist()\n",
        "        self.class_ids = metadata['class_id'].tolist()\n",
        "        self.toxicities = metadata['poisonous'].tolist()\n",
        "        self.num_species_classes = len(unique_class_ids)\n",
        "\n",
        "        # Pre-load images if required\n",
        "        if self.pre_load:\n",
        "            self.images = []\n",
        "            for img_name in self.image_paths:\n",
        "                img_path = os.path.join(self.image_dir, img_name)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    print(f\"Warning: Image {img_path} could not be read.\")\n",
        "                    continue\n",
        "\n",
        "                img_processed = process(img, crop_s=self.crop_h, interp_mode=self.interpolate, out_size=self.out_size)\n",
        "                # Convert image to tensor and float32\n",
        "                image = torch.from_numpy(img_processed).float()\n",
        "                image = image.permute(2, 0, 1)\n",
        "\n",
        "                # Normalize using ImageNet mean and std\n",
        "                mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "                std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "                image = (image - mean) / std\n",
        "                self.images.append(image)\n",
        "                self.load_num += 1\n",
        "                if self.load_num / 3 == 0:\n",
        "                  print(f\"{self.load_num / 1000} images loaded\")\n",
        "        else:\n",
        "            self.images = None  # Images will be loaded in __getitem__\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.pre_load:\n",
        "            image = self.images[idx]\n",
        "        else:\n",
        "            img_name = self.image_paths[idx]\n",
        "            img_path = os.path.join(self.image_dir, img_name)\n",
        "\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                raise ValueError(f\"Image at {img_path} could not be read.\")\n",
        "\n",
        "            image_processed = process(img, crop_s=self.crop_h, interp_mode=self.interpolate, out_size=self.out_size)\n",
        "\n",
        "            # Convert image to tensor and float32\n",
        "            img_tensor = torch.from_numpy(image_processed).float().permute(2, 0, 1)\n",
        "\n",
        "            # Normalize using ImageNet mean and std\n",
        "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "            image = (img_tensor - mean) / std\n",
        "\n",
        "            '''\n",
        "            print(image.shape)\n",
        "            print(f\"Image dtype: {image.dtype}\")  # Should be torch.float32\n",
        "            print(f\"Image min: {image.min()}, max: {image.max()}\")  # Should be within expected range\n",
        "            '''\n",
        "\n",
        "        # labels\n",
        "        class_id = self.class_ids[idx]\n",
        "        toxicity = self.toxicities[idx]\n",
        "\n",
        "        return image, (class_id, toxicity), img_name\n"
      ],
      "metadata": {
        "id": "cSgQT5XrLZbs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jqvaiw5LW1E",
        "outputId": "4aa31b89-6b56-4a49-c6aa-349ffdcdd8ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in dataset: 25763\n",
            "Length of train_loader: 161 and val_loader: 40\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "config = {\n",
        "    \"image_dir\": \"/content/drive/MyDrive/Tree_trunk/Fungi/x_train\",\n",
        "    \"labels_path\": \"/content/drive/MyDrive/Tree_trunk/Fungi/train_metadata_height.csv\",\n",
        "    \"pre_load\": False,\n",
        "    \"batch_size\": 128,\n",
        "    \"crop_height\": 16,\n",
        "    \"interpolate\": \"bilinear\",\n",
        "    \"out_size\": (224, 224)\n",
        "}\n",
        "\n",
        "# Define the classes to include (your list of unique class IDs)\n",
        "class_ids_to_include = [4, 11, 16, 25, 30, 32, 37, 39, 43, 63, 100, 103, 128, 129, 131, 136, 142, 168, 180, 213, 214, 223, 252, 266, 309, 366, 389, 413, 473, 478, 487, 522, 555, 559, 591, 633, 637, 657, 671, 673, 689, 694, 724, 728, 738, 748, 764, 787, 812, 814, 830, 837, 845, 856, 884, 908, 909, 912, 967, 975, 989, 992, 1000, 1005, 1014, 1020, 1052, 1054, 1088, 1093, 1115, 1121, 1135, 1136, 1141, 1160, 1183, 1207, 1214, 1220, 1221, 1232, 1239, 1242, 1290, 1302, 1355, 1381, 1395, 1420, 1438, 1440, 1481, 1484, 1493, 1533, 1537, 1546, 1573, 1603]\n",
        "\n",
        "# Initialize the full dataset\n",
        "full_dataset = FungiDataset(\n",
        "    image_dir=config[\"image_dir\"],\n",
        "    labels_path=config[\"labels_path\"],\n",
        "    pre_load=config[\"pre_load\"],\n",
        "    crop_height=config[\"crop_height\"],\n",
        "    interpolate=config[\"interpolate\"],\n",
        "    out_size=config[\"out_size\"],\n",
        "    transform=None,\n",
        "    class_ids_to_include=class_ids_to_include  # Pass the list of class IDs\n",
        ")\n",
        "\n",
        "print(f\"Number of samples in dataset: {len(full_dataset)}\")\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_indices, val_indices = train_test_split(\n",
        "    list(range(len(full_dataset))), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = Subset(full_dataset, train_indices)\n",
        "val_dataset = Subset(full_dataset, val_indices)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        "    prefetch_factor=1,  # Prefetch batches to improve performance\n",
        "    pin_memory=True,  # Optimize for GPU\n",
        "    collate_fn=fungi_collate_fn,\n",
        "    drop_last=True  # Drops the last incomplete batch\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    num_workers=1,\n",
        "    prefetch_factor=1,\n",
        "    pin_memory=True,\n",
        "    collate_fn=fungi_collate_fn,\n",
        "    drop_last=True # also\n",
        ")\n",
        "\n",
        "print(f\"Length of train_loader: {len(train_loader)} and val_loader: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE7ronjtLW1E",
        "outputId": "98a2d42f-bc8c-460d-ebd8-e781dc4f2c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of species classes: 100\n",
            "Pretrained weights loaded successfully.\n",
            "MultiTaskModel(\n",
            "  (base_model): MetaFormer(\n",
            "    (stem): Stem(\n",
            "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
            "      (norm): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
            "    )\n",
            "    (stages): Sequential(\n",
            "      (0): MetaFormerStage(\n",
            "        (downsample): Identity()\n",
            "        (blocks): Sequential(\n",
            "          (0): MetaFormerBlock(\n",
            "            (norm1): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): SepConv(\n",
            "              (pwconv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act1): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
            "              (act2): Identity()\n",
            "              (pwconv2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Identity()\n",
            "            (norm2): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Identity()\n",
            "          )\n",
            "          (1): MetaFormerBlock(\n",
            "            (norm1): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): SepConv(\n",
            "              (pwconv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act1): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
            "              (act2): Identity()\n",
            "              (pwconv2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Identity()\n",
            "            (norm2): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Identity()\n",
            "          )\n",
            "          (2): MetaFormerBlock(\n",
            "            (norm1): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): SepConv(\n",
            "              (pwconv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act1): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
            "              (act2): Identity()\n",
            "              (pwconv2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Identity()\n",
            "            (norm2): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): MetaFormerStage(\n",
            "        (downsample): Downsampling(\n",
            "          (norm): LayerNorm2dNoBias((64,), eps=1e-06, elementwise_affine=True)\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "        (blocks): Sequential(\n",
            "          (0): MetaFormerBlock(\n",
            "            (norm1): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): SepConv(\n",
            "              (pwconv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act1): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
            "              (act2): Identity()\n",
            "              (pwconv2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Identity()\n",
            "            (norm2): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Identity()\n",
            "          )\n",
            "          (1): MetaFormerBlock(\n",
            "            (norm1): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): SepConv(\n",
            "              (pwconv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act1): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
            "              (act2): Identity()\n",
            "              (pwconv2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Identity()\n",
            "            (norm2): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Identity()\n",
            "          )\n",
            "          (2): MetaFormerBlock(\n",
            "            (norm1): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): SepConv(\n",
            "              (pwconv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act1): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
            "              (act2): Identity()\n",
            "              (pwconv2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Identity()\n",
            "            (norm2): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): MetaFormerStage(\n",
            "        (downsample): Downsampling(\n",
            "          (norm): LayerNorm2dNoBias((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (conv): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "        (blocks): Sequential(\n",
            "          (0): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (1): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (2): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (3): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (4): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (5): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (6): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (7): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (8): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=320, out_features=960, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=320, out_features=1280, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1280, out_features=320, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): MetaFormerStage(\n",
            "        (downsample): Downsampling(\n",
            "          (norm): LayerNorm2dNoBias((320,), eps=1e-06, elementwise_affine=True)\n",
            "          (conv): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        )\n",
            "        (blocks): Sequential(\n",
            "          (0): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (1): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "          (2): MetaFormerBlock(\n",
            "            (norm1): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
            "            (token_mixer): Attention(\n",
            "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path1): Identity()\n",
            "            (layer_scale1): Identity()\n",
            "            (res_scale1): Scale()\n",
            "            (norm2): LayerNormNoBias((512,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (act): StarReLU(\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (drop_path2): Identity()\n",
            "            (layer_scale2): Identity()\n",
            "            (res_scale2): Scale()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (head): Sequential(\n",
            "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
            "      (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (drop): Dropout(p=0.0, inplace=False)\n",
            "      (fc): MlpHead(\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (act): SquaredReLU(\n",
            "          (relu): ReLU()\n",
            "        )\n",
            "        (norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=100, bias=True)\n",
            "        (head_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc_toxicity): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Set num_species_classes based on the dataset\n",
        "num_species_classes = full_dataset.num_species_classes\n",
        "print(f\"Number of species classes: {num_species_classes}\")  # Should print 100\n",
        "num_toxicity_classes = 2   # Assuming binary classification (edible or poisonous)\n",
        "\n",
        "# Create the CAFormer model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model = timm.create_model(\n",
        "    \"caformer_s18.sail_in22k\",\n",
        "    pretrained=True,\n",
        "    num_classes=num_species_classes  # For species classification\n",
        ")\n",
        "base_model.to(device)\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, base_model, num_species_classes, num_toxicity_classes):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "        self.base_model = base_model\n",
        "\n",
        "        # Replace the classifier for species classification\n",
        "        self.base_model.reset_classifier(num_species_classes)\n",
        "\n",
        "        num_features = base_model.num_features  # Number of features after pooling\n",
        "\n",
        "        # Create a new classifier for toxicity\n",
        "        self.fc_toxicity = nn.Linear(num_features, num_toxicity_classes)\n",
        "\n",
        "        # Define a pooling layer if not present\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features\n",
        "        features = self.base_model.forward_features(x)  # Shape: [batch_size, channels, height, width]\n",
        "        #print(f\"Features shape: {features.shape}\")\n",
        "\n",
        "        # Species classification (using base model's head)\n",
        "        species_logits = self.base_model.forward_head(features)\n",
        "        # print(f\"Species logits shape: {species_logits.shape}\")\n",
        "\n",
        "        # Apply global average pooling for toxicity classification\n",
        "        pooled_features = self.global_pool(features).flatten(1)  # Shape: [batch_size, channels]\n",
        "        # print(f\"Pooled features shape: {pooled_features.shape}\")\n",
        "\n",
        "        # Toxicity classification\n",
        "        toxicity_logits = self.fc_toxicity(pooled_features)\n",
        "        # print(f\"Toxicity logits shape: {toxicity_logits.shape}\")\n",
        "\n",
        "        return {'species': species_logits, 'toxicity': toxicity_logits}\n",
        "\n",
        "# Initialize the multi-task model\n",
        "model = MultiTaskModel(base_model, num_species_classes, num_toxicity_classes)\n",
        "model.to(device)\n",
        "\n",
        "# Load pretrained weights\n",
        "pretrained_weights_path = \"/content/multi_task_model.pth\"  # Path to your saved weights\n",
        "try:\n",
        "    state_dict = torch.load(pretrained_weights_path, map_location=device, weights_only=True)\n",
        "    model.load_state_dict(state_dict)\n",
        "    print(\"Pretrained weights loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Pretrained weights file not found: {pretrained_weights_path}\")\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adjust learning rate as needed\n",
        "\n",
        "# Define loss functions\n",
        "criterion_species = nn.CrossEntropyLoss()\n",
        "criterion_toxicity = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiIaMWBrLW1F",
        "outputId": "4cf5b623-665c-4f50-e8f3-ac12426d2c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class IDs in batch: tensor([13, 19, 80, 70,  5, 19, 12, 33, 34, 59, 77,  7, 77, 69, 99, 39, 32, 27,\n",
            "        62, 32, 60, 48, 26, 74, 83, 59, 37, 32, 13, 77, 69,  5, 51, 15, 29, 78,\n",
            "        93, 56, 85, 28, 91, 92, 31, 88, 81, 87, 48, 32, 54,  6, 39,  5, 26, 17,\n",
            "        22, 48,  5,  4, 83, 70, 28, 18, 46, 17, 18, 54, 20, 54,  2, 17, 65, 81,\n",
            "        23,  6, 98, 78, 23, 89, 77, 32, 11,  1, 25, 68,  7, 93, 99, 86, 13, 70,\n",
            "        14,  9, 90, 59, 14, 64, 77, 94,  5, 38, 31, 67, 11, 43, 87, 25, 92, 76,\n",
            "        62, 61, 48, 52, 19, 56, 50, 27, 38, 84, 87, 29, 64, 46, 18, 80, 67,  2,\n",
            "        74, 77])\n",
            "Min class ID: 1, Max class ID: 99\n"
          ]
        }
      ],
      "source": [
        "# Get a batch of data\n",
        "images, (class_ids, toxicities), _ = next(iter(train_loader))\n",
        "\n",
        "# Check the range of class_ids\n",
        "print(f\"Class IDs in batch: {class_ids}\")\n",
        "print(f\"Min class ID: {class_ids.min()}, Max class ID: {class_ids.max()}\")\n",
        "\n",
        "# Ensure class IDs are in the range [0, num_species_classes - 1]\n",
        "assert class_ids.min() >= 0 and class_ids.max() < num_species_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EUYCgN03LW1F"
      },
      "outputs": [],
      "source": [
        "def conf_matrix(targets, predictions, task_name, matrix_type='species', colors=None):\n",
        "    \"\"\"\n",
        "    Compute and plot a confusion matrix with customizable display and colors.\n",
        "\n",
        "    Args:\n",
        "        targets: True labels.\n",
        "        predictions: Predicted labels.\n",
        "        task_name: Name of the task (e.g., 'Species', 'Toxicity').\n",
        "        matrix_type: Type of matrix ('species' or 'toxicity') for specific display logic.\n",
        "        colors: Custom color palette.\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import confusion_matrix, classification_report\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib.colors import ListedColormap\n",
        "    import numpy as np\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(targets, predictions)\n",
        "\n",
        "    if matrix_type == 'species':\n",
        "        # For Species Misclassification Matrix\n",
        "        plt.figure(figsize=(6, 1))  # Wide and short, single row\n",
        "        sns.set(font_scale=1.4)\n",
        "\n",
        "        # Define colors: Red for misclassified, Green for recognized\n",
        "        cmap = sns.color_palette(['green', 'red']) if not colors else sns.color_palette(colors)\n",
        "\n",
        "        sns.heatmap(\n",
        "            cm[:1],  # Only show the first row\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap=cmap,\n",
        "            cbar=False,\n",
        "            xticklabels=['Missclassified', 'Recognized'],  # Bottom labels\n",
        "            yticklabels=[]  # Remove true labels from the side\n",
        "        )\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.title(f'{task_name} Misclassification Matrix')\n",
        "        plt.show()\n",
        "\n",
        "    if matrix_type == 'toxicity':\n",
        "        # For Toxicity Matrix\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        sns.set(font_scale=1.4)\n",
        "\n",
        "        # Assign unique indices to each cell type\n",
        "        cell_type_indices = np.array([[0, 1], [2, 3]])  # TN, FP, FN, TP\n",
        "\n",
        "        # Define custom colors for each cell type\n",
        "        if colors is None:\n",
        "            colors = ['black', 'yellow', 'purple', 'black']  # TN, FP, FN, TP\n",
        "\n",
        "        # Create a custom colormap from the specified colors\n",
        "        custom_cmap = ListedColormap(colors)\n",
        "\n",
        "        # Plot the heatmap using the cell_type_indices to map colors\n",
        "        sns.heatmap(\n",
        "            cell_type_indices,\n",
        "            annot=cm,\n",
        "            fmt='d',\n",
        "            cmap=custom_cmap,\n",
        "            cbar=False,\n",
        "            xticklabels=['Negative', 'Positive'],\n",
        "            yticklabels=['Negative', 'Positive']\n",
        "        )\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'{task_name} Classification Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "    return cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "g6ShVbXWLW1F"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, num_epochs=10, alpha = 1.0, beta = 0.6):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies_species = []\n",
        "    train_accuracies_toxicity = []\n",
        "    val_accuracies_species = []\n",
        "    val_accuracies_toxicity = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_species = 0\n",
        "        correct_toxicity = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        # Iterate over batches\n",
        "        for batch_idx, (images, (class_ids, toxicities), _) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            class_ids = class_ids.to(device, dtype=torch.long)\n",
        "            toxicities = toxicities.to(device, dtype=torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss_species = criterion_species(outputs['species'], class_ids)\n",
        "            loss_toxicity = criterion_toxicity(outputs['toxicity'], toxicities)\n",
        "            loss = alpha * loss_species + beta * loss_toxicity  # weighting\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update running loss\n",
        "            batch_loss = loss.item() * images.size(0)\n",
        "            running_loss += batch_loss\n",
        "\n",
        "            # Calculate accuracies\n",
        "            _, preds_species = torch.max(outputs['species'], 1)\n",
        "            _, preds_toxicity = torch.max(outputs['toxicity'], 1)\n",
        "            batch_correct_species = (preds_species == class_ids).sum().item()\n",
        "            batch_correct_toxicity = (preds_toxicity == toxicities).sum().item()\n",
        "            batch_samples = images.size(0)\n",
        "            correct_species += batch_correct_species\n",
        "            correct_toxicity += batch_correct_toxicity\n",
        "            total_samples += batch_samples\n",
        "\n",
        "            # Calculate batch accuracies\n",
        "            batch_accuracy_species = batch_correct_species / batch_samples * 100\n",
        "            batch_accuracy_toxicity = batch_correct_toxicity / batch_samples * 100\n",
        "\n",
        "            # Print per-batch metrics\n",
        "            print(f\"Train Batch {batch_idx+1}/{len(train_loader)}: Loss = {loss.item():.4f}, Species Acc = {batch_accuracy_species:.2f}%, Toxicity Acc = {batch_accuracy_toxicity:.2f}%\")\n",
        "\n",
        "        avg_train_loss = running_loss / total_samples\n",
        "        train_losses.append(avg_train_loss)\n",
        "        train_accuracy_species = correct_species / total_samples * 100\n",
        "        train_accuracy_toxicity = correct_toxicity / total_samples * 100\n",
        "        train_accuracies_species.append(train_accuracy_species)\n",
        "        train_accuracies_toxicity.append(train_accuracy_toxicity)\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_correct_species = 0\n",
        "        val_correct_toxicity = 0\n",
        "        val_total_samples = 0\n",
        "        val_predictions_species = []\n",
        "        val_targets_species = []\n",
        "        val_predictions_toxicity = []\n",
        "        val_targets_toxicity = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, (class_ids, toxicities), _) in enumerate(val_loader):\n",
        "                images = images.to(device)\n",
        "                class_ids = class_ids.to(device, dtype=torch.long)\n",
        "                toxicities = toxicities.to(device, dtype=torch.long)\n",
        "\n",
        "                outputs = model(images)\n",
        "\n",
        "                loss_species = criterion_species(outputs['species'], class_ids)\n",
        "                loss_toxicity = criterion_toxicity(outputs['toxicity'], toxicities)\n",
        "                loss = alpha * loss_species + beta * loss_toxicity  # Adjust weighting\n",
        "\n",
        "                # Update running loss\n",
        "                batch_loss = loss.item() * images.size(0)\n",
        "                val_running_loss += batch_loss\n",
        "\n",
        "                # Calculate accuracies\n",
        "                _, preds_species = torch.max(outputs['species'], 1)\n",
        "                _, preds_toxicity = torch.max(outputs['toxicity'], 1)\n",
        "                batch_correct_species = (preds_species == class_ids).sum().item()\n",
        "                batch_correct_toxicity = (preds_toxicity == toxicities).sum().item()\n",
        "                batch_samples = images.size(0)\n",
        "                val_correct_species += batch_correct_species\n",
        "                val_correct_toxicity += batch_correct_toxicity\n",
        "                val_total_samples += batch_samples\n",
        "\n",
        "                # Store predictions and targets for confusion matrices\n",
        "                val_predictions_species.extend(preds_species.cpu().numpy())\n",
        "                val_targets_species.extend(class_ids.cpu().numpy())\n",
        "                val_predictions_toxicity.extend(preds_toxicity.cpu().numpy())\n",
        "                val_targets_toxicity.extend(toxicities.cpu().numpy())\n",
        "\n",
        "                # Calculate batch accuracies\n",
        "                batch_accuracy_species = batch_correct_species / batch_samples * 100\n",
        "                batch_accuracy_toxicity = batch_correct_toxicity / batch_samples * 100\n",
        "\n",
        "                # Print per-batch metrics\n",
        "                print(f\"Val Batch {batch_idx+1}/{len(val_loader)}: Loss = {loss.item():.4f}, Species Acc = {batch_accuracy_species:.2f}%, Toxicity Acc = {batch_accuracy_toxicity:.2f}%\")\n",
        "\n",
        "        avg_val_loss = val_running_loss / val_total_samples\n",
        "        val_losses.append(avg_val_loss)\n",
        "        val_accuracy_species = val_correct_species / val_total_samples * 100\n",
        "        val_accuracy_toxicity = val_correct_toxicity / val_total_samples * 100\n",
        "        val_accuracies_species.append(val_accuracy_species)\n",
        "        val_accuracies_toxicity.append(val_accuracy_toxicity)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}, Species Acc: {train_accuracy_species:.2f}%, Toxicity Acc: {train_accuracy_toxicity:.2f}%\")\n",
        "        print(f\"  Val Loss:   {avg_val_loss:.4f}, Species Acc: {val_accuracy_species:.2f}%, Toxicity Acc: {val_accuracy_toxicity:.2f}%\")\n",
        "\n",
        "        # Confusion Matrices\n",
        "        from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "        # For Species Classification\n",
        "        val_predictions_species = np.array(val_predictions_species)\n",
        "        val_targets_species = np.array(val_targets_species)\n",
        "\n",
        "        # Compute the confusion matrix for species classification\n",
        "        species_conf_matrix = confusion_matrix(val_targets_species, val_predictions_species)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.imshow(species_conf_matrix, cmap=\"viridis\")\n",
        "        plt.colorbar()\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "        plt.title(\"Konfzis mtrix mrgezsgre\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # For Toxicity Classification\n",
        "        val_predictions_toxicity = np.array(val_predictions_toxicity)\n",
        "        val_targets_toxicity = np.array(val_targets_toxicity)\n",
        "\n",
        "        # Compute the confusion matrix for toxicity classification\n",
        "        toxicity_conf_matrix = confusion_matrix(val_targets_toxicity, val_predictions_toxicity)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.imshow(toxicity_conf_matrix, cmap=\"viridis\")\n",
        "        plt.colorbar()\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "        plt.title(\"Konfzis mtrix mrgezsgre\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        '''\n",
        "        # Plot Confusion Matrix for Species Classification\n",
        "        conf_matrix(\n",
        "            species_binary_targets,\n",
        "            species_binary_predictions,\n",
        "            task_name='Species',\n",
        "            matrix_type='species',\n",
        "            colors=['red', 'green']  # Red for misclassified, Green for recognized\n",
        "        )\n",
        "        '''\n",
        "        '''\n",
        "        # Plot Confusion Matrix for Toxicity Classification\n",
        "        conf_matrix(\n",
        "            toxicity_targets,\n",
        "            toxicity_predictions,\n",
        "            task_name='Toxicity',\n",
        "            matrix_type='toxicity',\n",
        "            colors=['orange', 'yellow', 'purple', 'black']  # TN, FP, FN, TP\n",
        "        )\n",
        "        '''\n",
        "\n",
        "        from sklearn.metrics import classification_report\n",
        "\n",
        "        classification_report_species = classification_report(val_targets_species, val_predictions_species)\n",
        "        classification_report_toxicity = classification_report(val_targets_toxicity, val_predictions_toxicity)\n",
        "        print(f\"Species Classification Report:\\n{classification_report_species}\")\n",
        "        print(f\"Toxicity Classification Report:\\n{classification_report_toxicity}\")\n",
        "\n",
        "    return {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accuracies_species': train_accuracies_species,\n",
        "        'train_accuracies_toxicity': train_accuracies_toxicity,\n",
        "        'val_accuracies_species': val_accuracies_species,\n",
        "        'val_accuracies_toxicity': val_accuracies_toxicity\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TUKn78vcLW1F"
      },
      "outputs": [],
      "source": [
        "# Set the number of epochs\n",
        "num_epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Check memory usage (optional)\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "#'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BAbEU5dj1mSM",
        "outputId": "ac6ca286-3ee6-4fb7-91e6-2c4200cd9eb6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Clear CUDA cache\\ntorch.cuda.empty_cache()\\n\\n# Check memory usage (optional)\\ntorch.cuda.memory_summary(device=None, abbreviated=False)\\n#'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Tr1pbU5LW1F",
        "outputId": "009e477d-c1d4-425f-d019-459809656baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/1\n",
            "Train Batch 1/161: Loss = 0.0189, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 2/161: Loss = 0.0181, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 3/161: Loss = 0.0040, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 4/161: Loss = 0.0812, Species Acc = 96.88%, Toxicity Acc = 100.00%\n",
            "Train Batch 5/161: Loss = 0.0022, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 6/161: Loss = 0.0061, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 7/161: Loss = 0.0011, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 8/161: Loss = 0.0060, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 9/161: Loss = 0.0011, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 10/161: Loss = 0.0102, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 11/161: Loss = 0.0134, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 12/161: Loss = 0.0117, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 13/161: Loss = 0.0083, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 14/161: Loss = 0.0144, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 15/161: Loss = 0.0027, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 16/161: Loss = 0.0021, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 17/161: Loss = 0.0319, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 18/161: Loss = 0.0033, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 19/161: Loss = 0.0433, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 20/161: Loss = 0.0068, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 21/161: Loss = 0.0034, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 22/161: Loss = 0.0239, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 23/161: Loss = 0.0211, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 24/161: Loss = 0.0013, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 25/161: Loss = 0.0013, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 26/161: Loss = 0.0012, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 27/161: Loss = 0.0037, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 28/161: Loss = 0.0361, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 29/161: Loss = 0.0039, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 30/161: Loss = 0.0115, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 31/161: Loss = 0.0010, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 32/161: Loss = 0.0166, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 33/161: Loss = 0.0014, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 34/161: Loss = 0.0695, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 35/161: Loss = 0.0067, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 36/161: Loss = 0.0046, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 37/161: Loss = 0.0137, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 38/161: Loss = 0.0019, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 39/161: Loss = 0.0025, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 40/161: Loss = 0.0095, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 41/161: Loss = 0.0527, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 42/161: Loss = 0.0049, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 43/161: Loss = 0.0030, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 44/161: Loss = 0.0127, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 45/161: Loss = 0.0141, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 46/161: Loss = 0.0030, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 47/161: Loss = 0.0739, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 48/161: Loss = 0.0006, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 49/161: Loss = 0.0160, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 50/161: Loss = 0.0181, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 51/161: Loss = 0.0068, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 52/161: Loss = 0.0064, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 53/161: Loss = 0.0033, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 54/161: Loss = 0.0015, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 55/161: Loss = 0.0170, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 56/161: Loss = 0.0179, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 57/161: Loss = 0.0089, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 58/161: Loss = 0.0035, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 59/161: Loss = 0.0038, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 60/161: Loss = 0.0162, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 61/161: Loss = 0.0192, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 62/161: Loss = 0.0121, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 63/161: Loss = 0.0025, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 64/161: Loss = 0.0236, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 65/161: Loss = 0.0006, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 66/161: Loss = 0.0032, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 67/161: Loss = 0.0327, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 68/161: Loss = 0.0267, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 69/161: Loss = 0.0046, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 70/161: Loss = 0.0018, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 71/161: Loss = 0.0045, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 72/161: Loss = 0.0015, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 73/161: Loss = 0.0017, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 74/161: Loss = 0.0218, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 75/161: Loss = 0.0063, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 76/161: Loss = 0.0032, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 77/161: Loss = 0.0590, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 78/161: Loss = 0.0059, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 79/161: Loss = 0.0044, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 80/161: Loss = 0.0019, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 81/161: Loss = 0.0018, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 82/161: Loss = 0.0149, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 83/161: Loss = 0.0070, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 84/161: Loss = 0.0470, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 85/161: Loss = 0.0094, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 86/161: Loss = 0.0033, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 87/161: Loss = 0.0068, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 88/161: Loss = 0.0038, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 89/161: Loss = 0.0019, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 90/161: Loss = 0.0062, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 91/161: Loss = 0.0005, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 92/161: Loss = 0.0018, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 93/161: Loss = 0.0176, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 94/161: Loss = 0.0187, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 95/161: Loss = 0.0003, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 96/161: Loss = 0.0007, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 97/161: Loss = 0.0054, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 98/161: Loss = 0.0076, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 99/161: Loss = 0.0207, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 100/161: Loss = 0.0098, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 101/161: Loss = 0.0098, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 102/161: Loss = 0.0023, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 103/161: Loss = 0.0364, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 104/161: Loss = 0.0015, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 105/161: Loss = 0.0009, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 106/161: Loss = 0.0080, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 107/161: Loss = 0.0067, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 108/161: Loss = 0.0035, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 109/161: Loss = 0.0031, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 110/161: Loss = 0.0103, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 111/161: Loss = 0.0031, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 112/161: Loss = 0.0027, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 113/161: Loss = 0.0022, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 114/161: Loss = 0.0176, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 115/161: Loss = 0.0007, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 116/161: Loss = 0.0008, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 117/161: Loss = 0.0134, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 118/161: Loss = 0.0244, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 119/161: Loss = 0.0339, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 120/161: Loss = 0.0093, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 121/161: Loss = 0.0028, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 122/161: Loss = 0.0041, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 123/161: Loss = 0.0009, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 124/161: Loss = 0.0021, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 125/161: Loss = 0.0660, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 126/161: Loss = 0.0078, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 127/161: Loss = 0.0042, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 128/161: Loss = 0.0070, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 129/161: Loss = 0.0074, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 130/161: Loss = 0.0180, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 131/161: Loss = 0.0004, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 132/161: Loss = 0.0094, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 133/161: Loss = 0.0012, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 134/161: Loss = 0.0016, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 135/161: Loss = 0.0021, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 136/161: Loss = 0.0167, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 137/161: Loss = 0.0019, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 138/161: Loss = 0.0017, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 139/161: Loss = 0.0015, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 140/161: Loss = 0.0211, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 141/161: Loss = 0.0016, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 142/161: Loss = 0.0071, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 143/161: Loss = 0.0003, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 144/161: Loss = 0.0005, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 145/161: Loss = 0.0313, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 146/161: Loss = 0.0009, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 147/161: Loss = 0.0266, Species Acc = 98.44%, Toxicity Acc = 100.00%\n",
            "Train Batch 148/161: Loss = 0.0127, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 149/161: Loss = 0.0029, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 150/161: Loss = 0.0005, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 151/161: Loss = 0.0195, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 152/161: Loss = 0.0058, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 153/161: Loss = 0.0035, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 154/161: Loss = 0.0005, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 155/161: Loss = 0.0061, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 156/161: Loss = 0.0026, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 157/161: Loss = 0.0158, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 158/161: Loss = 0.0021, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 159/161: Loss = 0.0144, Species Acc = 99.22%, Toxicity Acc = 100.00%\n",
            "Train Batch 160/161: Loss = 0.0005, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Train Batch 161/161: Loss = 0.0065, Species Acc = 100.00%, Toxicity Acc = 100.00%\n",
            "Val Batch 1/40: Loss = 1.5925, Species Acc = 73.44%, Toxicity Acc = 96.09%\n",
            "Val Batch 2/40: Loss = 0.9985, Species Acc = 83.59%, Toxicity Acc = 96.88%\n",
            "Val Batch 3/40: Loss = 1.2114, Species Acc = 81.25%, Toxicity Acc = 96.88%\n",
            "Val Batch 4/40: Loss = 1.1823, Species Acc = 79.69%, Toxicity Acc = 98.44%\n",
            "Val Batch 5/40: Loss = 1.0631, Species Acc = 78.91%, Toxicity Acc = 93.75%\n",
            "Val Batch 6/40: Loss = 1.3921, Species Acc = 81.25%, Toxicity Acc = 95.31%\n",
            "Val Batch 7/40: Loss = 1.2837, Species Acc = 73.44%, Toxicity Acc = 96.88%\n",
            "Val Batch 8/40: Loss = 1.3991, Species Acc = 80.47%, Toxicity Acc = 96.88%\n",
            "Val Batch 9/40: Loss = 1.1175, Species Acc = 82.81%, Toxicity Acc = 96.88%\n",
            "Val Batch 10/40: Loss = 1.3556, Species Acc = 78.12%, Toxicity Acc = 96.88%\n",
            "Val Batch 11/40: Loss = 1.0127, Species Acc = 82.81%, Toxicity Acc = 97.66%\n",
            "Val Batch 12/40: Loss = 1.1393, Species Acc = 78.12%, Toxicity Acc = 100.00%\n",
            "Val Batch 13/40: Loss = 1.2782, Species Acc = 75.78%, Toxicity Acc = 97.66%\n",
            "Val Batch 14/40: Loss = 1.4947, Species Acc = 78.12%, Toxicity Acc = 96.88%\n",
            "Val Batch 15/40: Loss = 1.2707, Species Acc = 79.69%, Toxicity Acc = 97.66%\n",
            "Val Batch 16/40: Loss = 0.9693, Species Acc = 80.47%, Toxicity Acc = 99.22%\n",
            "Val Batch 17/40: Loss = 1.3034, Species Acc = 74.22%, Toxicity Acc = 97.66%\n",
            "Val Batch 18/40: Loss = 1.5589, Species Acc = 76.56%, Toxicity Acc = 96.88%\n",
            "Val Batch 19/40: Loss = 1.5737, Species Acc = 71.88%, Toxicity Acc = 98.44%\n",
            "Val Batch 20/40: Loss = 1.4518, Species Acc = 78.12%, Toxicity Acc = 95.31%\n",
            "Val Batch 21/40: Loss = 1.3942, Species Acc = 75.78%, Toxicity Acc = 96.88%\n",
            "Val Batch 22/40: Loss = 1.5807, Species Acc = 70.31%, Toxicity Acc = 96.88%\n",
            "Val Batch 23/40: Loss = 1.4611, Species Acc = 78.91%, Toxicity Acc = 96.09%\n",
            "Val Batch 24/40: Loss = 1.1146, Species Acc = 78.12%, Toxicity Acc = 98.44%\n",
            "Val Batch 25/40: Loss = 1.2316, Species Acc = 78.91%, Toxicity Acc = 97.66%\n",
            "Val Batch 26/40: Loss = 0.9794, Species Acc = 85.16%, Toxicity Acc = 98.44%\n",
            "Val Batch 27/40: Loss = 1.2945, Species Acc = 78.12%, Toxicity Acc = 96.88%\n",
            "Val Batch 28/40: Loss = 1.2035, Species Acc = 76.56%, Toxicity Acc = 95.31%\n",
            "Val Batch 29/40: Loss = 1.4159, Species Acc = 81.25%, Toxicity Acc = 95.31%\n",
            "Val Batch 30/40: Loss = 1.0971, Species Acc = 79.69%, Toxicity Acc = 97.66%\n",
            "Val Batch 31/40: Loss = 1.4975, Species Acc = 75.00%, Toxicity Acc = 96.09%\n",
            "Val Batch 32/40: Loss = 1.5800, Species Acc = 80.47%, Toxicity Acc = 96.88%\n",
            "Val Batch 33/40: Loss = 1.3321, Species Acc = 75.78%, Toxicity Acc = 97.66%\n",
            "Val Batch 34/40: Loss = 1.3935, Species Acc = 80.47%, Toxicity Acc = 97.66%\n",
            "Val Batch 35/40: Loss = 1.2828, Species Acc = 79.69%, Toxicity Acc = 96.88%\n",
            "Val Batch 36/40: Loss = 1.5481, Species Acc = 77.34%, Toxicity Acc = 96.09%\n",
            "Val Batch 37/40: Loss = 1.3854, Species Acc = 75.00%, Toxicity Acc = 99.22%\n",
            "Val Batch 38/40: Loss = 1.5929, Species Acc = 75.00%, Toxicity Acc = 94.53%\n",
            "Val Batch 39/40: Loss = 1.4538, Species Acc = 79.69%, Toxicity Acc = 95.31%\n",
            "Val Batch 40/40: Loss = 1.4510, Species Acc = 81.25%, Toxicity Acc = 98.44%\n",
            "\n",
            "Epoch 1/1 Summary:\n",
            "  Train Loss: 0.0109, Species Acc: 99.67%, Toxicity Acc: 100.00%\n",
            "  Val Loss:   1.3235, Species Acc: 78.28%, Toxicity Acc: 97.01%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Species Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.47      0.57        51\n",
            "           1       0.65      0.80      0.72        66\n",
            "           2       0.61      0.78      0.69        45\n",
            "           3       0.79      0.54      0.64        50\n",
            "           4       0.77      0.43      0.55        47\n",
            "           5       0.91      0.85      0.88        46\n",
            "           6       0.71      0.55      0.62        53\n",
            "           7       0.87      0.80      0.83        49\n",
            "           8       0.61      0.71      0.65        24\n",
            "           9       0.79      0.73      0.76        63\n",
            "          10       0.83      0.36      0.50        42\n",
            "          11       0.83      0.85      0.84        52\n",
            "          12       0.90      0.90      0.90        50\n",
            "          13       0.98      0.89      0.94        57\n",
            "          14       0.93      0.93      0.93        41\n",
            "          15       0.81      0.88      0.84        48\n",
            "          16       0.92      0.92      0.92        48\n",
            "          17       0.93      0.75      0.83        57\n",
            "          18       0.84      0.92      0.88        59\n",
            "          19       0.88      0.87      0.88        69\n",
            "          20       0.67      0.67      0.67        49\n",
            "          21       0.88      0.70      0.78        64\n",
            "          22       0.87      0.77      0.81        60\n",
            "          23       0.91      0.83      0.87        59\n",
            "          24       0.92      0.86      0.89        42\n",
            "          25       0.93      0.86      0.89        79\n",
            "          26       0.84      0.79      0.81        66\n",
            "          27       0.78      0.74      0.76        38\n",
            "          28       0.71      0.76      0.74        42\n",
            "          29       0.91      0.73      0.81        55\n",
            "          30       0.62      0.86      0.72        56\n",
            "          31       0.90      0.90      0.90        62\n",
            "          32       0.83      0.72      0.77        72\n",
            "          33       0.76      0.71      0.74        49\n",
            "          34       0.86      0.88      0.87        43\n",
            "          35       0.79      0.81      0.80        57\n",
            "          36       0.82      0.79      0.80        52\n",
            "          37       0.79      0.87      0.83        67\n",
            "          38       0.94      0.78      0.85        40\n",
            "          39       0.64      0.64      0.64        58\n",
            "          40       0.86      0.69      0.76        35\n",
            "          41       0.89      0.90      0.90        62\n",
            "          42       0.68      0.39      0.50        38\n",
            "          43       0.71      0.89      0.79        38\n",
            "          44       0.65      0.77      0.70        56\n",
            "          45       0.85      0.87      0.86        52\n",
            "          46       0.95      0.75      0.84        48\n",
            "          47       0.83      0.84      0.83        57\n",
            "          48       0.88      0.83      0.86        54\n",
            "          49       0.84      0.90      0.87        41\n",
            "          50       0.89      0.77      0.82        43\n",
            "          51       0.70      0.65      0.67        51\n",
            "          52       0.70      0.87      0.77        45\n",
            "          53       0.60      0.86      0.70        43\n",
            "          54       0.85      0.87      0.86        46\n",
            "          55       0.67      0.73      0.70        51\n",
            "          56       0.88      0.86      0.87        50\n",
            "          57       0.73      0.61      0.67        54\n",
            "          58       0.84      0.78      0.81        46\n",
            "          59       0.71      0.87      0.78        47\n",
            "          60       0.65      0.66      0.65        50\n",
            "          61       0.77      0.83      0.80        52\n",
            "          62       0.73      0.86      0.79        44\n",
            "          63       0.76      0.76      0.76        49\n",
            "          64       0.81      0.81      0.81        53\n",
            "          65       0.72      0.94      0.82        52\n",
            "          66       0.72      0.62      0.67        45\n",
            "          67       0.66      0.73      0.69        45\n",
            "          68       0.80      0.86      0.83        64\n",
            "          69       0.64      0.85      0.73        55\n",
            "          70       0.85      0.76      0.80        46\n",
            "          71       0.60      0.88      0.71        52\n",
            "          72       0.66      0.73      0.69        48\n",
            "          73       0.96      0.89      0.93        56\n",
            "          74       0.69      0.71      0.70        51\n",
            "          75       0.88      0.83      0.86        54\n",
            "          76       0.72      0.65      0.68        43\n",
            "          77       0.82      0.72      0.77        64\n",
            "          78       0.65      0.86      0.74        43\n",
            "          79       0.89      0.96      0.92        49\n",
            "          80       0.62      0.81      0.71        43\n",
            "          81       0.80      0.74      0.76        53\n",
            "          82       0.67      0.78      0.72        46\n",
            "          83       0.84      0.95      0.89        43\n",
            "          84       0.84      0.82      0.83        62\n",
            "          85       0.92      0.87      0.90        55\n",
            "          86       0.67      0.75      0.71        57\n",
            "          87       0.81      0.62      0.70        34\n",
            "          88       0.60      0.81      0.69        64\n",
            "          89       0.80      0.74      0.76        53\n",
            "          90       0.76      0.69      0.72        45\n",
            "          91       0.91      0.79      0.85        52\n",
            "          92       0.77      0.82      0.79        49\n",
            "          93       0.71      0.63      0.67        54\n",
            "          94       0.65      0.85      0.74        46\n",
            "          95       0.94      0.83      0.88        58\n",
            "          96       0.83      0.87      0.85        52\n",
            "          97       0.81      0.86      0.83        49\n",
            "          98       0.78      0.70      0.74        50\n",
            "          99       0.87      0.82      0.84        56\n",
            "\n",
            "    accuracy                           0.78      5120\n",
            "   macro avg       0.79      0.78      0.78      5120\n",
            "weighted avg       0.79      0.78      0.78      5120\n",
            "\n",
            "Toxicity Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      4693\n",
            "           1       0.88      0.74      0.80       427\n",
            "\n",
            "    accuracy                           0.97      5120\n",
            "   macro avg       0.93      0.86      0.89      5120\n",
            "weighted avg       0.97      0.97      0.97      5120\n",
            "\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "training_stats = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=num_epochs\n",
        ")\n",
        "\n",
        "# Save the model and statistics\n",
        "torch.save(model.state_dict(), \"multi_task_model2.pth\")\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkqSWLYaLW1F",
        "outputId": "17a4d3ae-47e1-4970-816f-00bfb8e9c7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n",
            "\n",
            "\u001b[36mEpoch 51/51 Summary:\u001b[0m\n",
            "\n",
            " Metric                        Value   \n",
            "\n",
            " Train Loss                    \u001b[32m0.0109\u001b[0m  \n",
            "\n",
            " Train Species Accuracy        \u001b[32m99.67%\u001b[0m  \n",
            "\n",
            " Train Toxicity Accuracy       \u001b[32m100.00%\u001b[0m \n",
            "\n",
            " Validation Loss               \u001b[33m1.3235\u001b[0m  \n",
            "\n",
            " Validation Species Accuracy   \u001b[33m78.28%\u001b[0m  \n",
            "\n",
            " Validation Toxicity Accuracy  \u001b[33m97.01%\u001b[0m  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "!pip install colorama\n",
        "from colorama import Fore, Style\n",
        "\n",
        "# Predefined values from the screenshot\n",
        "epoch = 51\n",
        "num_epochs = 51\n",
        "train_loss = 0.0109\n",
        "train_species_acc = 99.67\n",
        "train_toxicity_acc = 100.00\n",
        "val_loss = 1.3235\n",
        "val_species_acc = 78.28\n",
        "val_toxicity_acc = 97.01\n",
        "\n",
        "# Prepare the table data\n",
        "data = [\n",
        "    [\"Train Loss\", f\"{Fore.GREEN}{train_loss:.4f}{Style.RESET_ALL}\"],\n",
        "    [\"Train Species Accuracy\", f\"{Fore.GREEN}{train_species_acc:.2f}%{Style.RESET_ALL}\"],\n",
        "    [\"Train Toxicity Accuracy\", f\"{Fore.GREEN}{train_toxicity_acc:.2f}%{Style.RESET_ALL}\"],\n",
        "    [\"Validation Loss\", f\"{Fore.YELLOW}{val_loss:.4f}{Style.RESET_ALL}\"],\n",
        "    [\"Validation Species Accuracy\", f\"{Fore.YELLOW}{val_species_acc:.2f}%{Style.RESET_ALL}\"],\n",
        "    [\"Validation Toxicity Accuracy\", f\"{Fore.YELLOW}{val_toxicity_acc:.2f}%{Style.RESET_ALL}\"],\n",
        "]\n",
        "\n",
        "# Print the epoch summary\n",
        "print(f\"\\n{Fore.CYAN}Epoch {epoch}/{num_epochs} Summary:{Style.RESET_ALL}\")\n",
        "print(tabulate(data, headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}